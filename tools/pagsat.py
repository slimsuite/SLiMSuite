#!/usr/bin/python

# See below for name and description
# Copyright (C) 2014 Richard J. Edwards <redwards@cabbagesofdoom.co.uk>
#  
# This program is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License
# as published by the Free Software Foundation; either version 2 of the License, or (at your option) any later version.
# 
# This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied
# warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with this program; if not, write to 
# the Free Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
#
# Author contact: <seqsuite@gmail.com> / School of Biotechnology and Biomolecular Sciences, UNSW, Sydney, Australia.
#
# To incorporate this module into your own programs, please see GNU Lesser General Public License disclaimer in rje.py

"""
Module:       PAGSAT
Description:  Pairwise Assembled Genome Sequence Analysis Tool
Version:      2.6.8
Last Edit:    08/04/19
Copyright (C) 2015  Richard J. Edwards - See source code for GNU License Notice

Function:
    This module is for the assessment of an assembled genome versus a suitable reference. For optimal results, the
    reference genome will be close to identical to that which should be assembled. However, comparative analyses should
    still be useful when different assemblies are run against a related genome - although there will not be the same
    expectation for 100% coverage and accuracy, inaccuracies would still be expected to make an assembly less similar
    to the reference.

Input:
    Main input for PAGSAT is an assembled genome in fasta format (`assembly=FILE`) and a reference genome in fasta format
    (`refgenome=FILE` or `reference=FILE`) with corresponding `*.gb`, `*.gbk` or `*.gbff` genbank download for feature
    extraction. For full function, a features table plus protein and gene sequences should be provided. (These will be
    parsed from a Genbank reference file.) Basic contig-reference mapping and plotting will still be performed with a
    pure sequence reference that lacks features or gene sequences.

    ### ~ Reference Sequence Naming ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
    PAGSAT expects a particular naming format for assembly sequences, which is a bit more constrained that most programs.
    This is to enable the full suite of visualisation with clear unambiguous labelling of contigs. Input sequence names
    must be in the form: `ctgXX_SPCODE__ACCBASE.YY`, where both `ctgXX` and `YY` are *unique* for each contig.
    (Generally `XX` and `YY` will match but this is not a requirement.) `ACCBASE` could be the same for all sequences, or
    it could be sequence-specific. It can also include `.` characters: only the final `.` element must be unique. `YY`
    must end with numbers. (These are expected to be contig numbers, possibly with a prefix.)

Sequence mapping:
    Version 2.6 introduced a `mapper=minimap` option for using minimap2 in place of BLAST+ for mapping the assembly and
    reference against each other (and themselves). This should be considered a "quick and dirty" version of PAGSAT, with
    much faster run times but missing a lot of small repeat sequences and more divergent matches. It is primarily for
    initial assessment and triage of different assemblies before picking a cleaner/tidier one for further analysis.

Output:
    Main output is a number of delimited text files and PNG graphics made with R. Details to follow.

    NOTE: Snapper is now used for the underlying Reference vs Assembly GABLAM searches (unless `snapper=F`). For speed,
    the SNP mapping functions are switched off. To get the full set of Snapper outputs, use `makesnp=T`.

    ### ~ MapFas Output ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
    The `mapfas=T` function generates a new copy of the assembly (in the main PAGSAT output directory) in which contigs
    have been reorientated to be the same strand as the reference chromosomes where possible. This is performed on the
    basis of the reference chromosome with maximum unique coverage for each contig, e.g the contig will be matched to the
    reference chromosome for which it has the most bases that ONLY map to that chromosome. (Clearly this will only work
    if the reference is haploid!) Where the majority of matching bases are on the negative strand, the contig will be
    reverse complemented and the accnum updated such that `XXXX.YY` becomes `XXXX.RYY`.

    If the assembly has `*.coverage.tdt` and `*.depthplot.tdt` data (generated by
    `SeqSuite.SAMTools` or `PAGSAT` if a `*.sam` file is provided), these files will be converted to `*.map.*.tdt` that
    match the `*.map.fasta` contigs.

Commandline:
    ### ~ Input/Setup Options ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
    assembly=FILE   : Fasta file of assembled contigs to assess [None]
    refgenome=FILE  : Fasta file of reference genome for assessment (also *.gb for full functionality) [None]
    spcode=X        : Species code for reference genome (if not already processed by rje_genbank) [None]
    minqv=X         : Minimum mean QV score for assembly contigs (read from *.qv.csv) [20]
    mincontiglen=X  : Minimum contig length to retain in assembly (QV filtering only) [1000]
    casefilter=T/F  : Whether to filter leading/trailing lower case (low QV) sequences [True]
    ### ~ Reference vs Assembly Options ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
    minlocid=X      : Minimum percentage identity for local hits mapping to chromosome coverage [95.0]
    minloclen=X     : Mininum length for local hits mapping to chromosome coverage [250]
    genesummary=T/F : Whether to include reference gene searches in summary data [True]
    protsummary=T/F : Whether to include reference protein searches in summary data [True]
    tophitbuffer=X  : Percentage identity difference to keep best hits for reference genes/proteins. [1.0]
    diploid=T/F     : Whether to treat assembly as a diploid [False]
    minunique=X     : Minimum number of "Unique-mapping" nucleotides to retain a contig-chromosome link [250]
    snapper=T/F     : Run Snapper to generate "best" unique mapping of assembly contigs to Reference [True]
    makesnp=T       : Generate the full set of SNP outputs for Snapper [False]
    mapper=X        : Program to use for mapping files against each other (blast/minimap) [blast]
    mapopt=CDICT    : Dictionary of updated minimap2 options [N:250,p:0.0001,x:asm20]
    ### ~ Output Options ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
    basefile=X      : Basename for output files and directories. [assembly+ref]
    rgraphics=T/F   : Whether to generate PNG graphics using R. (Needs R installed and setup) [True]
    dotplots=T/F    : Whether to use gablam.r to output dotplots for all ref vs assembly. [False]
    assessment=T/F  : Whether to perform full reference versus assembly assessment [False]
    report=T/F      : Whether to generate HTML report. Also sets assessment=T (default function). [False]
    genetar=T/F     : Whether to tar and zip the GeneHits/ and ProtHits/ folders (if generated & Mac/Linux) [True]
    chromalign=T/F  : [Discontinued] Whether to perform crude chromosome-contig alignment [False]
    orderedfas=T/F  : Whether to generate crude ordered contig output for e.g. Progressive Mauve [False]
    treeformats=LIST: Output formats for chromosome versus contig %identify UPGMA tree [nwk,png]
    dismatrix=T/F   : Whether to generate distance matrix of chromosome vs contig identities [False]
    ### ~ Comparison Options ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
    compare=FILES   : Compare assemblies selected using a list of *.Summary.tdt files (wildcards allowed). []
    fragcov=LIST    : List of coverage thresholds to count min. local BLAST hits (checks integrity) [50,90,95,99]
    chromcov=LIST   : Report no. of chromosomes covered by a single contig at different %globID (GABLAM table) [95,98,99]
    compile=FILES   : Compile reference chromosome comparisons for a set of *.report.html files []
    ### ~ Assembly Tidy/Edit Options ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
    mapfas=T/F      : Output assembly *.map.fasta file with RevComp contigs based on initial (automatic) mapping [False]
    tidy=T/F        : Execute semi-automated assembly tidy/edit mode to complete draft assembly [False]
    newacc=X        : New base for edited contig accession numbers (None will keep old accnum) [None]
    newchr=X        : Code to replace "chr" in new sequence names for additional PAGSAT compatibility [ctg]
    spcode=X        : Species code for renaming assembly sequences [PAGSAT]
    refchr=X        : Code used in place of "chr" for reference sequence names [chr]
    orphans=T/F     : Whether to include and process orphan contigs [True]
    joinsort=X      : Whether to sort potential chromosome joins by `Length` or `Identity` [Identity]
    joinmerge=X     : Merging mode for joining chromosomes (mid/start/end/longest) [mid]
    joinmargin=X    : Number of extra bases allowed to still be considered an end local BLAST hit [10]
    ### ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
"""
#########################################################################################################################
### SECTION I: GENERAL SETUP & PROGRAM DETAILS                                                                          #
#########################################################################################################################
import glob, os, string, sys, time
slimsuitepath = os.path.abspath(os.path.join(os.path.dirname(os.path.realpath(__file__)),'../')) + os.path.sep
sys.path.append(os.path.join(slimsuitepath,'libraries/'))
sys.path.append(os.path.join(slimsuitepath,'tools/'))
### User modules - remember to add *.__doc__ to cmdHelp() below ###
import rje, rje_db, rje_genbank, rje_html, rje_menu, rje_obj, rje_samtools, rje_seqlist, rje_sequence, rje_synteny, rje_tree, rje_tree_group, rje_xref
import rje_blast_V2 as rje_blast
import rje_dismatrix_V3 as rje_dismatrix
import gablam, snapper
#########################################################################################################################
def history():  ### Program History - only a method for PythonWin collapsing! ###
    '''
    # 1.0.0 - Initial working version for based on rje_pacbio assessment=T.
    # 1.1.0 - Fixed bug with gene and protein summary data. Removed gene/protein reciprocal searches. Added compare mode.
    # 1.1.1 - Added PAGSAT output directory for tidiness!
    # 1.1.2 - Renamed the PacBio class PAGSAT.
    # 1.2.0 - Tidied up output directories. Added QV filter and Top Gene/Protein hits output.
    # 1.2.1 - Added casefilter=T/F  : Whether to filter leading/trailing lower case (low QV) sequences [True]
    # 1.3.0 - Added tophitbuffer=X and initial synteny analysis for keeping best reference hits.
    # 1.4.0 - Added chrom-v-contig alignment files along with *.ordered.fas.
    # 1.4.1 - Made default chromalign=T.
    # 1.4.2 - Fixed casefilter=F.
    # 1.5.0 - diploid=T/F     : Whether to treat assembly as a diploid [False]
    # 1.6.0 - mincontiglen=X  : Minimum contig length to retain in assembly [1000]
    # 1.6.1 - Added diploid=T/F to R PNG call.
    # 1.7.0 - Added tidy=T/F option. (Development)
    # 1.7.1 - Updated tidy=T/F to include initial assembly.
    # 1.7.2 - Fixed some bugs introduced by changing gablam fragment output.
    # 1.7.3 - Added circularise sequence generation.
    # 1.8.0 - Added orphan processing and non-chr naming of Reference.
    # 1.9.0 - Modified the join sorting and merging. Added better tracking of positions when trimming.
    # 1.9.1 - Added joinmargin=X    : Number of extra bases allowed to still be considered an end local BLAST hit [10]
    # 1.10.0 - Added weighted tree output and removed report warning.
    # 1.10.1 - Fixed issue related to having Description in GABLAM HitSum tables.
    # 1.10.2 - Tweaked haploid core output.
    # 1.10.3 - Fixed tidy bug for RevComp contigs and switched joinsort default to Identity. (Needs testing.)
    # 1.10.4 - Added genetar option to tidy out genesummary and protsummary output. Incorporated rje_synteny.
    # 1.10.5 - Set gablamfrag=1 for gene/protein hits.
    # 1.11.0 - Consolidated automated tidy mode and cleaned up some excess code.
    # 1.11.1 - Added option for running self-PAGSAT of ctidX contigs versus haploid set. Replaced ctid "X" with "N".
    # 1.11.2 - Fixed Snapper run choice bug.
    # 1.11.3 - Added reference=FILE as alias for refgenome=FILE. Fixed orphan delete bug.
    # 1.12.0 - Tidying up and documenting outputs. Changed default minloclen=250 and minlocid=95. (LTR identification.)
    # 2.0.0 - Major overhaul of outputs to improve consistency and clarity. Added Snapper to main run.
    # 2.1.0 - Added localSAM output.
    # 2.1.1 - Fixed the case of some output files.
    # 2.1.2 - Fixed some issues with reverse hits in Snapper and application of minlocid.
    # 2.2.0 - Added mapout=T, which is recommended for first run if going to subsequently tidy. (Run tidy on mapfile.)
    # 2.2.1 - Tried to fix covplot bug in compare=FILES mode.
    # 2.2.2 - Cleaned up *.map.* output for SAMPhaser output files. Added tidy/mapfas option selection.
    # 2.2.3 - Added #NOTE to tidy and fixed makesnp=T bug.
    # 2.2.4 - Fixed `fragrevcomp=F` bug for Gene and Protein TopHits.
    # 2.2.5 - Hopefully really fixed makesnp=T bug now!
    # 2.2.6 - Fixed Haploid tidy sequence output naming bug.
    # 2.2.7 - Fixed Compare File path bug & dropped some empty outputs.
    # 2.3.0 - Minor bug fixes and extra tidy options (join gaps and multi-deletes).
    # 2.3.1 - Minor bug fixes.
    # 2.3.2 - Updated the synteny mappings to be m::n instead of m:n for Excel compatibility.
    # 2.3.3 - Fixed bad assembly sequence name bug.
    # 2.3.4 - Fixed full.fas request bug.
    # 2.4.0 - Added PAGSAT compile mode to generate comparisons of reference chromosomes across assemblies.
    # 2.5.0 - Reduced the executed code when mapfas=T assessment=F. (Recommended first run.) Added renaming.
    # 2.5.1 - Added recognition of *.gbff for genbank files.
    # 2.6.0 - Added mapper=X : Program to use for mapping files against each other (blast/minimap) [blast]
    # 2.6.1 - Switch failure to find key report files to a long warning, not program exit.
    # 2.6.2 - Fixed bugs with mapper=minimap mode and started adding more internal documentation.
    # 2.6.3 - Fixed default behaviour to run report=T mode.
    # 2.6.4 - Fixed summary table merge bug.
    # 2.6.5 - Fixed compile path bug.
    # 2.6.6 - Fixed BLAST LocalIDCut error for GABLAM and QAssemble stat filtering.
    # 2.6.7 - Generalised compile path bug fix.
    # 2.6.8 - Added ChromXcov fields to PAGSAT Compare.
   '''
#########################################################################################################################
def todo():     ### Major Functionality to Add - only a method for PythonWin collapsing! ###
    '''
    # [Y] : Populate Module Docstring with basic info.
    # [Y] : Populate makeInfo() method with basic info.
    # [ ] : Add full description of program to module docstring.
    # [Y] : Create initial working version of program.
    # [N] : Add REST outputs to restSetup() and restOutputOrder()
    # [Y] : Add to SLiMSuite or SeqSuite.
    # [Y] : Add reduced functionality if genbank file not given (i.e. no features).
    # [Y] : Add HTML report output.
    # [ ] : Add indels to QAssemble
    # [?] : Have a min minloclen (=localcut) but then try increasing by 1kb chunks without increasing "N" periods?
    # [Y] : Calculate the difference from Reference as a number for comparisons.
    # [?] : Pull out "N" regions of the reference - QAssemble back against the pre-assembly and subreads.
    # [ ] : Add (interactive?) reformatting of *.full.fas for refgenome input.
    # [Y] : Include minloclen in relevant file names - GABLAM and default basefile.
    # [Y] : Consider using minloclen for localcut=X GABLAM Cut-off length for local alignments contributing to global stats.
    # [Y] : Option to switch off Gene and Protein searches for increased speed. (Need to edit R summGraph() too)
    # [ ] : Improve gene search to extend hits to full length of genes/proteins.
    # [ ] : Separate minloclen and localcut?
    # [ ] : Add thumbnails=T/F for report and R graphics
    # [ ] : Add maxcontig=X for a single summary page. (Ask to proceed if more contigs? Or split?)
    # [ ] : Add summary stats for assembly and reference? (Could load them into SeqList objects)
    # [Y] : Add reading of unitig coverage and quality scores from quiver (*.qv.csv files)
    # [Y] : Need to tidy up outputs. Generate a *.PAGSAT/ directory for most outputs: update R script accordingly.
    # [N] : blastdir=PATH   : Path for blast results file (unless keepblast=F) [./assembly.BLAST/]
    # [Y] : Add separate GABLAM directory for feature searches? (./assembly.GABLAM/) (These ignore cutoffs, right?)
    # [Y] : Add (and distinguish) minlocid to output file names as well as minloclen. (Make integer? *.LXXX.IDXX.*)
    # [X] : Contemplate setting softmask=F for BLAST searches. (Why are some genes missing?!)
    # [ ] : Consider replacing GABLAM fragfas with own gene extraction algorithm that extends ORFs & combines exons.
    # [Y] : Move R graphics such that it can be re-run in isolation (if summary.png missing).
    # [ ] : Need to add Ty element searching and mapping. Probably need to do this prior to assembly?
    # [ ] : Add Ty element map to the contig output somehow? Or just a separate map?
    # [Y] : Sort out Full, Tandem, Partial etc. TopHits classification.
    # [ ] : Add an "ends" mode for tidying where only unique-mapped ends are considered for joining.
    # [ ] : Will need to modify contig chr naming for "ends" mode - some ambiguous, some not.
    # [Y] : Add Snapper in place of GABLAM: Test makesnp=F to limit output to CNV and unique local hits.
    # [ ] : Update to reassign CtidA and B to Snapper regions when diploid=T. (And CtidN?)
    # [ ] : Update TopHits to process CtidA and CtidB separately when diploid=T. (And CtidN?)
    # [ ] : Add generation of *.depthplot.tdt and *.coverage.tdt files (rje_samtools) for pagsat R scripts and PNGs.
    # [ ] : Replace ctid with htig. (Haplotigs - homologous chromosomes - not chromatids.)
    # [ ] : Find out what causes some local hits to escape the minlocid cutoff and trigger pre-2.0 version warning.
    # [2.2.7] : Fix compare mode to work with new output and runs performed in other directories. (See #!# comments.)
    # [ ] : Need to add check for input sequence naming compatibility.
    # [2.3.0] : Add running "open *.assembly.html" option (Y/N) - No gives firefox option?
    # [2.3.0] : Update preassembly message to mention assembly.html not report.html. (Or both?)
    # [ ] : Update compare mode to assess coverage based on Snapper output.
    # [ ] : Tidy up assessment of blast outputs etc. if using mapper=minimap.
    # [ ] : Fix covplot output for mapper=minimap runs.
    '''
#########################################################################################################################
def makeInfo(): ### Makes Info object which stores program details, mainly for initial print to screen.
    '''Makes Info object which stores program details, mainly for initial print to screen.'''
    (program, version, last_edit, copy_right) = ('PAGSAT', '2.6.8', 'April 2019', '2015')
    description = 'Pairwise Assembled Genome Sequence Analysis Tool'
    author = 'Dr Richard J. Edwards.'
    comments = ['This program is still in development and has not been published.',rje_obj.zen()]
    return rje.Info(program,version,last_edit,description,author,time.time(),copy_right,comments)
#########################################################################################################################
def cmdHelp(info=None,out=None,cmd_list=[]):   ### Prints *.__doc__ and asks for more sys.argv commands
    '''Prints *.__doc__ and asks for more sys.argv commands.'''
    try:### ~ [1] ~ Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
        if not info: info = makeInfo()
        if not out: out = rje.Out()
        ### ~ [2] ~ Look for help commands and print options if found ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
        cmd_help = cmd_list.count('help') + cmd_list.count('-help') + cmd_list.count('-h')
        if cmd_help > 0:
            print '\n\nHelp for %s %s: %s\n' % (info.program, info.version, time.asctime(time.localtime(info.start_time)))
            out.verbose(-1,4,text=__doc__)
            if rje.yesNo('Show general commandline options?'): out.verbose(-1,4,text=rje.__doc__)
            if rje.yesNo('Quit?'): sys.exit()           # Option to quit after help
            cmd_list += rje.inputCmds(out,cmd_list)     # Add extra commands interactively.
        elif out.stat['Interactive'] > 1: cmd_list += rje.inputCmds(out,cmd_list)    # Ask for more commands
        ### ~ [3] ~ Return commands ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
        return cmd_list
    except SystemExit: sys.exit()
    except KeyboardInterrupt: sys.exit()
    except: print 'Major Problem with cmdHelp()'
#########################################################################################################################
def setupProgram(extracmd=[]): ### Basic Setup of Program when called from commandline.
    '''
    Basic Setup of Program when called from commandline:
    - Reads sys.argv and augments if appropriate
    - Makes Info, Out and Log objects
    - Returns [info,out,log,cmd_list]
    '''
    try:### ~ [1] ~ Initial Command Setup & Info ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
        info = makeInfo()                                   # Sets up Info object with program details
        cmd_list = rje.getCmdList(sys.argv[1:]+extracmd,info=info)   # Reads arguments and load defaults from program.ini
        out = rje.Out(cmd_list=cmd_list)                    # Sets up Out object for controlling output to screen
        out.verbose(2,2,cmd_list,1)                         # Prints full commandlist if verbosity >= 2 
        out.printIntro(info)                                # Prints intro text using details from Info object
        cmd_list = cmdHelp(info,out,cmd_list)               # Shows commands (help) and/or adds commands from user
        log = rje.setLog(info,out,cmd_list)                 # Sets up Log object for controlling log file output
        return (info,out,log,cmd_list)                      # Returns objects for use in program
    except SystemExit: sys.exit()
    except KeyboardInterrupt: sys.exit()
    except: print 'Problem during initial setup.'; raise
#########################################################################################################################
### END OF SECTION I                                                                                                    #
#########################################################################################################################

                                                    ### ~ ### ~ ###

#########################################################################################################################
### SECTION II: PAGSAT Class                                                                                            #
#########################################################################################################################
class PAGSAT(rje_obj.RJE_Object):
    '''
    PAGSAT Class. Author: Rich Edwards (2015).

    Str:str
    - Assembly=FILE   : Fasta file of assembled contigs to assess [None]
    - BaseBase        : Path-trimmed Basefile for outputs that do not involve data filtering etc.
    - ChrMap=X        : Contig:Chromosome mapping mode for assembly tidy (unique/align) [unique]
    - CutBase         : Path-trimmed Basefile for outputs that include data filtering etc.
    - GABLAMDir       : Parent directory for all BLAST and GABLAM searches.
    - JoinMerge=X     : Merging mode for joining chromosomes (consensus/long/end) [end]
    - JoinSort=X      : Whether to sort potential chromosome joins by `Length` or `Identity` [Length]
    - Mapper=X        : Program to use for mapping files against each other (blast/minimap) [blast]
    - NewAcc=X        : New base for edited contig accession numbers (None will keep old accnum) [None]
    - NewChr=X        : Code to replace "chr" in new sequence names for additional PAGSAT compatibility [ctg]
    - RefBase=X       : Basefile for reference genome for assessment (*.gb) [None]
    - RefChr=X        : Code used in place of "chr" for reference sequence names [chr]
    - RefGenome=FILE  : Fasta file of reference genome for assessment (also *.gb for full functionality) [None]
    - ResDir          : Results directory = BASEFILE.PAGSAT/
    - SpCode=X        : Species code for non-gnspacc format sequences [PAGSAT]

    Bool:boolean
    - Assessment=T/F  : Whether to perform full reference versus assembly assessment (default function) [True]
    - CaseFilter=T/F  : Whether to filter leading/trailing lower case (low QV) sequences [True]
    - ChromAlign=T/F  : Whether to align chromosomes with contigs (slow!) [False]
    - Diploid=T/F     : Whether to treat assembly as a diploid [False]
    - DisMatrix=T/F   : Whether to generate distance matrix of chromosome vs contig identities [False]
    - DotPlots=T/F    : Whether to use gablam.r to output dotplots for all ref vs assembly. [False]
    - Features=T/F    : Whether to expect a Features table (from Genbank processing) [True]
    - GeneSummary=T/F : Whether to include reference gene searches in summary data [True]
    - GeneTar=T/F     : Whether to tar and zip the GeneHits/ and ProtHits/ folders (if generated & Mac/Linux) [True]
    - MapFas=T/F      : Output assembly *.map.fasta file with RevComp contigs based on initial (automatic) mapping [True]
    - OrderedFas=T/F  : Whether to generate crude ordered contig output for e.g. Progressive Mauve [False]
    - Orphans=T/F     : Whether to include and process orphan contigs [True]
    - ProtSummary=T/F : Whether to include reference protein searches in summary data [True]
    - RGraphics=T/F   : Whether to generate PNG graphics using R [True]
    - Report=T/F      : Whether to generate HTML report [True]
    - Snapper=T/F     : Run Snapper on ctidX output following PAGSAT Tidy [True]
    - Tidy=T/F        : Execute semi-automated assembly tidy/edit mode to complete draft assembly [False]

    Int:integer
    - JoinMargin=X    : Number of extra bases allowed to still be considered an end local BLAST hit [10]
    - MinContigLen=X  : Minimum contig length to retain in assembly [1000]
    - MinLocLen=X     : Mininum length for local hits mapping to chromosome coverage [100]
    - MinQV=X         : Minimum mean QV score for assembly contigs (read from *.qv.csv) [20]
    - MinUnique=X     : Minimum number of "Unique-mapping" nucleotides to retain a contig-chromosome link [250]

    Num:float
    - MinLocID=X      : Minimum percentage identity for local hits mapping to chromosome coverage [0.99]
    - TopHitBuffer=X  : Percentage identity difference to keep best hits for reference genes/proteins. [1.0]

    File:file handles with matching str filenames
    
    List:list
    - ChromCov=LIST   : Report no. of chromosomes covered by a single contig at different %globID (GABLAM table) [95,98,99]
    - Compare=FILES   : Special mode to compare a list of *.Summary.tdt files (wildcards allowed). []
    - Compile=FILES   : Compile reference chromosome comparisons for a set of *.report.html files []
    - FragCov=LIST    : List of coverage thresholds to count min. local BLAST hits (checks integrity) [50,90,95,99]

    Dict:dictionary
    - QV              : Dictionary of contig:QV score read from *.qv.csv

    Obj:RJE_Objects
    - Features  : Reference Features Database table (reused for Compare=T).
    '''
#########################################################################################################################
    ### <1> ### Class Initiation etc.: sets attributes                                                                  #
#########################################################################################################################
    def _setAttributes(self):   ### Sets Attributes of Object
        '''Sets Attributes of Object.'''
        ### ~ Basics ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
        self.strlist = ['Assembly','BaseBase','CaseFilter','ChrMap','CutBase','GABLAMDir','JoinMerge','JoinSort',
                        'Mapper','NewAcc','NewChr','RefBase','RefChr','RefGenome','ResDir']
        self.boollist = ['Assessment','ChromAlign','Diploid','DisMatrix','DotPlots','Features','GeneSummary','GeneTar',
                         'MapFas','Orphans','ProtSummary','RGraphics','Report','Snapper','Tidy']
        self.intlist = ['JoinMargin','MinContigLen','MinLocLen','MinQV','MinUnique']
        self.numlist = ['MinLocID','TopHitBuffer']
        self.filelist = []
        self.listlist = ['ChromCov','Compare','Compile','FragCov']
        self.dictlist = ['QV']
        self.objlist = ['DB','Features']
        ### ~ Defaults ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
        self._setDefaults(str='None',bool=False,int=0,num=0.0,obj=None,setlist=True,setdict=True,setfile=True)
        self.setStr({'ChrMap':'unique','GABLAMDir':rje.makePath('GABLAM/'),'JoinMerge':'mid','JoinSort':'Identity',
                     'Mapper':'blast','NewChr':'ctg','RefChr':'chr'})
        self.setBool({'Assessment':False,'CaseFilter':True,'ChromAlign':False,
                      'Diploid':False,'DisMatrix':False,'DotPlots':False,'Features':True,
                      'GeneSummary':True,'GeneTar':True,'MapFas':False,'OrderedFas':False,'Orphans':True,
                      'ProtSummary':True,'RGraphics':True,'Report':False,'Snapper':True,'Tidy':False})
        self.setInt({'JoinMargin':10,'MinLocLen':250,'MinQV':20,'MinContigLen':1000,'MinUnique':250})
        self.setNum({'MinLocID':95.0,'TopHitBuffer':1.0})
        self.list['ChromCov'] = [95,98,99]
        self.list['FragCov'] = [50,90,95,99]
        ### ~ Other Attributes ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
        self._setForkAttributes()   # Delete if no forking
#########################################################################################################################
    def _cmdList(self):     ### Sets Attributes from commandline
        '''
        Sets attributes according to commandline parameters:
        - see .__doc__ or run with 'help' option

        The following command over-rides will be executed:

        * If `win32=$` then `genetar` is set to `False`.
        * If the assembly file is `*.map.$EXT` then `mapfas` will be set to `False`.
        * ... complete
        '''
        for cmd in self.cmd_list:
            try:
                self._generalCmd(cmd)   ### General Options ### 
                self._forkCmd(cmd)  # Delete if no forking
                ### Class Options (No need for arg if arg = att.lower()) ### 
                #self._cmdRead(cmd,type='str',att='Att',arg='Cmd')  # No need for arg if arg = att.lower()
                self._cmdReadList(cmd,'str',['ChrMap','JoinMerge','JoinSort','Mapper','NewAcc','NewChr','RefChr'])   # Normal strings
                #self._cmdReadList(cmd,'path',['Att'])  # String representing directory path 
                self._cmdReadList(cmd,'file',['Assembly','RefGenome'])  # String representing file path
                self._cmdRead(cmd,type='file',att='RefGenome',arg='reference')  # No need for arg if arg = att.lower()
                #self._cmdReadList(cmd,'date',['Att'])  # String representing date YYYY-MM-DD
                self._cmdReadList(cmd,'bool',['Assessment','CaseFilter','ChromAlign','Diploid','DisMatrix','DotPlots','GeneSummary','GeneTar','MapFas',
                                              'OrderedFas','Orphans','ProtSummary','RGraphics','Report','Snapper','Tidy'])  # True/False Booleans
                self._cmdReadList(cmd,'int',['JoinMargin','MinContigLen','MinLocLen','MinQV','MinUnique'])   # Integers
                self._cmdReadList(cmd,'float',['TopHitBuffer']) # Floats
                self._cmdReadList(cmd,'perc',['MinLocID'])
                #self._cmdReadList(cmd,'max',['Att'])   # Integer value part of min,max command
                #self._cmdReadList(cmd,'list',[])  # List of strings (split on commas or file lines)
                self._cmdReadList(cmd,'ilist',['ChromCov','FragCov'])  # List of strings (split on commas or file lines)
                #self._cmdReadList(cmd,'clist',['Att']) # Comma separated list as a *string* (self.str)
                self._cmdReadList(cmd,'glist',['Compare','Compile']) # List of files using wildcards and glob
                #self._cmdReadList(cmd,'cdict',['Att']) # Splits comma separated X:Y pairs into dictionary
                #self._cmdReadList(cmd,'cdictlist',['Att']) # As cdict but also enters keys into list
            except: self.errorLog('Problem with cmd:%s' % cmd)
        if self.win32() and self.getBool('GeneTar'):
            self.printLog('#WIN32','Cannot use targz on Windows: GeneTar=False.')
            self.setBool({'GeneTar':False})
        if self.getBool('MapFas') and rje.baseFile(self.getStr('Assembly')).endswith('.map') and (self.i() < 0 or rje.yesNo('Assembly file seems to be a mapping output file (*.map.fasta): switch mapfas=F')):
            self.printLog('#CMD','Assembly file seems to be a mapping output file (*.map.fasta): switched mapfas=F')
            self.setBool({'MapFas':False})
        if self.getBool('MapFas') and self.getBool('Tidy'):
            if (self.i() < 0 or rje.yesNo('MapFas=T and Tidy=T. It is recommended to run Tidy mode on *.map.fasta output: switch tidy=F?')):
                self.printLog('#CMD','Switching tidy=False.')
                self.setBool({'Tidy':False})
            elif rje.yesNo('Switch mapfas=F?'):
                self.printLog('#CMD','Switching mapfas=False.')
                self.setBool({'MapFas':False})
        if self.getBool('Tidy') and not self.getBool('Assessment'):
            self.printLog('#CMD','Tidy mode: switching assessment=True.')
            self.setBool({'Assessment':True})
        if self.getBool('Report') and not self.getBool('Assessment'):
            self.printLog('#CMD','Report mode: switching assessment=True.')
            self.setBool({'Assessment':True})
        if self.getBool('Tidy') and (self.getBool('GeneSummary') or self.getBool('ProtSummary')):
            self.printLog('#TIDY','PAGAT Tidy mode selected with: GeneSummary:%s; ProtSummary:%s' % (self.getBool('GeneSummary'),self.getBool('ProtSummary')))
            self.printLog('#TIDY','Switching genesummary=F protsummary=F will make Tidy Quicker.')
            if self.yesNo('Switch off GeneSummary and ProtSummary for faster PASGAT Tidy run? (Will Reactivate for follow-up PAGSAT on tidied assembly.)'):
                self.setBool({'GeneSummary':False,'ProtSummary':False})
                self.printLog('#TIDY','Set: GeneSummary=%s; ProtSummary=%s' % (self.getBool('GeneSummary'),self.getBool('ProtSummary')))
        if os.path.split(self.getStr('Basefile'))[0]:
            if self.i() >= 0 and rje.yesNo('Cannot use basefile=X with path. (basefile=%s). Trim path?' % self.getStr('Basefile')):
                self.baseFile(os.path.split(self.getStr('Basefile'))[1])
            else: raise ValueError('Cannot use basefile=X with path. (basefile=%s)' % self.getStr('Basefile'))
        if self.getStrLC('ResDir'):
            self.warnLog('ResDir=X does not function with PAGSAT. (Ignored.)')
            self.deBug(self.getStrLC('ResDir'))
        ### Mapper ###
        self.setStr({'Mapper':self.getStrLC('Mapper')})
        if self.getStr('Mapper') not in ['minimap','minimap2','blast']:
            self.warnLog('mapper=%s not recognised (blast/minimap): switched to blast' % self.getStr('Mapper'))
            self.setStr({'Mapper':'blast'})
            self.cmd_list.append('mapper=blast')
        if self.getStr('Mapper') in ['minimap2']: self.setStr({'Mapper':'minimap'})
#########################################################################################################################
    def pafMode(self): return self.getStr('Mapper') in ['minimap','minimap2']
#########################################################################################################################
    ### <2> ### Main Class Backbone                                                                                     #
#########################################################################################################################
    def run(self):  ### Main run method
        '''# PAGSAT Overview

        PAGSAT has six basic run modes. In each case, the setup will be run first. For `compare` and `compile` modes,
        this sets the `basefile` for output and initiates the internal Database object. All other modes will set up the
        reference and assembly genomes, along with key output directories and file names.

        The six run modes, in reverse order of precedence are:

        1. **MapFas** (`mapfas=T`). Output assembly `*.map.fasta` file with RevComp contigs based on initial (automatic)
        mapping but do not perform any additional assessment or analysis. This is best-suited for a pre-run before `tidy`
        mode. This can be combined with any assessment mode.

        2. **Assessment** (`assessment=T`). Perform the basic PAGSAT function of full reference versus assembly
        assessment. PNG graphics will be generated if `rgraphics=T`.

        3. **Report** (`report=T`). Peform PAGSAT assessment and generate additional `*.report.html` HTML report output.

        4. **Tidy** (`tidy=T`). Perform PAGAST report (if not found) and generate additional `*.assembly.html` contig vs.
        contig graphics, along with interactive options for tidying the assembly (deleting/joining contigs, etc.)

        5. **Compile** (`compile=FILES`). Compile reference chromosome comparisons for a set of `*.report.html` files for
        a detailed chromosome-by-chromosome comparison of assebmlies.

        6. **Compare** (`compare=FILES`). Compare assemblies selected using a list of `*.Summary.tdt` files (wildcards
        allowed) and additional calculate values, to compile a table of statistics.

        If no acceptable run mode is detected, the option to run **Report** mode will be given.
        '''
        try:### ~ [1] ~ Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            self.devLog('#RUN','Run',debug=False)
            if not self.setup(): return False
            ### ~ [2] ~ Add main run code here ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            if self.list['Compare']: return self.compare()
            if self.list['Compile']: return self.compile()
            if self.getBool('Tidy'): return self.tidy()
            if self.getBool('Report'): return self.report()
            if self.getBool('Assessment'): return self.assessment()
            if self.getBool('MapFas'): return self.pureMapFas()
            ### ~ [3] ~ Add default run mode here ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            #!# Replace with menu at some point #!#
            self.printLog('#RUN','No PAGSAT run mode (mapfas/assessment/report/tidy/compare/compile) detected.')
            if self.i() < 0  or rje.yesNo('No PAGSAT run mode (mapfas/assessment/report/tidy/compare/compile) detected. Run report mode?'):
                self.printLog('#RUN','Set report=T.')
                self.setBool({'Report':True,'Assessment':True})
                return self.report()
        except:
            self.errorLog(self.zen())
            raise   # Delete this if method error not terrible
#########################################################################################################################
    def setup(self):    ### Main class setup method.
        '''
        Main class setup method. This sets up the main Database object.

        In Compare or Compile mode, nothing else is done beyond checking/setting basefile.

        Other modes go through a series of setup stages:
        1. Set up Reference Genome.
        2. Set up Assembly with QV filtering if required.
        3. Report on key settings and setup output directories etc.
        '''
        try:### ~ [0] Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            self.devLog('#RUN','Setup',debug=False)
            ## ~ [0a] Database Object ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            #i# First, the Database object is setup. This is used to control all output tables and integrate data.
            self.printLog('#~~#','## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ PAGSAT Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##')
            self.obj['DB'] = rje_db.Database(self.log,self.cmd_list+['tuplekeys=T'])
            ## ~ [0b] Check for Compare Mode and cancel rest of setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            if self.list['Compare'] or self.list['Compile']:
                if not self.basefile(return_none=''): self.basefile('pagsat')
                return True

            ### ~ [1] Set up Reference Genome ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            checkfiles = []     # List of files that need to exist to proceed
            ## ~ [1a] Set up Reference Genome basefile (RefBase) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            #i# RefBase will include the path to the reference genomes
            if rje.exists('%s.gb' % self.getStr('RefGenome')): self.setStr({'RefBase':self.getStr('RefGenome')})
            elif rje.exists('%s.gbk' % self.getStr('RefGenome')): self.setStr({'RefBase':self.getStr('RefGenome')})
            elif rje.exists('%s.gbff' % self.getStr('RefGenome')): self.setStr({'RefBase':self.getStr('RefGenome')})
            else: self.setStr({'RefBase':rje.baseFile(self.getStr('RefGenome'))})
            if rje.exists('%s.gbk' % self.getStr('RefBase')): gbfile = '%s.gbk' % self.getStr('RefBase')
            elif rje.exists('%s.gbff' % self.getStr('RefBase')): gbfile = '%s.gbff' % self.getStr('RefBase')
            else: gbfile = '%s.gb' % self.getStr('RefBase')
            ## ~ [1b] Establish whether Genbank processing of RefGenome needs to be performed ~~~~~ ##
            rungb = False   # Whether to run rje_genbank on RefGenome
            gbcheck = ['gene.fas','prot.fas','Feature.tdt']
            if string.split(self.getStr('RefGenome'),'.')[-1] in ['gb','gbk','gbff']: gbcheck.append('full.fas')
            for rfile in gbcheck:
                gfile = '%s.%s' % (self.getStr('RefBase'),rfile)
                self.printLog('#CHECK','%s: %s' % (gfile,{True:'Found.',False:'Missing!'}[os.path.exists(gfile)]))
                rungb = rungb or not os.path.exists(gfile)
                checkfiles.append(gfile)
            self.bugPrint('Run Genbank: %s' % rungb)
            #i# NOTE: If *.gb (and *.gbk) file missing, Genbank will not be run but can still use manual features table.
            if not rje.exists(gbfile): rungb = False
            ## ~ [1b] Run Genbank to process sequence data if required ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            if rungb:
                gcmd = ['protacc=locus_tag','details=product,gene_synonym,note,db_xref']   # Defaults
                gcmd += self.cmd_list   # Can over-ride/add. This include spcode=X
                gcmd += ['seqin=%s' % gbfile,'taxdir=','tabout=T','fasout=full,gene,cds,prot']
                rje_genbank.GenBank(self.log,gcmd).run()
                for cfile in checkfiles:
                    if not rje.exists(cfile): raise IOError('Cannot find %s! Genbank processing failure?' % cfile)
            ## ~ [1c] Check for existence of Features file. Could be manually created ~~~~~~~~~~~~~ ##
            ftfile = '%s.Feature.tdt' % self.getStr('RefBase')
            self.setBool({'Features':os.path.exists(ftfile)})       # Whether features table generated/found
            self.bugPrint('Features: %s' % self.getBool('Features'))
            ## ~ [1d] Check sequence naming and offer reformatting options ~~~~~~~~~~~~~~~~~~~~~~~~ ##
            #!# Need to add reformatting here #!#
            if string.split(self.getStr('RefGenome'),'.')[-1] in ['gb','gbk','gbff']:  # Look for *.fas
                self.setStr({'RefGenome':'%s.fas' % self.getStr('RefBase')})
            if not rje.exists(self.getStr('RefGenome')) or open(self.getStr('RefGenome'),'r').readline()[:1] != '>':
                self.printLog('#REF','%s missing or not recognised fasta.' % self.getStr('RefGenome'))
                if rje.exists('%s.full.fas' % self.getStr('RefBase')):
                    self.printLog('#NAMES','%s.full.fas sequence names will not be suitable.' % self.getStr('RefBase'))
                    #!# Add option to rename manually #!#
                    if self.i() >=0 and rje.yesNo('Modify gene names now?'):
                        tmpseqlist = rje_seqlist.SeqList(self.log,self.cmd_list+['seqin=%s.full.fas' % self.getStr('RefBase'),'autoload=T','seqmode=file'])
                        self.setStr({'RefGenome':'%s.fas' % self.getStr('RefBase')})
                        if rje.yesNo('Auto-rename with incrementing %s (refchr=X)?' % self.getStr('RefChr')):
                            tmpseqlist.setStr({'NewAcc':'None'})
                            tmpseqlist.setStr({'NewGene':self.getStr('RefChr')})
                            tmpseqlist.setStr({ 'SeqOut':self.getStr('RefGenome') })
                            tmpseqlist.setBool({'AutoFilter':False})
                            tmpseqlist.rename(genecounter=True)
                        else:
                            if not self.yesNo('Manually edit gene names with consistent labels (e.g. ChrX)'):
                                self.printLog('#NAMES','Please modify gene names in %s.full.fas (e.g. ChrX) and save as %s.fas.' % (self.getStr('RefBase'),self.getStr('RefBase')))
                                self.printLog('#NAMES','Then re-run with refgenome=%s.fas.' % self.getStr('RefBase'))
                                return False
                            tmpseqlist.edit()
                            os.rename(tmpseqlist.getStr('EditFile'),self.getStr('RefGenome'))
                        self.printLog('#REF','Reference genome replaced with renamed fasta file: %s' % self.getStr('RefGenome'))
                    else:
                        self.printLog('#NAMES','Please modify gene names in %s.full.fas (e.g. ChrX) and save as %s.fas.' % (self.getStr('RefBase'),self.getStr('RefBase')))
                        self.printLog('#NAMES','Then re-run with refgenome=%s.fas.' % self.getStr('RefBase'))
                if not rje.exists(self.getStr('RefGenome')): return False
            self.printLog('#REF','Reference genome fasta: %s' % self.getStr('RefGenome'))
            if not rje.exists(self.getStr('RefGenome')): raise IOError('Cannot find RefGenome: %s!' % self.getStr('RefGenome'))

            ### ~ [2] Assembly ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            if not rje.exists(self.getStr('Assembly')): raise IOError('Cannot find Assembly: %s!' % self.getStr('Assembly'))
            while True:
                assseqlist = rje_seqlist.SeqList(self.log,self.cmd_list+['seqin=%s' % self.getStr('Assembly'),'autoload=T','seqmode=file'])
                ## ~ [2a] Check assembly gene names. Should be unique. ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
                #?# Should not match Reference either?
                #!# Add reformatting of assembly genes if not acceptable.
                #!# Add checking versus reference genes if required.
                assgenes = []   # These should be unique for later processing
                goodnames = True
                while assseqlist.nextSeq():
                    gnspacc = rje.matchExp('^(\S+)_(\S+)__(\S+)',assseqlist.seqName())
                    agene = assseqlist.seqGene()
                    if agene in assgenes or not gnspacc:
                        self.debug('%s -> %s: %s %s' % (assseqlist.seqName(), agene, agene in assgenes, gnspacc))
                        self.printLog('#NAMES','%s sequence names will not be suitable.' % self.getStr('Assembly'))
                        if self.i() < 0 or rje.yesNo('Rename sequences using newacc=X and newchr=X?'):
                            #i# Rename sequences
                            if not assseqlist.getStrLC('SpCode'): assseqlist.setStr({'SpCode':'PAGSAT'})
                            if not assseqlist.getStrLC('NewAcc'): newacc = rje.baseFile(self.getStr('Assembly'),True).upper()
                            else: newacc = assseqlist.getStr('NewAcc')
                            if not newacc.endswith('.'): newacc = '%s.' % newacc
                            assseqlist.setStr({'NewAcc':newacc})
                            assseqlist.setStr({'NewGene':self.getStr('NewChr')})
                            assseqlist.setStr({'SeqOut':'%s.renamed.fas' % self.baseFile()}) # rje.baseFile(self.getStr('Assembly'),True)})
                            self.setStr({ 'Assembly':assseqlist.getStr('SeqOut') })
                            assseqlist.setBool({'AutoFilter':False})
                            assseqlist.rename(genecounter=True)
                            self.printLog('#ASSFAS','Assembly replaced with renamed fasta file: %s' % self.getStr('Assembly'))
                            goodnames = False
                            break
                        self.printLog('#NAMES','Please modify gene names in %s to be unique (e.g. CtgX) and re-run.' % (self.getStr('Assembly')))
                        return False
                    else: assgenes.append(agene)
                if goodnames: break
            ## ~ [2b] Check for QV data and perform QV filtering ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            qvfile = '%s.qv.csv' % rje.baseFile(self.getStr('Assembly'))    # QV data file
            qvcut = self.getInt('MinQV')                                    # QV cutoff
            abase = rje.baseFile(self.getStr('Assembly'),strip_path=True)   # Assembly basefile
            qvbase = '%s.QV/%s.qv%d' % (abase,abase,qvcut)                  # QV-filtered assembly basefile
            qvfas = '%s.fas' % (qvbase)                                     # QV-filtered assembly fasta file
            if rje.exists(qvfile) and not self.force() and rje.exists(qvfas): self.setStr({'Assembly':qvfas})
            if rje.exists(qvfile) and (self.force() or not rje.exists(qvfas)):
                qdb = self.db().addTable(qvfile,['contig_id'],name='QV')
                qdb.dataFormat({'mean_coverage':'num','mean_qv':'num'})
                qdb.addFields(['Contig','Seq','Len','QStart','QEnd'])
                assseqlist = rje_seqlist.SeqList(self.log,self.cmd_list+['seqin=%s' % self.getStr('Assembly'),'autoload=T','seqmode=file','usecase=T'])
                qx = 0
                while assseqlist.nextSeq():
                    seqname = assseqlist.seqName()
                    sname = assseqlist.shortName()
                    for qentry in qdb.entries():
                        if '%s|' % qentry['contig_id'] in seqname:
                            if qentry['Seq']: raise ValueError('Multiple QV sequence mapping error! (%s)' % seqname)
                            qentry['Seq'] = assseqlist.obj['Current']; qentry['Contig'] = sname
                            qentry['QEnd'] = qentry['Len'] = assseqlist.seqLen()
                            qentry['QStart'] = 1
                            if sname in self.dict['QV']: raise ValueError('Multiple QV sequence mapping error! (%s)' % seqname)
                            self.dict['QV'][sname] = qentry['mean_qv']; qx += 1
                if qx != qdb.entryNum(): raise ValueError('Only %d of %d QV values mapped to sequences!' % (qx,qdb.entryNum()))
                if qx != assseqlist.seqNum(): raise ValueError('%d QV values but %d sequences!' % (qx,assseqlist.seqNum()))
                # Filter qdb on XCov and/or QV and see if entries lost
                lencut = self.getInt('MinContigLen')
                qvcutlen = 0
                dropped = []
                for qentry in qdb.sortedEntries('Contig'):
                    if qentry['mean_qv'] < qvcut:
                        self.printLog('#MINQV','%s failed to meet QV>=%d: %.3f kb; XCov=%s; QV=%s' % (qentry['Contig'],qvcut,qentry['Len']/1000.0,rje.sf(qentry['mean_coverage'],3),rje.sf(qentry['mean_qv'],3)))
                        qvcutlen += qentry['Len']
                        qentry['QStart'] = qentry['Qend'] = 0
                        dropped.append(qentry)
                        #qdb.dropEntry(qentry)
                    elif qentry['Len'] < lencut:
                        self.printLog('#MINLEN','%s failed to meet Len>=%d: %.3f kb; XCov=%s; QV=%s' % (qentry['Contig'],lencut,qentry['Len']/1000.0,rje.sf(qentry['mean_coverage'],3),rje.sf(qentry['mean_qv'],3)))
                        qvcutlen += qentry['Len']
                        qentry['QStart'] = qentry['Qend'] = 0
                        dropped.append(qentry)
                        #qdb.dropEntry(qentry)
                    else:
                        self.printLog('#QV','%s: %.3f kb; XCov=%s; QV=%s' % (qentry['Contig'],qentry['Len']/1000.0,rje.sf(qentry['mean_coverage'],3),rje.sf(qentry['mean_qv'],3)))
                if dropped or self.getBool('CaseFilter'):
                    self.printLog('#QV','%d of %d contigs (%.2f kb) fail to meet QV>=%d' % (len(dropped),qx,qvcutlen/1000.0,qvcut))
                    rje.mkDir(self,qvbase)
                    if rje.exists(qvfas) and not self.force():
                        self.printLog('#QV','QVFas file found (force=F): %s' % qvfas)
                        QVFAS = None
                    else:
                        # Make new Assembly file in new directory. BASEFILE.Assembly.QVX
                        rje.backup(self,qvfas)
                        QVFAS = open(qvfas,'w')
                    sx = 0; trimx = 0
                    for qentry in qdb.entries():
                        seq = qentry['Seq']
                        (name,sequence) = assseqlist.getSeq(seq)
                        if self.getBool('CaseFilter'):
                            i = 0; slen = j = len(sequence)
                            while i < len(sequence) and sequence[i] == sequence[i].lower(): i += 1
                            while j and sequence[j-1] == sequence[j-1].lower(): j -= 1
                            name = name + ' QVTrimmed:%d-%d' % (i+1,j)
                            sequence = sequence[i:j]
                            qentry['QStart'] = i+1
                            qentry['QEnd'] = j
                            trimx += slen - len(sequence)
                            if len(sequence) != slen: self.printLog('#TRIM','%s: %s bp QV trimmed.' % (assseqlist.shortName(seq),rje.iStr(slen-len(sequence))))
                            if len(sequence) < lencut: self.printLog('#TRIM','%s: %s bp QV trimmed => now too short!' % (assseqlist.shortName(seq),rje.iStr(slen-len(sequence)))); continue
                            if not sequence: self.warnLog('No quality (upper case) sequence for %s!' % name); continue
                        if QVFAS: QVFAS.write('>%s\n%s\n' % (name, sequence)); sx += 1
                    if self.getBool('CaseFilter'):
                        self.printLog('#TRIM','Total assembly QV trimmed: %.3f kb' % (trimx/1000.0))
                    if QVFAS:
                        QVFAS.close()
                        self.printLog('\r#OUT','%s of %s sequences output to %s.' % (sx,assseqlist.seqNum(),qvfas))
                        # Save qdb too!
                        qdb.saveToFile('%s.qv.csv' % qvbase)
                    self.setStr({'Assembly':qvfas})
                else: self.printLog('#QV','%d of %d contigs meet QV>=%d' % (qdb.entryNum(),qx,qvcut))
            else: self.printLog('#QV','%s not found: no QV filtering/reporting/' % qvfile)
            ## ~ [2c] Check for SAM file or rid.tdt file for depth plot data ~~~~~~~~~~~~~~~~~~~~~~ ##
            assbase = rje.baseFile(self.getStr('Assembly'))
            if self.getBool('MapFas') and assbase.endswith('.map') and (self.i() < 0 or rje.yesNo('Assembly file seems to be a mapping output file (*.map.fasta): switch mapfas=F')):
                self.printLog('#CMD','Assembly file seems to be a mapping output file (*.map.fasta): switched mapfas=F')
                self.setBool({'MapFas':False})
            samfile = '%s.sam' % assbase
            ridfile = '%s.rid.tdt' % assbase
            depfile = '%s.depthplot.tdt' % assbase
            if self.i() > -1 and not (rje.exists(samfile) or rje.exists(ridfile) or rje.exists(depfile)):
                if not rje.yesNo('SAM, RID or depthplot.tdt file needed for read depth plots. (Not found.) Proceed without them (not required), copy files into assembly directory first, or "N" to Quit. Proceed?'):
                    return False
            if rje.exists(samfile) or rje.exists(ridfile) or rje.exists(depfile):
                #!# Why is this not picking up the files in the assembly directory? Had to move to run directory!
                #!# SAMTools is stripping path. Why? Something to do with conflicting RID files in different modes? Give different names? #!#
                samcmd = ['seqin=%s' % self.getStr('Assembly'),'readcheck=%s' % samfile,'depthplot=T','control=None','treatment=None','basefile=%s' % assbase,'readlen=%s' % (rje.exists(samfile) or rje.exists(ridfile))]
                rje_samtools.SAMtools(self.log,self.cmd_list+samcmd).run()

            ### ~ [3] Report on Key settings ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            self.printLog('#INPUT','Assembly file: %s' % self.getStr('Assembly'))
            self.printLog('#INPUT','Reference genome file: %s' % self.getStr('RefGenome'))
            self.printLog('#INPUT','Reference genbank file: %s.gb' % self.getStr('RefBase'))
            minloclen = self.getInt('MinLocLen')
            self.printLog('#PARAM','Min. local BLAST alignment length: %sbp ("L%d")' % (rje.iStr(minloclen),minloclen))
            minlocid = self.getNum('MinLocID')
            if minlocid > 99: minlocid = minlocid * 10
            self.printLog('#PARAM','Min. local BLAST alignment %%identity: %s%% ("ID%d")' % (rje.sf(self.getNum('MinLocID'),3),int(minlocid)))
            if not self.baseFile(return_none=None):
                self.baseFile('%s.%s' % (rje.baseFile(self.getStr('Assembly'),strip_path=True),rje.baseFile(self.getStr('RefGenome'),strip_path=True)))
            basedir = rje.makePath('%s.PAGSAT/' % self.baseFile())
            gabdir = rje.makePath('%s.GABLAM/' % self.baseFile())
            rje.mkDir(self,basedir)
            rje.mkDir(self,gabdir)
            self.setStr({'GABLAMDir':gabdir,'ResDir':basedir,'BaseBase':os.path.basename(self.baseFile())})
            self.printLog('#GABDIR',self.getStr('GABLAMDir'))   # Directory for GABLAM and BLAST output
            self.printLog('#PAGDIR',self.getStr('ResDir'))      # Directory for PAGSAT output
            # Primary basefile is PAGSAT directory with additional cut-off information added
            if self.getStr('Mapper') == 'minimap':
                self.baseFile('%s%s.paf.L%dID%d' % (basedir,os.path.basename(self.baseFile()),minloclen,int(minlocid)))
            else: self.baseFile('%s%s.L%dID%d' % (basedir,os.path.basename(self.baseFile()),minloclen,int(minlocid)))
            self.setStr({'CutBase':os.path.basename(self.baseFile())})
            self.printLog('#BASE',self.getStr('BaseBase'))      # Root basefile
            self.printLog('#PAGOUT','%s.*' % self.baseFile())   # Primary output basefile
            if self.baseFile() != self.fileBase(): raise ValueError('Dev problem! Please report. Avoid use of basefile=X.')
            self.db().basefile(self.basefile())
            return True     # Setup successful
        except: self.errorLog('Problem during %s setup.' % self.prog()); return False  # Setup failed
#########################################################################################################################
    def fileBase(self,resdir='Res',base='Cut',extra=None):   ### Returns appropriate file output basename
        '''
        Returns appropriate file output basename. Default should return same as self.baseFile()
        @param dir:str ['Res'] = Whether output directory is 'GABLAM' or 'Res'.
        @param base:str ['Cut'] = Whether file basename included cutoffs ('Cut') or not ('Base')
        @param extra:str [None] = Additional filename element to add to basefile.
        @return: path constructed from GABLAMDir/ResDir and CutBase/BaseBase.
        '''
        filebase = '%s%s' % (self.getStr('%sDir' % resdir),self.getStr('%sBase' % base))
        if extra: filebase = '%s.%s' % (filebase,extra)
        return filebase
#########################################################################################################################
    def restSetup(self):    ### Sets up self.dict['Output'] and associated output options if appropriate.
        '''
        Run with &rest=help for general options. Run with &rest=full to get full server output as text or &rest=format
        for more user-friendly formatted output. Individual outputs can be identified/parsed using &rest=OUTFMT for:

        coverage = main results table
        '''
        try:### ~ [0] ~ Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            for outfmt in self.restOutputOrder(): self.dict['Output'][outfmt] = 'No output generated.'
            #!# Add specific program output here. Point self.dict['Output'][&rest=X] to self.str key.
            return
        except: self.errorLog('RestSetup error')
#########################################################################################################################
    def restOutputOrder(self): return ['coverage']
#########################################################################################################################
    ### <3> ### PAGSAT GABLAM Methods                                                                                   #
#########################################################################################################################
    def runGABLAM(self,gabcmd,gtype='Reference',blastgz=True,runsnapper=False): ### Runs GABLAM with given commands and basefile, managing *blast file.
        '''
        Runs GABLAM with given commands and basefile, managing *blast file. Adds minloclen for actual run.
        >> gabcmd:list = List of GABLAM run commands. Will extract basefile from this list.
        >> gtype:str = Type of PAGSAT GABLAM search
        >> blastgz:bool [True] = whether to make/process a general BLAST file if possible. (e.g. rename and g(un)zip)
        >> runsnapper:bool [False] = whether to replace GABLAM with Snapper if snapper=T.
        '''
        try:### ~ [0] Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            self.devLog('#RUN','runGABLAM')
            #self.bugPrint(gabcmd)
            basefile = None
            for gcmd in gabcmd:
                if gcmd.startswith('basefile='): basefile = string.split(gcmd,'=',1)[1]
            if runsnapper and self.getBool('Snapper'): self.printLog('#~~#','## ~~~~~ %s Snapper ~~~~~ ##' % basefile)
            else: self.printLog('#~~#','## ~~~~~ %s GABLAM ~~~~~ ##' % basefile)
            # Set blastbase = basefile name for blast file
            if gtype == 'Self': blastbase = string.join(string.split(basefile,'.')[:-1],'.')
            else: blastbase = self.fileBase('GABLAM','Base',gtype)
            ### ~ [1] Run GABLAM, processing BLAST file as required ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            if self.pafMode():
                blastfile = '%s.paf' % blastbase
            else: blastfile = '%s.blast' % blastbase
            # Unzip file if required
            if rje.exists('%s.gz' % blastfile) and blastgz:
                os.system('gunzip %s.gz' % blastfile)
                self.printLog('#GUNZIP','%s unzipped.' % blastfile)
            # Rename BLAST file if found
            if rje.exists(blastfile) and blastbase != basefile:
                os.rename(blastfile,'%s.blast' % basefile)
                self.printLog('#BLAST','%s -> %s.blast' % (blastfile,basefile))
            elif not rje.exists(blastfile): self.printLog('#BLAST','%s not found.' % (blastfile))
            # Run GABLAM
            self.debug('%s: %s' % (runsnapper and self.getBool('Snapper'),gabcmd))
            if runsnapper and self.getBool('Snapper'): snapper.Snapper(self.log,gabcmd).run()
            else: gablam.GABLAM(self.log,gabcmd).run()

            if self.pafMode():
                # Rename BLAST file if kept
                if rje.exists('%s.paf' % basefile) and blastbase != basefile:
                    os.rename('%s.paf' % basefile,blastfile)
                    self.printLog('#PAF','%s.paf -> %s' % (basefile,blastfile))
            else:
                # Rename BLAST file if kept
                if rje.exists('%s.blast' % basefile) and blastbase != basefile:
                    os.rename('%s.blast' % basefile,blastfile)
                    self.printLog('#BLAST','%s.blast -> %s' % (basefile,blastfile))
            # (Re)zip BLAST file if required
            if rje.exists(blastfile) and blastgz:
                os.system('gzip %s' % blastfile)
                self.printLog('#GZIP','%s (re)zipped.' % blastfile)
            return True
        except: self.errorLog('%s.runGABLAM() error' % self.prog()); return False
#########################################################################################################################
    def qAssembleGABLAM(self,gtype='Reference'):   ### Generate GABLAM analyses for assembly assessment.
        '''
        Generate GABLAM analyses for assembly assessment.
        >> gtype:str ['qassemble'] = type of GABLAM to run (Reference/Assembly/Genes/Proteins/Genes.Reciprocal/Proteins.Reciprocal)
        '''
        try:### ~ [0] Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            self.devLog('#RUN','qAssembleGABLAM',debug=True)
            ## ~ [0a] Set up basefiles for outputs ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            refbase = self.getStr('RefBase')        # Used for searches of genes and proteins
            gdir = self.getStr('GABLAMDir')         # GABLAMDir. Also used as BLAST directory
            if gtype in ['Reference','Assembly','RefMap']:   # These searches used cutoff data
                gbase = self.fileBase('GABLAM','Cut',gtype)
            else:                                   # Other searches do not need cutoffs.
                gbase = self.fileBase('GABLAM','Base',gtype)
            self.printLog('#GDIR',gdir)
            rje.mkDir(self,gdir,log=True)
            ## ~ [0b] Check for existing GABLAM output files ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            if not self.force():
                runfound = True
                if gtype in ['Reference','Assembly','RefMap'] and not rje.exists('%s.hitsum.tdt' % gbase): runfound = False
                if gtype in ['Reference','Assembly','RefMap'] and not rje.exists('%s.gablam.tdt' % gbase): runfound = False
                if gtype in ['Reference','Assembly','RefMap'] and not rje.exists('%s.local.tdt' % gbase): runfound = False
                if gtype in ['Reference','Assembly','RefMap'] and not rje.exists('%s.hitsum.tdt' % (gbase)): runfound = False
                #!# Add Snapper output check for Reference and RefMap
                self.printLog('#GABLAM','%s GABLAM %s.* found: %s' % (gtype,gbase,runfound))
                if runfound: return True
            ## ~ [0c] Setup GABLAM options ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            ## Might want to set forks for speed up
            if self.getInt('Forks') < 2: self.printLog('#INFO','Consider setting forks=X to speed up multiple BLASTs.')
            ## GABLAM defaults that can be over-ridden by commandline
            gabdefault = ['makesnp=F','keepblast=T','fullblast=T','blastdir=%s' % gdir,'dismat=F','distrees=F','disgraph=F','dotplots=F']
            ## GABLAM options that must be set
            gabcmd = gabdefault + self.cmd_list + ['qassemble=T','outstats=GABLAM','qryacc=F','percres=T',
                                                   'localcut=%d' % self.getInt('MinLocLen'),'localidcut=%f' % self.getNum('MinLocID'),
                                                   'localmin=%d' % self.getInt('MinLocLen'),'localidmin=%f' % self.getNum('MinLocID'),
                                                   'basefile=%s' % gbase]
            fascmd = ['fasout=T','fragfas=T','combinedfas=T','localcut=0','localmin=0','localidcut=0','localidmin=0']

            ### ~ [1] Perform different GABLAM searches ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            # 1. QAssemble GABLAM of the reference genome against the assembly to get full genome coverage.
            if gtype in ['Reference','RefMap']:
                if self.getBool('Snapper'):
                    #i# Note that Snapper performs the GABLAM search "backwards" which is a bit confusing!
                    gcmd = ['seqin=%s' % self.getStr('Assembly'),'reference=%s' % self.getStr('RefGenome'),'dna=T','blastp=blastn']
                    #!# Possibly add SNP Frequency output at some point? #!#
                    if gtype in ['Reference']: gabcmd = ['localsam=T'] + gabcmd
                    gcmd = ['nocopyfas=F'] + gcmd + ['reftype=both']
                    self.runGABLAM(gabcmd + gcmd,gtype,runsnapper=True)
                else:
                    gcmd = ['seqin=%s' % self.getStr('RefGenome'),'searchdb=%s' % self.getStr('Assembly'),'dna=T','blastp=blastn','dotplots=%s' % self.getBool('DotPlots'),'dotlocalmin=%s' % self.getInt('MinLocLen')]
                    self.runGABLAM(gabcmd + gcmd,gtype)
            # 2. QAssemble GABLAM of the assembly versus reference genome to assess assembly accuracy in terms of excess sequence.
            if gtype == 'Assembly':
                gcmd = ['seqin=%s' % self.getStr('Assembly'),'searchdb=%s' % self.getStr('RefGenome'),'dna=T','blastp=blastn']
                self.runGABLAM(gabcmd + gcmd,gtype)
            # 3. QAssemble GABLAM of the reference genes (from Genbank annotation) to assess accuracy in terms of annotated features.
            if gtype == 'Genes':
                fasdir = '%s.GeneHits/' % gbase
                gabcmd = ['localsam=T'] + gabcmd
                gcmd = fascmd + ['seqin=%s.gene.fas' % refbase,'searchdb=%s' % self.getStr('Assembly'),'dna=T','blastp=blastn','fasdir=%s.GeneHits/'% gbase,'reftype=hit','fragrevcomp=F','dotplots=F']
                self.runGABLAM(gabcmd + gcmd,gtype)
                if rje.exists(fasdir) and self.getBool('GeneTar'):
                    rje.targz(self,fasdir)
                    rje.deleteDir(self,fasdir,contentsonly=False,confirm=self.i() > 1,report=True)
            # Perform Fragments search of hit genes
            if gtype == 'Genes.Fragments':
                gcmd = ['localcut=0','seqin=%s.gene.fas' % refbase,'searchdb=%s.fas' % gbase[:-10],'dna=T','blastp=blastn','fragrevcomp=F','dotplots=F']
                self.runGABLAM(gabcmd + gcmd,gtype)
            # Perform Reciprocal search of hit genes
            if gtype == 'Genes.Reciprocal':
                gcmd = ['localcut=0','searchdb=%s.gene.fas' % refbase,'seqin=%s.fas' % gbase[:-11],'dna=T','blastp=blastn','fragrevcomp=F','dotplots=F']
                self.runGABLAM(gabcmd + gcmd,gtype)
            # 4. QAssemble GABLAM of the reference proteins (from Genbank annotation) to assess accuracy in terms of proteome coverage.
            if gtype == 'Proteins':
                fasdir = '%s.ProtHits/' % gbase
                gcmd = fascmd + ['seqin=%s.prot.fas' % refbase,'searchdb=%s' % self.getStr('Assembly'),'blastp=tblastn','fasdir=%s.ProtHits/'% gbase,'fragrevcomp=F','dotplots=F']
                self.runGABLAM(gabcmd + gcmd,gtype)
                if rje.exists(fasdir) and self.getBool('GeneTar'):
                    rje.targz(self,fasdir)
                    rje.deleteDir(self,fasdir,contentsonly=False,confirm=self.i() > 1,report=True)
            # 5. Perform Fragments search of hit protein-coding sequences by proteins
            if gtype == 'Proteins.Fragments':
                gcmd = ['localcut=0','seqin=%s.prot.fas' % refbase,'searchdb=%s.fas' % gbase[:-10],'blastp=tblastn','fragrevcomp=F','dotplots=F']
                self.runGABLAM(gabcmd + gcmd,gtype)
            # 6. Perform Reciprocal search of hit protein-coding sequences versus proteins
            #Q# Should these be translated first?
            if gtype == 'Proteins.Reciprocal':
                gcmd = ['localcut=0','searchdb=%s.prot.fas' % refbase,'seqin=%s.fas' % gbase[:-11],'blastp=blastx','fragrevcomp=F','dotplots=F']
                self.runGABLAM(gabcmd + gcmd,gtype)
        except: self.errorLog('%s.qAssembleGABLAM error' % self.prog())
#########################################################################################################################
    def selfQAssemble(self,genome=None):    ### Runs QAssemble GABLAM against self.
        '''
        Runs QAssemble GABLAM against self.
        >> genome:str = Genome to self QAssemble. Uses self.getStr('RefGenome') if None.
        << selfdb = Database Object with HitSum and Local tables loaded.
        '''
        try:### ~ [0] Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            self.devLog('#RUN','selfQAssemble',debug=False)
            if not genome: genome = self.getStr('RefGenome')
            #if self.getStr('Mapper') == 'minimap':
            if self.pafMode():
                genbase = '%s.paf.L%dID%d' % (rje.baseFile(genome),self.getInt('MinLocLen'),self.getInt('MinLocID'))
            else: genbase = '%s.L%dID%d' % (rje.baseFile(genome),self.getInt('MinLocLen'),self.getInt('MinLocID'))
            #i# This is using its own Database object
            selfdb = rje_db.Database(self.log,self.cmd_list+['basefile=%s' % genbase])
            ## ~ [1] Check for existing run data ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            if not self.force():
                hdb = selfdb.addTable(mainkeys=['Qry'],name='hitsum',expect=False)
                gdb = selfdb.addTable(mainkeys=['Qry','Hit'],name='gablam',expect=False)
                ldb = selfdb.addTable(mainkeys=['Qry','Hit','AlnNum'],name='local',expect=False)
                if hdb and ldb and gdb: return selfdb
            ## ~ [2] Run GABLAM ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            ## Might want to set forks for speed up
            if self.getInt('Forks') < 2: self.printLog('#INFO','Consider setting forks=X to speed up multiple BLASTs.')
            ## Process reference gb file if required and find genome, genes and proteins
            blastdir = rje.makePath(os.path.dirname(genbase))
            gabdefault = ['keepblast=T','fullblast=T','blastdir=%s' % blastdir,'dismat=F','distrees=F','disgraph=F','dotplots=F']
            ## GABLAM options that must be set
            gabcmd = gabdefault + self.cmd_list + ['qassemble=T','outstats=GABLAM','qryacc=F','percres=T']
            gabcmd += ['seqin=%s' % genome,'dna=T','blastp=blastn','basefile=%s' % genbase,'selfhit=T','selfsum=T',
                       'localmin=%d' % self.getInt('MinLocLen'),'localidmin=%f' % self.getNum('MinLocID'),
                       'localcut=%d' % self.getInt('MinLocLen'),'localidcut=%f' % self.getNum('MinLocID'),
                       'localsam=T','reftype=hit','reference=%s' % genome]
            if self.getBool('Snapper'): gabcmd += ['makesnp=F']
            self.runGABLAM(gabcmd,'Self')
            hdb = selfdb.addTable(mainkeys=['Qry'],name='hitsum',expect=False)
            gdb = selfdb.addTable(mainkeys=['Qry','Hit'],name='gablam',expect=False)
            ldb = selfdb.addTable(mainkeys=['Qry','Hit','AlnNum'],name='local',expect=False)
            if hdb and ldb and gdb: return selfdb
            else: return None
        except: self.errorLog('%s.selfQAssemble error' % self.prog()); return None
#########################################################################################################################
    def disMatrixOut(self,gtables=[]): ### Output BLAST GABLAM distance matrix and Tree.
        '''
        Output BLAST GABLAM distance matrix and Tree.
        >> gtables:list [] = List of GABLAM summary tables to combine into dismatrix and tree.
        '''
        try:### ~ [0] ~ Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            self.devLog('#RUN','disMatrixOut',debug=False)
            self.printLog('#~~#','## ~~~~~~~~~~~~~~~~~~~~~~~~~ PAGSAT Identity Matrix/Tree ~~~~~~~~~~~~~~~~~~~~~~~~~ ##')
            gablam = rje_dismatrix.DisMatrix(self.log,self.cmd_list+['basefile=%s' % self.baseFile()])
            gablam.setStr({'Name':'%s GABLAM' % self.baseFile()})
            diskey = 'Qry_AlnID'
            namedict = {}
            spcode = None

            ### ~ [1] ~ Generate and output DisMatrix ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            for table in gtables:
                #self.debug(self.printLog('#DIS','Adding distances from %s' % table.name()))
                if not table: raise ValueError('Problem with PacBio dismatrix tables: %s' % gtables)
                table.dataFormat({diskey:'float','Hit_AlnID':'float'})
                for entry in table.entries():
                    if not spcode: spcode = string.split(entry['Qry'],'_')[1]
                    gablam.addDis(entry['Qry'],entry['Hit'],100.0-entry[diskey])
                    # Ref vs Assembly needs to be added both ways round
                    if not gablam.getDis(entry['Hit'],entry['Qry']): gablam.addDis(entry['Hit'],entry['Qry'],100.0-entry['Hit_AlnID'])
                    #self.debug('%s vs %s (%s & %s)' % (entry['Qry'],entry['Hit'],gablam.getDis(entry['Qry'],entry['Hit']),gablam.getDis(entry['Hit'],entry['Qry'])))
                    # Add to namedict
                    if entry['Qry'] not in namedict:
                        slen = float(entry['QryLen'])
                        if slen > 1e6: namedict[entry['Qry']] = '%s (%.2f Mb)' % (entry['Qry'],slen/1e6)
                        elif slen > 1e3: namedict[entry['Qry']] = '%s (%.2f kb)' % (entry['Qry'],slen/1e3)
                        else: namedict[entry['Qry']] = '%s (%.3f kb)' % (entry['Qry'],slen/1e3)
                        if entry['Qry'] in self.dict['QV']: namedict[entry['Qry']] = '%s; QV=%s)' % (namedict[entry['Qry']][:-1],rje.sf(self.dict['QV'][entry['Qry']],3))
                    if entry['Hit'] not in namedict:
                        slen = float(entry['HitLen'])
                        if slen > 1e6: namedict[entry['Hit']] = '%s (%.2f Mb)' % (entry['Hit'],slen/1e6)
                        elif slen > 1e3: namedict[entry['Hit']] = '%s (%.2f kb)' % (entry['Hit'],slen/1e3)
                        else: namedict[entry['Hit']] = '%s (%.3f kb)' % (entry['Hit'],slen/1e3)
                        if entry['Hit'] in self.dict['QV']: namedict[entry['Hit']] = '%s; QV=%s)' % (namedict[entry['Hit']][:-1],rje.sf(self.dict['QV'][entry['Hit']],3))
            if self.getBool('DisMatrix'): gablam.saveMatrix(filename='%s.dismatrix.csv' % self.baseFile())

            ### ~ [2] ~ Make DisMatrix symmetrical on mean difference and generate tree ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            gablam.forceSymmetry(method='mean',missing=100.0)
            self.setNum({'MST':gablam.MST()})
            ## ~ [2a] ~ Generate tree outputs ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            if self.dev() and self.debugging(): defaults = ['savetype=none','treeformats=nwk,text,png,r']
            else: defaults = ['savetype=none','treeformats=nwk,png']
            upgma = rje_tree.Tree(self.log,['savetype=none','treeformats=nwk,text,png,r']+self.cmd_list+['autoload=F'])
            nsftree = gablam.upgma()
            upgma.buildTree(nsftree,type='nsf',postprocess=False)
            self.printLog('#TREE','Total TreeLen=%s; MST=%s' % (rje.sf(upgma.treeLen(),3),rje.sf(gablam.MST(),3)))
            for node in upgma.node:
                if node.info['Name'] in namedict: node.info['Name'] = namedict[node.info['Name']]
            upgma.basefile(self.basefile())
            upgma.info['GroupSpecies'] = spcode
            self.printLog('#SPEC','Looking for tree duplications based on %s' % spcode)
            upgma.opt['QueryGroup'] = True
            rje_tree_group._dupGroup(upgma,useseq=False) #.findDuplicationsNoSeq(spcode)
            upgma.saveTrees()
            #gablam.savePNG(upgma)
        except: self.errorLog('Major problem with %s.disMatrixOut' % self)
#########################################################################################################################
    ### <4> ### PAGSAT Assessment Methods                                                                               #
#########################################################################################################################
    def pureMapFas(self):   ### Generate partial GABLAM analyses and assembly fasta mapping.
        '''Generate partial GABLAM analyses and assembly fasta mapping.'''
        try:### ~ [0] Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            self.devLog('#RUN','mapfas')
            self.printLog('#~~#','## =========================== PAGSAT FASTA MAPPING MODE ============================ ##')
            db = self.db()
            if not self.force():
                wanted = ['map.fasta']  #i# *.fasta for SAMTools etc.
                complete = True
                for wext in wanted:
                    wfile = '%s.%s' % (self.baseFile(),wext)
                    self.printLog('#CHECK','%s: %s.' % (wfile,os.path.exists(wfile)))
                    complete = complete and os.path.exists(wfile)
                if complete:
                    self.printLog('#SKIP','Fasta mapping found (force=F).')
                    return True

            #i# This is a reduced assessment run that only needs to compare the assembly to the reference
            #i# unidirectionally: we are interested in where the dominant unique matches of the assembled contigs match.


            ## ~ [0a] Load & Summarise Sequence files ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            # Read in reference and assembly to seqlists then combine in Sequences table
            # Generate summary tables: db('Sequences'): ['name','desc','gene','spec','accnum','length'],['name']
            self.obj['Reference'] = refseqlist = rje_seqlist.SeqList(self.log,self.cmd_list+['seqin=%s' % self.getStr('RefGenome'),'autoload=T','seqmode=filedb'])
            self.obj['Reference'].summarise(sumdb=True,save=False)
            refseqlist.saveSeq(seqfile='%s.combined.fas' % self.baseFile(),append=False,backup=False)
            self.obj['Assembly'] = assseqlist = rje_seqlist.SeqList(self.log,self.cmd_list+['seqin=%s' % self.getStr('Assembly'),'autoload=T','seqmode=filedb'])
            self.obj['Assembly'].summarise(sumdb=True,save=False)
            assseqlist.saveSeq(seqfile='%s.combined.fas' % self.baseFile(),append=True,backup=False)
            seqdb = db.addEmptyTable('Sequences',['Locus','Name','Chrom','Spec','Length','Source','Desc'],['Locus'])
            oldfields = ['name','desc','gene','spec','accnum','length']
            newfields = ['Name','Desc','Chrom','Spec','Locus','Length']
            for seqobj in ['Reference','Assembly']:
                objdb = self.obj[seqobj].db('sequences')
                for i in range(len(oldfields)): objdb.renameField(oldfields[i],newfields[i],log=False)
                objdb.addField('Source',evalue=seqobj)
                for entry in objdb.entries(): seqdb.addEntry(entry)
            seqdb.indexReport('Source')
            #x#seqdb.saveToFile()
            #?# Does this need any additional data? Could combine with Coverage files? Maybe "BestMatch" field? And/or ChromID?
            #?# Should Chrom be I-XVI and Contig be the full name? Or have ChromID be I-XVI ?
            #!# Add ChromID and data from the *.coverage.tdt files.
            #!# Will need a method to extract chromosome ID. Will have trouble with numbers, so stick to I-XVI for now?
            #!# Can add other letter/numbering systems later. May not need to keep genes unique once R script updated.

            ### ~ [1] All-by-all GABLAM files including Reciprocal Self-Searches ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            #i# NOTE: Cannot do a combined reference+assembly self-GABLAM as QAssemble stats would be messed up.
            #i# This is actually better in some ways as reference self-search can be re-used!
            ## ~ [1c] Load/Generate Reference versus Assembly GABLAM Tables ~~~~~~~~~~~~~~~~~~~~~~~ ##
            self.printLog('#~~#','## ~~~~~~~~~~~~~~~~~~~~ Assembly vs Reference GABLAM Searches ~~~~~~~~~~~~~~~~~~~~ ##')
            gbase = self.fileBase('GABLAM','Cut')
            db.baseFile(gbase)
            # Look to add QAssemble GABLAM tables: run qAssembleGABLAM() if force/missing.
            #i# I think this is the only one we need for mapfas output
            #self.qAssembleGABLAM('Reference')
            #success = self.db(table='Reference.hitsum',add=True,forcecheck=True,mainkeys=['Qry'])
            #success = success and self.db(table='Reference.gablam',add=True,forcecheck=True,mainkeys=['Qry','Hit'])
            #success = success and self.db(table='Reference.local',add=True,forcecheck=True,mainkeys=['Qry','Hit','AlnNum'])
            success = True
            if self.getBool('Snapper'):
                self.qAssembleGABLAM('RefMap')
                success = success and self.db(table='RefMap.unique',add=True,forcecheck=True,mainkeys=['Query','Hit','AlnID'])
                if not success: raise IOError('Failed to generate %s.RefMap Snapper' % self.db().baseFile())
                self.db('RefMap.unique').rename('RefSnap.local')
                self.db('RefSnap.local').renameField('AlnID','AlnNum')
                self.db('RefSnap.local').renameField('Query','Qry')
                # Want to use this for the *.assembly.png images. This is mapping contigs onto chromosomes?
                # Therefore want to swap Query and Hit? Or do we want to make contig assembly files too? (Yes)
                # Therefore we need two versions of the table:
                # |-- 1. The unique contigs mapped onto Reference
                # |-- 2. The "clean" unique mapping data that has good chromosomes for each contig.
                #       -> This one will want to have the non-unique Chrom Hits in place of "HitNum"
                refsnapdb = db.copyTable(self.db('RefSnap.local'),'AssSnap.local')
                for entry in refsnapdb.entries():
                    (entry['Qry'],entry['Hit']) = (entry['Hit'],entry['Qry'])
                    (entry['QryStart'],entry['SbjStart']) = (entry['SbjStart'],entry['QryStart'])
                    (entry['QryEnd'],entry['SbjEnd']) = (entry['SbjEnd'],entry['QryEnd'])
                    if int(entry['QryEnd']) < int(entry['QryStart']):
                        (entry['QryStart'],entry['QryEnd']) = (entry['QryEnd'],entry['QryStart'])
                        (entry['SbjStart'],entry['SbjEnd']) = (entry['SbjEnd'],entry['SbjStart'])
                refsnapdb.remakeKeys()
                #refsnapdb.indexReport('Qry')
                #self.db('RefSnap.local').indexReport('Qry')
                #self.debug('<<REF|ASS>>')
                #self.db('AssSnap.local').indexReport('Qry')
                #self.debug('?')
                #!# Swap Qry and Hit fields
                #!# Change use of Unique below
            else:
                self.qAssembleGABLAM('Assembly')
                success = self.db(table='Assembly.hitsum',add=True,forcecheck=True,mainkeys=['Qry'])
                success = success and self.db(table='Assembly.local',add=True,forcecheck=True,mainkeys=['Qry','Hit','AlnNum'])
                if not success: raise IOError('Failed to generate %s.Assembly GABLAM' % self.db().baseFile())

            #if not self.getBool('Snapper'): db.copyTable(self.db('Assembly.local'),'Unique.local')
            # Format local tables
            minloclen = self.getInt('MinLocLen')
            self.printLog('#LOCLEN','Checking local hits for len < %d' % minloclen)
            minid = self.getNum('MinLocID') / 100.0
            self.printLog('#LOCID','Checking local hits for identity < %s' % minid)
            if self.getBool('Snapper'): loctables = ['AssSnap']
            else: loctables = ['Assembly']
            for ctype in loctables:
                locdb = self.db('%s.local' % ctype)
                locdb.dataFormat({'Length':'int','Identity':'int','QryStart':'int','QryEnd':'int','SbjStart':'int','SbjEnd':'int'})
                locdb.dropField('Positives')
                locdb.makeField('1.0*Identity/Length','Local')
                for entry in locdb.entries():
                    if entry['Local'] < minid:  self.bugPrint(entry)
                    if entry['Length'] < minloclen:  self.bugPrint(entry)
                #self.debug('%s: %s' % (locdb,locdb.indexEntries('Qry','fcu03_MBGISH__FC170203U.03')))
                predropx = locdb.entryNum()
                #if self.dev():
                #    locdb.dropEntries(['Local<%f' % minid,'Length<%d' % minloclen],inverse=True,log=True,logtxt='Removing poor local hits')
                #    self.debug(locdb.entries())
                locdb.dropEntries(['Local<%f' % minid,'Length<%d' % minloclen],inverse=False,log=True,logtxt='Removing poor local hits')
                if predropx != locdb.entryNum(): self.warnLog('%s poor local hits removed. (Expected if running on V1.x data.)' % rje.iStr(predropx-locdb.entryNum()),quitchoice=False)


            ### ~ [5] Contig-Chromosome Mapping ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            ## ~ [5a] Directional coverage of Assembly Contigs ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            #># 'Qry','Pos','FwdHitAln','FwdChrom','RevHitAln','RevChrom','HitChrom','Class'
            #x#self.dirnCoveragePlot('Assembly')
            #i# Now use Unique.local for assembly dircov etc. Will be from Snapper if called, else is Assembly.local.
            self.obj['Ass'] = self.obj['Assembly']
            self.obj['Ref'] = self.obj['Reference']
            if self.getBool('Snapper'):
                self.dirnCoveragePlot('AssSnap')
            else: self.dirnCoveragePlot('Assembly')
            ## ~ [5b] Table of unique mapping based on sorted dircov tables ~~~~~~~~~~~~~~~~~~~~~~~ ##
            #i# Needs tuplekeys=T for sorting.
            #i# This is currently used for assembly tidy mapping. Sorts out mapping and direction based on dirnCoveragePlot().
            maptables = ['Assembly']
            if self.getBool('Snapper'):
                maptables = ['AssSnap']
                self.printLog('#MAP','Using Snapper unique.tdt data for Assembly.mapping')
            for ctype in maptables:
                ctgdb = self.db('%s.dircov' % ctype)
                if ctype == 'RefRec': mapdb = db.addEmptyTable('RefBench.mapping',['Qry','Chrom','Fwd','Rev'],['Qry','Chrom'])
                else: mapdb = db.addEmptyTable('Assembly.mapping',['Qry','Chrom','Fwd','Rev'],['Qry','Chrom'])
                for contig in ctgdb.index('Qry'):
                    ckeys = ctgdb.index('Qry')[contig][0:]
                    while ckeys:    # These should be in pairs!
                        cstart = cend = ctgdb.data(ckeys.pop(0))
                        if cstart['Class'] != 'U': continue
                        while ckeys and ctgdb.data(ckeys[0])['HitChrom'] == cstart['HitChrom'] and ctgdb.data(ckeys[0])['Class'] == 'U':
                            cend = ctgdb.data(ckeys.pop(0))
                        if (len(string.split(cstart['HitChrom'],';')) + cstart['FwdChrom'] + cstart['RevChrom']) != 2:
                            raise ValueError(cstart)
                        if (len(string.split(cend['HitChrom'],';')) + cend['FwdChrom'] + cend['RevChrom']) != 2:
                            raise ValueError(cend)
                        # Now have a region mapping to a single chromosome
                        chrom = cstart['HitChrom']
                        cpair = (contig,chrom)
                        mentry = mapdb.data(cpair)
                        if not mentry: mentry = mapdb.addEntry({'Qry':contig,'Chrom':chrom,'Fwd':0,'Rev':0})
                        mentry['Fwd'] += (cend['Pos'] - cstart['Pos'] + 1) * cstart['FwdChrom']
                        mentry['Rev'] += (cend['Pos'] - cstart['Pos'] + 1) * cstart['RevChrom']
                ## Update with Unique rating and Rank to use for mapping.
                mapdb.makeField(formula='Fwd+Rev',fieldname='Unique')
                mapdb.dropEntries('Unique<%d' % self.getInt('MinUnique'))
                mapdb.rankFieldByIndex('Qry','Unique',newfield='Rank',rev=True,absolute=True,lowest=True)
                mapdb.makeField(formula='Fwd-Rev',fieldname='Dirn') #i# Will be <0 if Bwd match best
                mapdb.dataFormat({'Fwd':'int','Rev':'int','Unique':'int','Dirn':'int'})
                mapdb.saveToFile()

            ### ~ [6] Update Sequences Table ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            #i# This uses the Assembly.mapping file to add MapDirn to sequences table.
            seqdb = self.db('Sequences')
            seqdb.setFields(string.split('Locus,Name,Chrom,MapChrom,MapUniq,MapDirn,Spec,Source,Desc,HitNum,MaxScore,EVal,Length,Coverage,Identity,Positives,Missing,Different,Perfect',','))
            ## ~ [6b] Add MapChrom ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            for sentry in seqdb.entries():
                if sentry['Source'] == 'Reference': continue
                else: mapdb = self.db('Assembly.mapping')
                for mentry in mapdb.entries():
                    if mentry['Qry'] != sentry['Name']: continue
                    if mentry['Rank'] > 1: continue
                    if sentry['MapChrom']: self.warnLog('%s maps to two MapChrom equally!' % sentry['Name']); continue
                    sentry['MapChrom'] = string.split(mentry['Chrom'],'_')[0]
                    #i# Unique gets the unique mapped nucloetides for the top ranked match. (Not sure what benefit this is!)
                    sentry['MapUniq'] = mentry['Unique']
                    sentry['MapDirn'] = 'Fwd'
                    if mentry['Dirn'] < 0: sentry['MapDirn'] = 'Rev'
                # Fill in Orphans
                if not sentry['MapChrom']:
                    sentry['MapChrom'] = 'Orphan'
                    sentry['MapUniq'] = 0
                    sentry['MapDirn'] = 'NA'
            seqdb.saveToFile()

            ### ~ [7] Generate MapFas output ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            if self.getBool('MapFas'): self.mapFas() #i# *.fasta for SAMTools etc.

        except: self.errorLog('%s.pureMapFas error' % self.prog())
#########################################################################################################################
    def assessment(self):   ### Generate GABLAM analyses and summarise assembly assessment.
        '''Generate GABLAM analyses and summarise assembly assessment.'''
        try:### ~ [0] Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            self.devLog('#RUN','assessment')
            self.printLog('#~~#','## =========================== PAGSAT ASSESSMENT MODE ============================ ##')
            db = self.db()
            if not self.force():
                wanted = ['Summary.tdt',    # Summary delimited text file of coverage etc.
                          'Sequences.tdt',  # Sequence Summary and ID xref file.
                          'png']            # Summary tree of assembly vs reference chromosomes.
                if self.getBool('ChromAlign'): wanted.append('ChromAlign.tdt')
                if self.getBool('OrderedFas'): wanted.append('ordered.fas')
                if self.getBool('MapFas'): wanted.append('map.fasta') #i# *.fasta for SAMTools etc.
                complete = True
                for wext in wanted:
                    wfile = '%s.%s' % (self.baseFile(),wext)
                    self.printLog('#CHECK','%s: %s.' % (wfile,os.path.exists(wfile)))
                    complete = complete and os.path.exists(wfile)
                if self.getBool('GeneSummary'):
                    sumdb = self.db('Summary',add=True,mainkeys=['Summary'])
                    self.printLog('#CHECK','Genes summary: %s.' % (sumdb and sumdb.data('Genes')))
                    complete = complete and sumdb and sumdb.data('Genes')
                if self.getBool('ProtSummary'):
                    sumdb = self.db('Summary',add=True,mainkeys=['Summary'])
                    self.printLog('#CHECK','Proteins summary: %s.' % (sumdb and sumdb.data('Proteins')))
                    complete = complete and sumdb and sumdb.data('Proteins')
                if complete:
                    self.printLog('#SKIP','Assessment run found (force=F).')
                    if self.getBool('RGraphics'): return self.rGraphics()
                    return True
            ## ~ [0a] Load & Summarise Sequence files ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            # Read in reference and assembly to seqlists then combine in Sequences table
            # Generate summary tables: db('Sequences'): ['name','desc','gene','spec','accnum','length'],['name']
            self.obj['Reference'] = refseqlist = rje_seqlist.SeqList(self.log,self.cmd_list+['seqin=%s' % self.getStr('RefGenome'),'autoload=T','seqmode=filedb'])
            self.obj['Reference'].summarise(sumdb=True,save=False)
            refseqlist.saveSeq(seqfile='%s.combined.fas' % self.baseFile(),append=False,backup=False)
            self.obj['Assembly'] = assseqlist = rje_seqlist.SeqList(self.log,self.cmd_list+['seqin=%s' % self.getStr('Assembly'),'autoload=T','seqmode=filedb'])
            self.obj['Assembly'].summarise(sumdb=True,save=False)
            assseqlist.saveSeq(seqfile='%s.combined.fas' % self.baseFile(),append=True,backup=False)
            seqdb = db.addEmptyTable('Sequences',['Locus','Name','Chrom','Spec','Length','Source','Desc'],['Locus'])
            oldfields = ['name','desc','gene','spec','accnum','length']
            newfields = ['Name','Desc','Chrom','Spec','Locus','Length']
            for seqobj in ['Reference','Assembly']:
                objdb = self.obj[seqobj].db('sequences')
                for i in range(len(oldfields)): objdb.renameField(oldfields[i],newfields[i],log=False)
                objdb.addField('Source',evalue=seqobj)
                for entry in objdb.entries(): seqdb.addEntry(entry)
            seqdb.indexReport('Source')
            #x#seqdb.saveToFile()
            #?# Does this need any additional data? Could combine with Coverage files? Maybe "BestMatch" field? And/or ChromID?
            #?# Should Chrom be I-XVI and Contig be the full name? Or have ChromID be I-XVI ?
            #!# Add ChromID and data from the *.coverage.tdt files.
            #!# Will need a method to extract chromosome ID. Will have trouble with numbers, so stick to I-XVI for now?
            #!# Can add other letter/numbering systems later. May not need to keep genes unique once R script updated.

            ### ~ [1] All-by-all GABLAM files including Reciprocal Self-Searches ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            #i# NOTE: Cannot do a combined reference+assembly self-GABLAM as QAssemble stats would be messed up.
            #i# This is actually better in some ways as reference self-search can be re-used!
            ## ~ [1a] Reference All-by-all (including self-assessment benchmark) ~~~~~~~~~~~~~~~~~~ ##
            self.printLog('#~~#','## ~~~~~~~~~~~~~~~~~~~~~~~~ Reference self-GABLAM Search ~~~~~~~~~~~~~~~~~~~~~~~~~ ##')
            checkdb = self.selfQAssemble()
            if not checkdb: raise ValueError('Reference self-GABLAM failure.')
            for table in ['hitsum','local','gablam']:
                tdb = checkdb.getTable(table)
                tdb.setStr({'Name':'RefRec.%s' % table})
                #!# NOTE: RefRec.hitsum will become RefBench.coverage
                tdb.baseFile(self.baseFile())
                db.list['Tables'].append(tdb)
            ## ~ [1b] Assembly All-by-all for dismatrix and tree ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            self.printLog('#~~#','## ~~~~~~~~~~~~~~~~~~~~~~~~~ Assembly self-GABLAM Search ~~~~~~~~~~~~~~~~~~~~~~~~~ ##')
            checkdb = self.selfQAssemble(self.getStr('Assembly'))
            if not checkdb: raise ValueError('Assembly self-GABLAM failure.')
            for table in ['hitsum','local','gablam']:
                tdb = checkdb.getTable(table)
                tdb.setStr({'Name':'AssRec.%s' % table})
                tdb.baseFile(self.baseFile())
                db.list['Tables'].append(tdb)
            #?# Does keeping all these files cause memory issues?
            ## ~ [1c] Load/Generate Reference versus Assembly GABLAM Tables ~~~~~~~~~~~~~~~~~~~~~~~ ##
            self.printLog('#~~#','## ~~~~~~~~~~~~~~~~~~~~ Assembly vs Reference GABLAM Searches ~~~~~~~~~~~~~~~~~~~~ ##')
            gbase = self.fileBase('GABLAM','Cut')
            db.baseFile(gbase)
            # Look to add QAssemble GABLAM tables: run qAssembleGABLAM() if force/missing.
            self.qAssembleGABLAM('Reference')
            success = self.db(table='Reference.hitsum',add=True,forcecheck=True,mainkeys=['Qry'])
            success = success and self.db(table='Reference.gablam',add=True,forcecheck=True,mainkeys=['Qry','Hit'])
            success = success and self.db(table='Reference.local',add=True,forcecheck=True,mainkeys=['Qry','Hit','AlnNum'])
            if self.getBool('Snapper'):
                success = success and self.db(table='Reference.unique',add=True,forcecheck=True,mainkeys=['Query','Hit','AlnID'])
                if not success: raise IOError('Failed to generate %s.Reference Snapper' % self.db().baseFile())
                self.db('Reference.unique').rename('RefSnap.local')
                self.db('RefSnap.local').renameField('AlnID','AlnNum')
                self.db('RefSnap.local').renameField('Query','Qry')
                # Want to use this for the *.assembly.png images. This is mapping contigs onto chromosomes?
                # Therefore want to swap Query and Hit? Or do we want to make contig assembly files too? (Yes)
                # Therefore we need two versions of the table:
                # |-- 1. The unique contigs mapped onto Reference
                # |-- 2. The "clean" unique mapping data that has good chromosomes for each contig.
                #       -> This one will want to have the non-unique Chrom Hits in place of "HitNum"
                refsnapdb = db.copyTable(self.db('RefSnap.local'),'AssSnap.local')
                for entry in refsnapdb.entries():
                    (entry['Qry'],entry['Hit']) = (entry['Hit'],entry['Qry'])
                    (entry['QryStart'],entry['SbjStart']) = (entry['SbjStart'],entry['QryStart'])
                    (entry['QryEnd'],entry['SbjEnd']) = (entry['SbjEnd'],entry['QryEnd'])
                    if int(entry['QryEnd']) < int(entry['QryStart']):
                        (entry['QryStart'],entry['QryEnd']) = (entry['QryEnd'],entry['QryStart'])
                        (entry['SbjStart'],entry['SbjEnd']) = (entry['SbjEnd'],entry['SbjStart'])
                refsnapdb.remakeKeys()
                #refsnapdb.indexReport('Qry')
                #self.db('RefSnap.local').indexReport('Qry')
                #self.debug('<<REF|ASS>>')
                #self.db('AssSnap.local').indexReport('Qry')
                #self.debug('?')
                #!# Swap Qry and Hit fields
                #!# Change use of Unique below
            elif not success: raise IOError('Failed to generate %s.Reference GABLAM' % self.db().baseFile())
            self.qAssembleGABLAM('Assembly')
            success = self.db(table='Assembly.hitsum',add=True,forcecheck=True,mainkeys=['Qry'])
            success = success and self.db(table='Assembly.local',add=True,forcecheck=True,mainkeys=['Qry','Hit','AlnNum'])
            if not success: raise IOError('Failed to generate %s.Assembly GABLAM' % self.db().baseFile())
            #if not self.getBool('Snapper'): db.copyTable(self.db('Assembly.local'),'Unique.local')
            # Format local tables
            minloclen = self.getInt('MinLocLen')
            self.printLog('#LOCLEN','Checking local hits for len < %d' % minloclen)
            minid = self.getNum('MinLocID') / 100.0
            self.printLog('#LOCID','Checking local hits for identity < %s' % minid)
            loctables = ['RefRec','AssRec','Reference','Assembly']
            if self.getBool('Snapper'): loctables += ['RefSnap','AssSnap']
            for ctype in loctables:
                locdb = self.db('%s.local' % ctype)
                locdb.dataFormat({'Length':'int','Identity':'int','QryStart':'int','QryEnd':'int','SbjStart':'int','SbjEnd':'int'})
                locdb.dropField('Positives')
                locdb.makeField('1.0*Identity/Length','Local')
                for entry in locdb.entries():
                    if entry['Local'] < minid:  self.bugPrint(entry)
                    if entry['Length'] < minloclen:  self.bugPrint(entry)
                #self.debug('%s: %s' % (locdb,locdb.indexEntries('Qry','fcu03_MBGISH__FC170203U.03')))
                predropx = locdb.entryNum()
                #if self.dev():
                #    locdb.dropEntries(['Local<%f' % minid,'Length<%d' % minloclen],inverse=True,log=True,logtxt='Removing poor local hits')
                #    self.debug(locdb.entries())
                locdb.dropEntries(['Local<%f' % minid,'Length<%d' % minloclen],inverse=False,log=True,logtxt='Removing poor local hits')
                if predropx != locdb.entryNum(): self.warnLog('%s poor local hits removed. (Expected if running on V1.x data.)' % rje.iStr(predropx-locdb.entryNum()),quitchoice=False)

            ## ~ [1d] Read in gene and protein results ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            ftbase = self.fileBase('GABLAM','Base')
            db.baseFile(ftbase)
            #i# NOTE: Reciprocal Gene and Protein searches have been disabled for now as not that useful.
            if self.getBool('GeneSummary'):
                self.qAssembleGABLAM('Genes')
                self.db(table='Genes.hitsum',add=True,forcecheck=True,mainkeys=['Qry'])
                self.qAssembleGABLAM('Genes.Fragments')    # Used only for TopHits Analysis
                #self.qAssembleGABLAM('Genes.Reciprocal')
                self.db(table='Genes.Reciprocal.hitsum',add=True,forcecheck=True,mainkeys=['Qry'])
            if self.getBool('ProtSummary'):
                self.qAssembleGABLAM('Proteins')            # Used only for TopHits Analysis
                self.db(table='Proteins.hitsum',add=True,forcecheck=True,mainkeys=['Qry'])
                self.qAssembleGABLAM('Proteins.Fragments')  # Used only for TopHits Analysis
                #self.qAssembleGABLAM('Proteins.Reciprocal')
                self.db(table='Proteins.Reciprocal.hitsum',add=True,forcecheck=True,mainkeys=['Qry'])
            db.baseFile(self.baseFile())
            for table in db.tables(): table.baseFile(self.baseFile())

            ### ~ [2] Optional outputs of attempted alignments and/or contig ordering ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            ## ~ [2a] OrderedFas output ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            #i# Order assembly contigs and reference by matches (based on biggest local alignments)
            if self.getBool('OrderedFas') or self.getBool('ChromAlign'): self.orderedFas()
            ## ~ [2b] Chromosome-Contig Alignments ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            #i# Attempts to align each contig to its best chromosome based on ordered local BLAST hits. Not that great!
            adb = self.db(table='ChromAlign',add=True,forcecheck=True,mainkeys=['Chrom'])
            if self.getBool('ChromAlign') and not adb: self.chromAlign(diploid=self.getBool('Diploid'))

            ### ~ [3] Generate Summary Tables, Charts and Statistics ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            self.printLog('#~~#','## ~~~~~~~~~~~~~~~~~~~~~~~~~~~ PAGSAT Summary Tables ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##')
            ## ~ [3a] Generate Distance Matrix and Tree ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            # Think about how best to make the distance matrix and tree. Add an assembly self-QAssemble and combine?
            self.disMatrixOut([self.db('Reference.gablam'),self.db('RefRec.gablam'),self.db('AssRec.gablam')])
            ## ~ [3b] Generate Summary Table ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            self.pagsatSummary()

            ### ~ [4] Generate coverage plotting data ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            self.obj['Ass'] = self.obj['Assembly']
            self.obj['Ref'] = self.obj['Reference']
            self.coveragePlot('Reference')
            self.coveragePlot('Assembly')
            if self.getBool('Snapper'):
                self.coveragePlot('RefSnap')
                self.coveragePlot('AssSnap')

            ### ~ [5] Contig-Chromosome Mapping ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            ## ~ [5a] Directional coverage of Assembly Contigs ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            #># 'Qry','Pos','FwdHitAln','FwdChrom','RevHitAln','RevChrom','HitChrom','Class'
            #x#self.dirnCoveragePlot('Assembly')
            #i# Now use Unique.local for assembly dircov etc. Will be from Snapper if called, else is Assembly.local.
            if self.getBool('Snapper'):
                self.dirnCoveragePlot('AssSnap')
            else: self.dirnCoveragePlot('Assembly')
            self.dirnCoveragePlot('RefRec')
            ## ~ [5b] Table of unique mapping based on sorted dircov tables ~~~~~~~~~~~~~~~~~~~~~~~ ##
            #i# Needs tuplekeys=T for sorting.
            #i# This is currently used for assembly tidy mapping. Sorts out mapping and direction based on dirnCoveragePlot().
            maptables = ['Assembly','RefRec']
            if self.getBool('Snapper'):
                maptables = ['AssSnap','RefRec']
                self.printLog('#MAP','Using Snapper unique.tdt data for Assembly.mapping')
            for ctype in maptables:
                ctgdb = self.db('%s.dircov' % ctype)
                if ctype == 'RefRec': mapdb = db.addEmptyTable('RefBench.mapping',['Qry','Chrom','Fwd','Rev'],['Qry','Chrom'])
                else: mapdb = db.addEmptyTable('Assembly.mapping',['Qry','Chrom','Fwd','Rev'],['Qry','Chrom'])
                for contig in ctgdb.index('Qry'):
                    ckeys = ctgdb.index('Qry')[contig][0:]
                    while ckeys:    # These should be in pairs!
                        cstart = cend = ctgdb.data(ckeys.pop(0))
                        if cstart['Class'] != 'U': continue
                        while ckeys and ctgdb.data(ckeys[0])['HitChrom'] == cstart['HitChrom'] and ctgdb.data(ckeys[0])['Class'] == 'U':
                            cend = ctgdb.data(ckeys.pop(0))
                        if (len(string.split(cstart['HitChrom'],';')) + cstart['FwdChrom'] + cstart['RevChrom']) != 2:
                            raise ValueError(cstart)
                        if (len(string.split(cend['HitChrom'],';')) + cend['FwdChrom'] + cend['RevChrom']) != 2:
                            raise ValueError(cend)
                        # Now have a region mapping to a single chromosome
                        chrom = cstart['HitChrom']
                        cpair = (contig,chrom)
                        mentry = mapdb.data(cpair)
                        if not mentry: mentry = mapdb.addEntry({'Qry':contig,'Chrom':chrom,'Fwd':0,'Rev':0})
                        mentry['Fwd'] += (cend['Pos'] - cstart['Pos'] + 1) * cstart['FwdChrom']
                        mentry['Rev'] += (cend['Pos'] - cstart['Pos'] + 1) * cstart['RevChrom']
                ## Update with Unique rating and Rank to use for mapping.
                mapdb.makeField(formula='Fwd+Rev',fieldname='Unique')
                mapdb.dropEntries('Unique<%d' % self.getInt('MinUnique'))
                mapdb.rankFieldByIndex('Qry','Unique',newfield='Rank',rev=True,absolute=True,lowest=True)
                mapdb.makeField(formula='Fwd-Rev',fieldname='Dirn') #i# Will be <0 if Bwd match best
                mapdb.dataFormat({'Fwd':'int','Rev':'int','Unique':'int','Dirn':'int'})
                mapdb.saveToFile()

            ### ~ [5] Generate additional summary of Gene and Protein Top Hits using Ref features ~~~~~~~~~~~~~~~~~~~ ###
            self.topHits()

            ### ~ [6] Update Sequences Table ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            seqdb = self.db('Sequences')
            seqdb.setFields(string.split('Locus,Name,Chrom,MapChrom,MapUniq,MapDirn,Spec,Source,Desc,HitNum,MaxScore,EVal,Length,Coverage,Identity,Positives,Missing,Different,Perfect',','))
            #i# Will need to add ChromID once this is being parsed/used
            ## ~ [6a] Incorporate Coverage Data ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            covtables = ['Assembly','Reference']
            #X# if self.getBool('Snapper'): covtables += ['AssSnap','RefSnap']
            #i# These are modified hitsum tables and have not been made with Snapper-filtered data.
            for ctype in covtables:
                ctable = self.db('%s.coverage' % ctype)
                if not ctable: raise ValueError('%s.coverage table missing!' % ctype)
                # Qry	HitNum	MaxScore	EVal	Description	Length	Coverage	Identity	Positives	Missing	Different	Perfect
                # -> Locus	Name	Chrom   Spec	Length	Source	Desc
                # => Locus,Name,Chrom,Spec,Source,Desc,HitNum,MaxScore,EVal,Length,Coverage,Identity,Positives,Missing,Different,Perfect
                for sentry in seqdb.entries():
                    if sentry['Source'] != ctype: continue
                    # Get correct Coverage entry
                    centry = ctable.data(sentry['Name'])
                    if not centry:
                        self.warnLog('Sequence "%s" not found in %s.coverage table!' % (sentry['Name'],ctype))
                        continue
                    # Check details
                    if sentry['Length'] != centry['Length']: self.warnLog('Length mismatch for "%s" in Sequences vs %s.coverage tables!' % (sentry['Name'],ctype))
                    if sentry['Desc'] != centry['Description']: self.warnLog('Description mismatch for "%s" in Sequences vs %s.coverage tables!' % (sentry['Name'],ctype))
                    # Update sentry
                    for field in string.split('HitNum,MaxScore,EVal,Coverage,Identity,Positives,Missing,Different,Perfect',','):
                        sentry[field] = centry[field]
            ## ~ [6b] Add MapChrom ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            for sentry in seqdb.entries():
                if sentry['Source'] == 'Reference': mapdb = self.db('RefBench.mapping')
                else: mapdb = self.db('Assembly.mapping')
                for mentry in mapdb.entries():
                    if mentry['Qry'] != sentry['Name']: continue
                    if mentry['Rank'] > 1: continue
                    if sentry['MapChrom']: self.warnLog('%s maps to two MapChrom equally!' % sentry['Name']); continue
                    sentry['MapChrom'] = string.split(mentry['Chrom'],'_')[0]
                    #i# Unique gets the unique mapped nucloetides for the top ranked match. (Not sure what benefit this is!)
                    sentry['MapUniq'] = mentry['Unique']
                    sentry['MapDirn'] = 'Fwd'
                    if mentry['Dirn'] < 0: sentry['MapDirn'] = 'Rev'
                # Fill in Orphans
                if not sentry['MapChrom']:
                    sentry['MapChrom'] = 'Orphan'
                    sentry['MapUniq'] = 0
                    sentry['MapDirn'] = 'NA'
            seqdb.saveToFile()

            ### ~ [7] Generate MapFas output ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            if self.getBool('MapFas'): self.mapFas() #i# *.fasta for SAMTools etc.

            ### ~ [8] Generate R Graphics ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            if self.getBool('RGraphics'): return self.rGraphics()

            #!# Generate Excel file - #!# Move this to report output? Generate at end of everything?
            if self.dev() and False:
                try:
                    import XlsxWriter
                    #!# Add code here
                except: self.errorLog('XlsxWriter not on system: no Excel output')

        except: self.errorLog('%s.assessment error' % self.prog())
#########################################################################################################################
    def mapFas(self):   ### Generates Revcomp-updated assembly file based on Mapping
        '''
        Generates Revcomp-updated assembly file based on Mapping. Uses MapDirn in self.db('Sequences').
        Also updates the coverage plot tables.
        '''
        try:### ~ [0] Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            self.printLog('#~~#','## ~~~~~ PAGSAT Mapped Contig Output ~~~~~ ##')
            seqdb = self.db('Sequences')    #i# Key is Locus = AccNum
            #># Locus	Name	Chrom	MapChrom	MapUniq	MapDirn	Spec	Source	Desc	HitNum	MaxScore	EVal
            #># Length	Coverage	Identity	Positives	Missing	Different	Perfect
            seqlist = self.obj['Assembly']
            seqlist.obj['Current'] = None
            ## ~ [0a]  Setup fasta output ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            mapfas = '%s.map.fasta' % self.baseFile()   #rje.baseFile(self.getStr('Assembly'))
            rje.backup(self,mapfas)
            MAPFAS = open(mapfas,'w')
            locmap = {}

            ### ~ [1] Work through contigs and output to file ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            mx = 0; rx = 0
            while seqlist.nextSeq():
                try:
                    acc = seqlist.seqAcc()
                    seqname = seqlist.seqName()
                    sequence = seqlist.seqSequence()
                    sentry = seqdb.data(acc)
                    #self.debug(sentry)
                    if sentry['MapDirn'] == 'Rev':
                        newacc = string.split(acc,'.')
                        newacc[-1] = 'R' + newacc[-1]
                        #self.debug(newacc)
                        newacc = string.join(newacc,'.')
                        newname = '%sR_%s__%s RevComp %s' % (sentry['Chrom'],sentry['Spec'],newacc,sentry['Desc'])
                        self.printLog('#MAPFAS','%s -> %s' % (acc,newname))
                        MAPFAS.write('>%s\n%s\n' % (newname,rje_sequence.reverseComplement(sequence))); mx += 1; rx += 1
                        locmap[string.split(seqname)[0]] = string.split(newname)[0]
                        locmap[acc] = string.split(newname)[0]
                    else:
                        MAPFAS.write('>%s\n%s\n' % (seqname,sequence)); mx += 1
                        locmap[string.split(seqname)[0]] = string.split(seqname)[0]
                        locmap[acc] = string.split(seqname)[0]
                except: self.errorLog('MapFas failure processing contig: %s' % seqlist.seqName())
            self.printLog('#MAPFAS','%s (%s RevComp) sequences output to %s.' % (rje.iStr(mx),rje.iStr(rx),mapfas))
            MAPFAS.close()

            ### ~ [2] Load and update coverage.tdt and depthplot.tdt ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            covtdt = '%s.coverage.tdt' % rje.baseFile(self.getStr('Assembly'))
            # Locus	Length	MeanX	MinX	MaxX	MedianX - Locus
            deptdt = '%s.depthplot.tdt' % rje.baseFile(self.getStr('Assembly'))
            # Locus	Pos	X - Locus,Pos
            if rje.exists(covtdt) and rje.exists(deptdt):
                self.printLog('#MAPCOV','Updating coverage and depthplot data for mapped fasta file.')
                mapdb = rje_db.Database(self.log,self.cmd_list+['tuplekeys=T'])
                try: mapdb.baseFile('%s.map' % self.baseFile()) #rje.baseFile(self.getStr('Assembly')))
                except:
                    self.errorLog('Odd baseFile() error!')
                    mapdb.setStr({'Basefile':'%s.map' % rje.baseFile(self.getStr('Assembly'))})
                ## ~ [2a] Coverage ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
                covdb = mapdb.addTable(filename=covtdt,mainkeys=['Locus'],name='coverage',expect=True)
                covdb.dataFormat({'Length':'int'})
                for entry in covdb.entries():
                    if not entry['Locus']:
                        self.warnLog('Empty locus removed from coverage table.')
                        covdb.dropEntry(entry); continue
                    if entry['Locus'] not in locmap:
                        locus = string.split(entry['Locus'],'.')
                        locus[-1] = locus[-1][-1] + locus[-1][:-1]
                        entry['Locus'] = string.join(locus,'.')
                    try: entry['Locus'] = locmap[entry['Locus']]
                    except: self.warnLog('Locus "%s" not found in locmap! Might have coverage plot issues.' % entry['Locus'])
                covdb.remakeKeys()
                covdb.saveToFile()
                ## ~ [2b] Depth Plot ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
                depdb = mapdb.addTable(filename=deptdt,mainkeys=['Locus','Pos'],name='depthplot',expect=True)
                depdb.dataFormat({'Length':'int','Pos':'int'})
                for locus in rje.sortKeys(depdb.index('Locus')):
                    if not locus:
                        for entry in depdb.indexEntries('Locus',locus): depdb.dropEntry(entry)
                        continue
                    maploc = locus  # Need to keep locus for indexEntries() below.
                    if locus not in locmap:
                        maploc = string.split(maploc,'.')
                        maploc[-1] = locus[-1][-1] + maploc[-1][:-1]
                        maploc = string.join(maploc,'.')
                    try: newloc = locmap[maploc]
                    except:
                        self.warnLog('Locus "%s" not found in locmap! Might have depth plot issues.' % locus)
                        newloc = locus
                    loclen = covdb.data(newloc)['Length']
                    for entry in depdb.indexEntries('Locus',locus):
                        entry['Locus'] = newloc
                        entry['Pos'] = loclen - entry['Pos'] + 1
                depdb.remakeKeys()
                depdb.saveToFile()

            ### ~ [FUTURE] Load and update other tdt files! ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###

        except:
            self.errorLog('%s.mapFas error' % self.prog())
            try: MAPFAS.close(); self.warnLog('Open %s file closed. (Likely incomplete)' % mapfas)
            except: pass
            return False
#########################################################################################################################
    def orderedFas(self):   ### Generates Ordered Fasta output if OrderedFas=T
        '''Generates Ordered Fasta output if OrderedFas=T.'''
        try:### ~ [0] Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            self.devLog('#RUN','orderedFas')
            self.warnLog('Ordered Fasta output is currently not being maintained. Please report bugs.')
            #!# Update this to use Unique.tdt local table instead #!#
            refseqlist = self.obj['Reference']
            assseqlist = self.obj['Assembly']
            ### ~ [1] Order assembly contigs and reference by matches (based on biggest local alignments) ~~~~~~~~~~~ ###
            self.printLog('#~~#','## ~~~~~ PAGSAT Contig Ordering ~~~~~ ##')
            locdb = self.db('Reference.local')
            # Create lists of contigs and chromosomes from seqlists
            seqdict = assseqlist.seqNameDic()
            chrom = refseqlist.names()
            contigs = assseqlist.names()
            mapping = []
            # Work through local alignments in identity (count) order for primary pairings
            for lentry in locdb.sortedEntries('Identity',reverse=True):
                if not contigs: break
                if lentry['Hit'] not in contigs: continue
                # If contig OR chromosome still in list:
                # a. Add to assembly list: (chr,start,end,contig,start,end)
                mapping.append((lentry['Qry'],lentry['QryStart'],lentry['QryEnd'],lentry['Hit'],lentry['SbjStart'],lentry['SbjEnd']))
                # b. Remove chr and contig from lists
                if lentry['Qry'] in chrom: chrom.remove(lentry['Qry'])
                if lentry['Hit'] in contigs: contigs.remove(lentry['Hit'])
            if chrom: self.printLog('#CHROM','%d reference chromosomes without primary contig hits: %s' % (len(chrom),string.join(chrom,', ')))
            else: self.printLog('#CHROM','No reference chromosomes without primary contig hits.')
            if contigs: self.printLog('#CHROM','%d assembly contigs without primary reference hits: %s' % (len(contigs),string.join(contigs,', ')))
            else: self.printLog('#CHROM','No assembly contigs without primary reference hits.')
            # Sort assembly list
            mapping.sort()
            if self.getBool('ChromAlign'): self.list['C2CMap'] = mapping[0:]
            # Cycle through chromosomes in order and output matching contigs to *.ordered.fas
            ordfile = '%s.ordered.fas' % self.baseFile()
            if self.force() or not rje.exists(ordfile):
                ordered = []
                for chrom in refseqlist.names():
                    for pair in mapping[0:]:
                        if pair[0] != chrom: continue
                        ordered.append(seqdict[pair[3]])
                        mapping.remove(pair)
                # Add (and log) any unmatched contigs to *.ordered.fas
                for seq in contigs: ordered.append(seqdict[seq])
                assseqlist.saveSeq(ordered,seqfile=ordfile)
        except: self.errorLog('%s.orderedFas error' % self.prog())
#########################################################################################################################
    def chromAlign(self,diploid=False): ### Generates PAGSAT Chrom Alignment tables
        '''Returns whether *Plots/*.summary.png has been made.'''
        try:### ~ [0] Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            self.devLog('#RUN','chromAlign')
            self.printLog('#~~#','## ~~~~~ PAGSAT Chromosome Alignments (Diploid: %s) ~~~~~ ##' % diploid)
            db = self.db()
            c2cmap = self.list['C2CMap']
            alndir = rje.makePath('%s.ALN/' % self.baseFile())
            rje.mkDir(self,alndir)
            minloclen = self.getInt('MinLocLen')
            minid = self.getNum('MinLocID') / 100.0
            refseqlist = self.obj['Reference']
            assseqlist = self.obj['Assembly']
            ### ~ [1] Reference vs Assembly local BLAST ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            ## Read BLAST into local database table including alignments
            if self.pafMode():
                blastfile = '%s.paf' % self.fileBase('GABLAM','Base','Reference')
            else: blastfile = '%s.blast' % self.fileBase('GABLAM','Base','Reference')
            # Unzip file if required
            blastgz = rje.exists('%s.gz' % blastfile)
            if blastgz:
                os.system('gunzip %s.gz' % blastfile)
                self.printLog('#GUNZIP','%s unzipped.' % blastfile)

            if self.pafMode():
                if not rje.exists(blastfile): raise IOError('#PAF','%s not found.' % (blastfile))
                #?# Will this read in the local hits table? Try it!
                blast = rje_blast.blastObj(self.log,self.cmd_list+['blastp=blastn'])
                blast.readBLAST(resfile=blastfile,clear=False,gablam=False,unlink=False,local=True,screen=True,log=False,keepaln=True)
            else:
                if not rje.exists(blastfile): raise IOError('#BLAST','%s not found.' % (blastfile))
                # Better to re-read in the original BLAST
                blast = rje_blast.blastObj(self.log,self.cmd_list+['blastp=blastn'])
                blast.readBLAST(resfile=blastfile,clear=False,gablam=False,unlink=False,local=True,screen=True,log=False,keepaln=True)
            # (Re)zip BLAST file if required
            if blastgz and rje.exists(blastfile):
                os.system('gzip %s' % blastfile)
                self.printLog('#GZIP','%s (re)zipped.' % blastfile)
            ## Use data from:
            bdb = blast.db('Local')
            self.debug(bdb.entryNum())
            # ['Query','Hit','AlnID','BitScore','Expect','Length','Identity','Positives','QryStart','QryEnd','SbjStart','SbjEnd','QrySeq','SbjSeq','AlnSeq'],
            bdb.dataFormat({'Identity':'int','QryStart':'int','QryEnd':'int','SbjStart':'int','SbjEnd':'int','Length':'int'})
            predropx = bdb.entryNum()
            bdb.dropEntries(['Length<%d' % minloclen],inverse=False,log=True,logtxt='Removing poor local hits')
            #x# Should be Identity/Length in this filter but now superseded as filter applied within GABLAM.
            #X# bdb.dropEntries(['Identity<%f' % minid,'Length<%d' % minloclen],inverse=False,log=True,logtxt='Removing poor local hits')
            if predropx != bdb.entryNum(): self.warnLog('%s poor local hits removed. Running on pre-V2.0.0 data?!' % rje.iStr(predropx-locdb.entryNum()))
            # If diploid mode, duplicate queries here >> -A and -B
            if self.getBool('Diploid') and diploid:
                for entry in bdb.entries():
                    newentry = rje.combineDict({},entry)
                    newentry['Query'] = '%s-B' % entry['Query']
                    bdb.addEntry(newentry)
                    entry['Query'] = '%s-A' % entry['Query']
                bdb.remakeKeys()
            ### ~ [2] Chromosome-Contig Alignments ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            bentries = bdb.sortedEntries('Identity',reverse=True)   # List of all entries (sorted) to process
            aentries = {}                                           # Dictionary of final entries for alignments
            alignpos = {}; ax = 0   # Dictionary of {chr/ctg:[(start,stop) list of positions included in local aln]}
            ## Process local alignments, keeping good ones and modifying the rest
            while bentries:
                entry = bentries.pop(0)     # This is best remaining hit
                ax += 1
                self.progLog('\r#LOCALN','Processing local alignments: %s -> %s' % (rje.iLen(bentries),rje.iLen(aentries)))
                entry['Qry'] = entry['Query']; entry['Sbj'] = entry['Hit']
                self.bugPrint('%s & %s' % (entry['Query'],entry['Sbj']))
                qh = 'Qry'
                if entry[qh] not in aentries: aentries[entry[qh]] = {}
                aentries[entry[qh]][entry['%sStart' % qh]] = entry
                # Update alignpos
                for qh in ['Qry','Sbj']:
                    if entry[qh] not in alignpos: alignpos[entry[qh]] = []
                    alignpos[entry[qh]].append((min(entry['%sStart' % qh],entry['%sEnd' % qh]),max(entry['%sStart' % qh],entry['%sEnd' % qh])))
                    alignpos[entry[qh]].sort()
                    i = 1
                    while i < len(alignpos[entry[qh]]):
                        if alignpos[entry[qh]][i][0] <= alignpos[entry[qh]][i-1][1]+1:
                            alignpos[entry[qh]][i-1] = (alignpos[entry[qh]][i-1][0],max(alignpos[entry[qh]][i-1][1],alignpos[entry[qh]][i][1]))
                            alignpos[entry[qh]].pop(i)
                        else: i += 1
                # Adjust/Filter remaining entries
                ex = 0
                while ex < len(bentries):
                    aentry = bentries[ex]
                    # Skip or delete if Query/Hit pair do not match
                    if entry['Query'] != aentry['Query'] and entry['Hit'] != aentry['Hit']: ex += 1; continue
                    if entry['Query'] != aentry['Query'] and entry['Hit'] == aentry['Hit']: bentries.pop(ex); continue
                    # Check for overlapping regions in Query
                    #??# What if in middle! :-(
                    #!# Need to fix this! #!#
                    dump = False
                    for (qstart,qend) in alignpos[entry['Query']]:
                        if qend < aentry['QryStart'] or qstart > aentry['QryEnd']: continue
                        if qstart <= aentry['QryStart'] and qend >= aentry['QryEnd']: dump = True; break
                        # Trim according to query positions
                        apos = 0                        # Position in alignment
                        qpos = aentry['QryStart'] - 1   # Position in query (prior to apos)
                        sdir = {True:1,False:-1}[aentry['SbjStart']<aentry['SbjEnd']]
                        spos = aentry['SbjStart'] - sdir  # Position in subject (prior to apos)
                        trimstart = aentry['QryEnd'] >= qend >= aentry['QryStart']  # and aentry['QryEnd'] >= qstart
                        trimend = aentry['QryStart'] <= qstart <= aentry['QryEnd'] #and aentry['QryStart'] <= qend
                        if (trimstart and trimend): self.bugPrint('Q: (%s,%s) vs (%s,%s)!' % (qstart,qend,aentry['QryStart'],aentry['QryEnd']))
                        while apos < len(aentry['AlnSeq']) and (trimstart or trimend):
                            if aentry['QrySeq'][apos] != '-': qpos += 1
                            if aentry['SbjSeq'][apos] != '-': spos += sdir
                            if trimstart and qpos > qend:   # Trim!
                                for qh in ['Qry','Sbj','Aln']: aentry['%sSeq' % qh] = aentry['%sSeq' % qh][apos:]
                                aentry['QryStart'] = qpos
                                aentry['SbjStart'] = spos
                                apos = 1; trimstart = False
                            elif trimend and qpos == qstart - 1:
                                for qh in ['Qry','Sbj','Aln']: aentry['%sSeq' % qh] = aentry['%sSeq' % qh][:apos+1]
                                aentry['QryEnd'] = qpos
                                aentry['SbjEnd'] = spos
                                break
                            else: apos += 1
                    if dump: bentries.pop(ex); continue
                    if entry['Query'] == aentry['Query'] and entry['Hit'] != aentry['Hit']: ex += 1; continue   # Can have 2+ contigs
                    # Check for overlapping regions in Hit
                    for (hstart,hend) in alignpos[entry['Hit']]:
                        if hend < min(aentry['SbjStart'],aentry['SbjEnd']) or hstart > max(aentry['SbjStart'],aentry['SbjEnd']): continue
                        if hstart <= min(aentry['SbjStart'],aentry['SbjEnd']) and hend >= max(aentry['SbjStart'],aentry['SbjEnd']): dump = True; continue
                        # Trim according to subject positions
                        apos = 0                        # Position in alignment
                        qpos = aentry['QryStart'] - 1   # Position in query (prior to apos)
                        sdir = {True:1,False:-1}[aentry['SbjStart']<aentry['SbjEnd']]
                        spos = aentry['SbjStart'] - sdir  # Position in subject (prior to apos)
                        if sdir > 0:    # Fwd hit
                            trimstart = aentry['SbjEnd'] >= hend >= aentry['SbjStart'] #and aentry['SbjEnd'] >= hstart
                            trimend = aentry['SbjStart'] <= hstart <= aentry['SbjEnd'] #and aentry['SbjStart'] <= hend
                            #if (trimstart and trimend): self.warnLog('(%s,%s) vs %s!' % (hstart,hend,aentry))
                            if (trimstart and trimend): self.bugPrint('Fwd: (%s,%s) vs (%s,%s)!' % (hstart,hend,aentry['SbjStart'],aentry['SbjEnd']))
                            while apos < len(aentry['AlnSeq']) and (trimstart or trimend):
                                if aentry['QrySeq'][apos] != '-': qpos += 1
                                if aentry['SbjSeq'][apos] != '-': spos += sdir
                                if trimstart and spos > hend:   # Trim!
                                    for qh in ['Qry','Sbj','Aln']: aentry['%sSeq' % qh] = aentry['%sSeq' % qh][apos:]
                                    aentry['QryStart'] = qpos
                                    aentry['SbjStart'] = spos
                                    apos = 1; trimstart = False
                                elif trimend and spos == hstart - 1:
                                    for qh in ['Qry','Sbj','Aln']: aentry['%sSeq' % qh] = aentry['%sSeq' % qh][:apos+1]
                                    aentry['QryEnd'] = qpos
                                    aentry['SbjEnd'] = spos
                                    break
                                else: apos += 1
                        else:
                            trimstart = aentry['SbjEnd'] <= hstart <= aentry['SbjStart'] #and aentry['SbjEnd'] <= hend
                            trimend = aentry['SbjStart'] >= hend >= aentry['SbjEnd'] #and aentry['SbjStart'] >= hstart
                            #if (trimstart and trimend): self.warnLog('(%s,%s) vs %s!' % (hstart,hend,aentry))
                            if (trimstart and trimend): self.bugPrint('Bwd: (%s,%s) vs (%s,%s)!' % (hstart,hend,aentry['SbjStart'],aentry['SbjEnd']))
                            while apos < len(aentry['AlnSeq']) and (trimstart or trimend):
                                if aentry['QrySeq'][apos] != '-': qpos += 1
                                if aentry['SbjSeq'][apos] != '-': spos += sdir
                                if trimstart and spos == hstart - 1:   # Trim!
                                    for qh in ['Qry','Sbj','Aln']: aentry['%sSeq' % qh] = aentry['%sSeq' % qh][apos:]
                                    aentry['QryStart'] = qpos
                                    aentry['SbjStart'] = spos
                                    apos = 1; trimstart = False
                                elif trimend and spos == hend + 1:
                                    for qh in ['Qry','Sbj','Aln']: aentry['%sSeq' % qh] = aentry['%sSeq' % qh][:apos+1]
                                    aentry['QryEnd'] = qpos
                                    aentry['SbjEnd'] = spos
                                    break
                                else: apos += 1
                    if dump: bentries.pop(ex); continue
                    ex += 1
            #self.debug(alignpos)
            self.printLog('\r#LOCALN','Processed local alignments -> %s pairwise aln.' % (rje.iStr(ax)))
            #bdb.dict['Data'] = {}
            #for entry in aentries: bdb.addEntry(entry)
            #bdb.newKey(['Query','QryStart'])
            #self.debug(bdb.dataKeys())
            ## Generate localn files:
            chrdict = refseqlist.seqNameDic()
            seqdict = assseqlist.seqNameDic()
            adb = self.db('ChromAlign')
            if not adb: adb = db.addEmptyTable('ChromAlign',['Chrom','Ctid','Type','Length','Identity','Coverage','Insertions','Deletions'],['Chrom','Ctid','Type'])
            ddb = db.addEmptyTable('ChromAlignLoc', ['Query','Hit','Ctid','AlnID','Length','Identity','QryStart','QryEnd','SbjStart','SbjEnd'],['Query','Hit','Ctid','AlnID'])
            for chrom in rje.sortKeys(aentries):
                #self.debug(chrom)
                if self.getBool('Diploid') and diploid: dentry = {'Query':chrom[:-2],'Ctid':chrom[-1]}
                else: dentry = {'Query':chrom,'Ctid':'H'}
                for entry in aentries[chrom].values():
                    #self.debug(entry)
                    #if self.getBool('Diploid') and diploid: dentry = {'Query':chrom[:-2],'Ctid':entry['Query'][-1]}
                    #else: dentry = {'Query':chrom,'Ctid':'H'}
                    ddentry = rje.combineDict({},dentry,overwrite=False)
                    ddentry = rje.combineDict(ddentry,entry,overwrite=False)
                    ddb.addEntry(ddentry)
                    #self.debug(ddentry)
                if self.getBool('Diploid') and diploid: chrseq = refseqlist.getSeq(chrdict[chrom[:-2]])
                else: chrseq = refseqlist.getSeq(chrdict[chrom])
                contigs = []
                poslist = rje.sortKeys(aentries[chrom])
                entry = aentries[chrom][poslist[0]]
                qname = string.split(entry['Query'],'__')[0]
                if self.getBool('Diploid') and diploid: qname += chrom[-2:]
                #self.debug(qname)
                aname = string.split(qname,'_')[0] + '_ALIGN'
                hname = string.split(qname,'_')[0] + '_' + string.split(entry['Hit'],'_')[1]
                qentry = {'Chrom':qname,'Type':'Reference','Ctid':dentry['Ctid']}; hentry = {'Chrom':hname,'Type':'Assembly','Ctid':dentry['Ctid']}
                qpos = 0    # Last position covered
                qseq = aseq = hseq = ''
                for spos in poslist:
                    entry = aentries[chrom][spos]
                    if entry['Hit'] not in contigs: contigs.append(entry['Hit'])
                    qname += ' %s(%s..%s)' % (string.split(entry['Qry'],'_')[-1],entry['QryStart'],entry['QryEnd'])
                    hname += ' %s(%s..%s)' % (string.split(entry['Hit'],'_')[-1],entry['SbjStart'],entry['SbjEnd'])
                    addseq = chrseq[1][qpos:entry['QryStart']]
                    if addseq:
                        qseq += addseq
                        aseq += '-' * len(addseq)
                        hseq += '.' * len(addseq)
                    if qseq: qseq += '.....'; aseq += 'XXXXX'; hseq += '.....'  # Small spacer between alignments
                    qseq += entry['QrySeq']
                    aseq += entry['AlnSeq']
                    hseq += entry['SbjSeq']
                    qpos = entry['QryEnd']
                addseq = chrseq[1][qpos:]
                if addseq:
                    qseq += addseq
                    aseq += '-' * len(addseq)
                    hseq += '.' * len(addseq)
                aseq = string.replace(aseq,' ','x')
                qentry['Length'] = len(chrseq[1])
                hentry['Length'] = 0
                for ctg in contigs: hentry['Length'] += assseqlist.seqLen(seqdict[ctg])
                qentry['Identity'] = hentry['Identity'] = string.count(aseq,'|')
                qentry['Insertions'] = hentry['Deletions'] = string.count(hseq,'-')
                qentry['Deletions'] = hentry['Insertions'] = string.count(qseq,'-')
                qentry['Coverage'] = hentry['Coverage'] = string.count(aseq,'x') + qentry['Identity'] - qentry['Insertions'] - qentry['Deletions']
                if not diploid:
                    ALNFAS = open('%s%s.aln.fas' % (alndir,chrom),'w')
                    ALNFAS.write('>%s\n%s\n' % (qname,qseq))
                    ALNFAS.write('>%s\n%s\n' % (aname,aseq))
                    ALNFAS.write('>%s\n%s\n' % (hname,hseq))
                    ALNFAS.close()
                    adb.addEntry(qentry)
                if diploid == self.getBool('Diploid'):
                    adb.addEntry(hentry)
            if diploid == self.getBool('Diploid'):
                ddb.saveToFile()
            if not diploid:
                adb.makeField('Length-Coverage','Missing',evalue=0)
                adb.makeField('Coverage-Identity','Different',evalue=0)
                adb.addField('Perfect',evalue=0)
                for entry in adb.entries():
                    if not entry['Missing'] and not entry['Different']: entry['Perfect'] = 1
                adb.compress(['Chrom'],default='sum')
                adb.dropField('Ctid')
                adb.saveToFile()
            #else: return adb

            # Build up and combine local alignments
            # >> Build up best -> Worst (BitScore), keeping if new sequences involved and trimming ends where appropriate
            # >> Fill in the gaps by splitting the shortest sequence in the middle and inserting gaps
            # Q. How to deal with inversions? RevComp and lower case?

            # Create lists of contigs and chromosomes from seqlists
            chrdict = refseqlist.seqNameDic()
            seqdict = assseqlist.seqNameDic()
            # Cycle through chromosomes in order and output matching contigs to *.ordered.fas
            for chrom in rje.sortKeys(chrdict): # refseqlist.names():
                #self.debug('%s -> %s' % (chrom,chrdict[chrom]))
                ALNFAS = open('%s%s.fas' % (alndir,chrom),'w')
                ALNFAS.write(refseqlist.fasta(chrdict[chrom]))
                for pair in c2cmap[0:]:
                    if pair[0] != chrom: continue
                    c2cmap.remove(pair)
                    if pair[-2] > pair[-1]:     # reverse!
                        (name,sequence) = assseqlist.getSeq(seqdict[pair[3]])
                        name += 'Reverse Complement'
                        #self.bugPrint(sequence[:100])
                        sequence = rje_sequence.reverseComplement(sequence)
                        #self.deBug(sequence[-100:])
                        ALNFAS.write('>%s\n%s\n' % (name,sequence))
                    else: ALNFAS.write(assseqlist.fasta(seqdict[pair[3]]))
                ALNFAS.close()
                #!# The following takes a long time and should be replaced with a better genome alignment program! (Exonerate?)
                #rje_seq.SeqList(self.log,self.cmd_list+['seqin=%s%s.fas' % (alndir,chrom),'autoload=T','autofilter=F','dna=T','align=F']).align(outfile='%s%s.aln.fas' % (alndir,chrom))
            return adb
        except: self.errorLog('%s.chromAlign error' % self.prog()); raise
#########################################################################################################################
    def pagsatSummary(self):    ### Generates PAGSAT Summary Table from HitSum tables.
        '''Generates PAGSAT Summary Table from HitSum tables.'''
        try:### ~ [0] Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            self.devLog('#RUN','pagsatSummary')
            db = self.db()
            sumtab = []     # List of hitsum tables for summary
            ## ~ [0a] Add summary columns etc. to hitsum tables and make Coverage ~~~~~~~~~~~~~~~~~ ##
            #i# 'Genes.Reciprocal' & 'Proteins.Reciprocal' currently disabled.
            for tname in ['RefRec','Reference','Assembly','Genes','Proteins']:
                table = self.db('%s.hitsum' % tname)
                if not table: continue
                if tname == 'RefRec': table.setStr({'Name':'RefBench.coverage'})
                else: table.setStr({'Name':'%s.coverage' % tname})
                self.printLog('#TABLE','### ~~~~~~~~~~~~~~~~~~~~~ %s ~~~~~~~~~~~~~~~~~~~ ###' % table.name())
                table.dataFormat({'HitNum':'int','Positives':'int','EVal':'num','Length':'int','Coverage':'int','Identity':'int'})
                table.makeField('Length-Coverage','Missing',evalue=0)
                table.makeField('Coverage-Identity','Different',evalue=0)
                table.dataFormat({'Missing':'int','Different':'int'})
                table.addField('Perfect',evalue=0)
                for entry in table.entries():
                    if not entry['Missing'] and not entry['Different']: entry['Perfect'] = 1
                #x#if tname in ['RefRec','Reference','Assembly']: table.saveToFile()
                if tname in ['RefRec']: table.saveToFile()
                table.dropFields(['CovHit','QryStart','QryEnd','Qry_AlnLen','Qry_AlnID'])
                sumtab.append(db.copyTable(table,string.replace(table.name(),'.coverage','')))
            # Add chromAlign data if performed
            adb = self.db('ChromAlign')
            if adb: fullsum = sumtab + db.splitTable(adb,'Type')
            else: fullsum = sumtab
            ### ~ [1] Output summary statistics ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            covdb = None
            for table in fullsum:
                if table not in sumtab:
                    table.dropFields(['Insertions','Deletions']); table.renameField('Chrom','Qry')
                    table.setStr({'Name':string.split(table.name(),'_')[-1]+'Align'})
                else: table.dropFields(['MaxScore','EVal','Description'])
                table.addField('N',evalue=1)
                table.addField('Summary',evalue=table.name())
                table.compress(['Summary'],default='sum')
                if table not in sumtab: table.list['Fields'] = covdb.fields()
                else: table.list['Fields'] = ['Summary'] + table.fields()[:-1]
                table.dropField('Qry')
                if covdb: db.mergeTables(covdb,table)
                else: covdb = table; table.setStr({'Name':'Summary'})
            covdb.renameField('HitNum','HitSeq')
            covdb.keepFields(['Summary','HitNum','Length','Coverage','Identity','Missing','Different','Perfect','N'])
            covdb.saveToFile()
        except: self.errorLog('%s.pagsatSummary error' % self.prog()); raise
#########################################################################################################################
    def coveragePlot(self,ctype='Reference'):    ### Generate coverage plotting data
        '''Generate coverage plotting data.'''
        try:### ~ [0] Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            self.devLog('#RUN','coveragePlot',debug=True)
            self.printLog('#~~#','## ~~~~~~~~~~~~~~~~~~~~ PAGSAT %s Coverage Plot Data ~~~~~~~~~~~~~~~~~~~~~ ##' % ctype)
            db = self.db()
            qryseqlist = self.obj[ctype[:3]]
            qryseqdict = qryseqlist.seqNameDic()   # Chromosomes to sequences
            if ctype[:3] == 'Ref': hitseqlist = self.obj['Ass']
            else: hitseqlist = self.obj['Ref']
            hitseqdict = hitseqlist.seqNameDic()
            ## ~ [0a] Setup Coverage Plot Table ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            #i# Old headers: ['Chrom','Pos','HitNum','ContigNum','Contigs', 'Class','ChromHit','ChromNum','RefChrom']
            #i# New headers: ['Qry',  'Pos','HitAln','HitSeq',   'HitChrom','Class','RecAln',  'RecSeq',  'RecChrom']
            chrdb = db.addEmptyTable('%s.covplot' % ctype,['Qry','Pos','HitAln','HitSeq','HitChrom','Class','RecAln','RecSeq','RecChrom'],['Qry','Pos'])
            ## ~ [0b] Reciprocal search local table ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            selfdb = self.db('%sRec.local' % ctype[:3])     # This is the chromosome versus chromosome plot
            ## ~ [0c] Reference vs Assembly local table ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            #?# Why is this failing for AssSnap?
            debugme = True #x#ctype == 'AssSnap'
            locdb = self.db('%s.local' % ctype)

            #!# This is having trouble for PAF mode, so work out what these tables are and document properly somewhere
            for table in [selfdb,locdb]: self.debug('%s: %d' % (table.name(),table.entryNum()))

            #i# NOTE: This used to use Reference.local for both files. The Assembly.local search would have used Hit and
            #i# SbjStart/SbjEnd rather than Qry data. In this case, SbjStart and End must be swapped if there is a
            #i# reverse hit. See PAGSAT_V1 for details.

            ### ~ [1] Generate Coverage Data for Chromosomes/Contigs ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            #i# NOTE: Some sequences may have no local BLAST hits and then end up absent from locdb.
            #i# We therefore use qryseqlist.names()
            for chrom in qryseqlist.names():     # locdb.index('Qry'):    # Should be the same for both.
                chromlen = qryseqlist.seqLen(qryseqdict[chrom])
                posdict = {1:{},chromlen:{}}    # Dictionary of all local alignment boundaries : {contig:[starts]}
                if debugme: self.debug('%s: %s' % (chrom,chrom in locdb.index('Qry')))
                if debugme: self.debug('%s: %s' % (chrom,locdb.indexDataList('Qry',chrom,'Hit')))
                for pos in locdb.indexDataList('Qry',chrom,'QryStart') + selfdb.indexDataList('Qry',chrom,'QryStart'):
                    if pos not in posdict: posdict[pos] = {}
                    if (pos-1) not in posdict: posdict[pos-1] = {}
                for pos in locdb.indexDataList('Qry',chrom,'QryEnd') + selfdb.indexDataList('Qry',chrom,'QryEnd'):
                    if pos not in posdict: posdict[pos] = {}
                    if pos < chromlen and (pos+1) not in posdict: posdict[pos+1] = {}
                if debugme: self.debug(posdict)
                poslist = rje.sortKeys(posdict)
                for lentry in locdb.indexEntries('Qry',chrom) + selfdb.indexEntries('Qry',chrom):
                    hit = lentry['Hit']
                    if debugme and chrom != hit: self.debug(lentry)
                    for pos in poslist:
                        if pos < lentry['QryStart']: continue
                        if pos > lentry['QryEnd']: break    # Next entry
                        if hit not in posdict[pos]: posdict[pos][hit] = []
                        posdict[pos][hit].append(lentry['SbjStart'])
                        if debugme and chrom != hit: self.debug('%s %d: %s' % (hit,pos,posdict[pos][hit]))
                for pos in poslist:
                    pentry = {'Qry':chrom,'Pos':pos,
                              'HitSeq':0,'HitAln':0,'Class':'N','HitChrom':[],
                              'RecAln':0,'RecSeq':0,'RecChrom':[]}
                    for contig in posdict[pos]:
                        if contig in hitseqdict:   # Contig
                            pentry['HitSeq'] += 1
                            pentry['HitAln'] += len(posdict[pos][contig])
                            pentry['HitChrom'].append(string.split(contig,'_')[0])
                        else:
                            pentry['RecSeq'] += 1
                            pentry['RecAln'] += len(posdict[pos][contig])
                            pentry['RecChrom'].append(string.split(contig,'_')[0])
                    pentry['HitChrom'].sort()
                    pentry['HitChrom'] = string.join(pentry['HitChrom'],';')
                    pentry['RecChrom'].sort()
                    pentry['RecChrom'] = string.join(pentry['RecChrom'],';')
                    # Class
                    if pentry['HitAln'] == 1: pentry['Class'] = 'U'
                    elif pentry['HitSeq'] == 1: pentry['Class'] = 'C'
                    elif pentry['HitSeq'] == pentry['HitAln'] == 2: pentry['Class'] = 'D'
                    elif pentry['HitSeq'] > 1: pentry['Class'] = 'M'
                    chrdb.addEntry(pentry)
            chrdb.saveToFile()
            #!# Need to add processing of this (should sort in order thanks to tuplekeys=T) to identify the best
            #!# Contig for each chromosome and visa versa. Add length/HitSeq
        except: self.errorLog('%s.coveragePlot error' % self.prog()); raise
#########################################################################################################################
    def dirnCoveragePlot(self,ctype='Reference'):    ### Generate directional coverage plotting data
        '''
        Generate directional coverage plotting data. (For contig mapping, not plotting at present.)
        Adds Dirn to ctype.local table, and generates ctype.dircov table.
        '''
        try:### ~ [0] Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            self.devLog('#RUN','dirnCoveragePlot')
            self.printLog('#~~#','## ~~~~~~~~~~~~~~~~~ PAGSAT %s Directional Coverage Data ~~~~~~~~~~~~~~~~~ ##' % ctype)
            db = self.db()
            qryseqlist = self.obj[ctype[:3]]
            qryseqdict = qryseqlist.seqNameDic()   # Chromosomes to sequences
            #self.deBug(rje.sortKeys(qryseqdict))
            #if ctype[:3] == 'Ref': hitseqlist = self.obj['Assembly']
            #else: hitseqlist = self.obj['Reference']
            #hitseqdict = hitseqlist.seqNameDic()
            ## ~ [0a] Setup Coverage Plot Table ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            #i# Old headers: ['Chrom','Pos','HitNum','ContigNum','Contigs', 'Class','ChromHit','ChromNum','RefChrom']
            #i# New headers: ['Qry',  'Pos','HitAln','HitSeq',   'HitChrom','Class','RecAln',  'RecSeq',  'RecChrom']
            ctgdb = db.addEmptyTable('%s.dircov' % ctype,['Qry','Pos','FwdHitAln','FwdChrom','RevHitAln','RevChrom','HitChrom','Class'],['Qry','Pos'])
            ## ~ [0b] Local table ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            locdb = self.db('%s.local' % ctype)
            if 'Dirn' not in locdb.fields():
                locdb.addField('Dirn',evalue='Fwd')
                for lentry in locdb.entries():
                    if lentry['SbjStart'] > lentry['SbjEnd']: lentry['Dirn'] = 'Rev'

            #i# NOTE: This used to use Reference.local for both files. The Assembly.local search would have used Hit and
            #i# SbjStart/SbjEnd rather than Qry data. In this case, SbjStart and End must be swapped if there is a
            #i# reverse hit. See PAGSAT_V1 for details.

            for chrom in locdb.index('Qry'):
                posdict = {'Fwd':{qryseqlist.seqLen(qryseqdict[chrom]):{}},'Rev':{qryseqlist.seqLen(qryseqdict[chrom]):{}}}    # Dictionary of all local alignment boundaries : {contig:[starts]}
                for lentry in locdb.indexEntries('Qry',chrom):
                    for dirn in ['Fwd','Rev']:
                        pos = lentry['QryStart']
                        if pos not in posdict[dirn]: posdict[dirn][pos] = {}
                        if (pos-1) not in posdict[dirn]: posdict[dirn][pos-1] = {}
                        pos = lentry['QryEnd']
                        if pos not in posdict[dirn]: posdict[dirn][pos] = {}
                        if (pos+1) not in posdict[dirn]: posdict[dirn][pos+1] = {}
                poslist = rje.sortUnique(rje.sortKeys(posdict['Fwd']) + rje.sortKeys(posdict['Rev']),num=True)
                for lentry in locdb.indexEntries('Qry',chrom):
                    dirn = lentry['Dirn']
                    hit = lentry['Hit']
                    for pos in poslist:
                        if pos < lentry['QryStart']: continue
                        if pos > lentry['QryEnd']: break    # Next entry
                        if hit not in posdict[dirn][pos]: posdict[dirn][pos][hit] = []
                        posdict[dirn][pos][hit].append(lentry['QryStart'])
                for pos in poslist:
                    pentry = {'Qry':chrom,'Pos':pos,'Class':'N','HitChrom':[]}
                    for dirn in ['Fwd','Rev']:
                        pentry['%sHitAln' % dirn] = 0; pentry['%sChrom' % dirn] = 0
                        if pos in posdict[dirn]:
                            for contig in posdict[dirn][pos]:
                                pentry['%sHitAln' % dirn] += len(posdict[dirn][pos][contig])
                                pentry['%sChrom' % dirn] += 1
                                pchrom = string.split(contig,'_')[0]
                                if pchrom not in pentry['HitChrom']: pentry['HitChrom'].append(pchrom)
                    pentry['HitChrom'].sort()
                    # Class
                    if (pentry['FwdHitAln']+pentry['RevHitAln']) == 1: pentry['Class'] = 'U'
                    elif len(pentry['HitChrom']) == 1: pentry['Class'] = 'C'
                    elif len(pentry['HitChrom']) > 1: pentry['Class'] = 'M'
                    pentry['HitChrom'] = string.join(pentry['HitChrom'],';')
                    ctgdb.addEntry(pentry)
            #x#ctgdb.saveToFile()
            # This file is not used for anything, so no need to save at this point?
            # Might want to replace the ChromAlign plot with this one using just the "U" regions?)

            #!# Need to add processing of this (should sort in order thanks to tuplekeys=T) to identify the best
            #!# Contig for each chromosome and visa versa. Add length/HitSeq
        except: self.errorLog('%s.coveragePlot error' % self.prog()); raise
#########################################################################################################################
    def rGraphics(self):    ### Generates PAGSAT R Graphics
        '''Returns whether *Plots/*.summary.png has been made.'''
        try:### ~ [0] Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            self.devLog('#RUN','rGraphics')
            self.printLog('#~~#','## ~~~~~ PAGSTAT R Graphics ~~~~~ ##')
            basename = self.baseFile(strip_path=True)
            rsfile ='%s.Plots/%s.summary.png' % (self.baseFile(),basename) # Summary reference figure.
            if not self.force() and os.path.exists(rsfile):
                self.printLog('#CHECK','%s: Found. (Force=F)' % rsfile)
                return True
            rcmd = '%s --no-restore --no-save --args "pagsat" "%s"' % (self.getStr('RPath'),self.baseFile())
            rcmd += ' "refbase=%s"' % rje.baseFile(self.getStr('RefGenome'))
            rcmd += ' "assbase=%s"' % rje.baseFile(self.getStr('Assembly'))
            rcmd += ' "minloclen=%d"' % self.getInt('MinLocLen')
            rcmd += ' "minlocid=%f"' % self.getNum('MinLocID')
            for boolvar in ['Diploid','GeneSummary','ProtSummary','ChromAlign','Features']:
                if not self.getBool(boolvar): rcmd += ' "%s=F"' % boolvar.lower()
            rdir = '%slibraries/r/' % slimsuitepath
            rcmd += ' "rdir=%s" < "%srje.r" > "%s.r.tmp.txt"' % (rdir,rdir,self.baseFile())
            self.printLog('#RPNG',rcmd)
            problems = os.popen(rcmd).read()
            if problems:
                for ptxt in problems: self.warnLog(ptxt)
            # Optional cleanup of *.r.tmp.txt ?
            return os.path.exists(rsfile)
        except: self.errorLog('%s.rGraphics error' % self.prog()); return False
#########################################################################################################################
    def topHits(self):    ### Generates output for Gene/Protein TopHits analysis
        '''Returns the Reference Features table, if given.'''
        try:### ~ [0] Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            self.devLog('#RUN','topHits')
            if not self.getBool('Features'):
                self.printLog('#TOPHIT','No Gene/Protein TopHit analysis without Genbank features table.')
                return False
            self.printLog('#~~#','## ~~~~~~~~~~~~~~~~~~~~~~~ PAGSTAT TopHits/Synteny Analysis ~~~~~~~~~~~~~~~~~~~~~~ ##')
            db = self.db()
            if not self.force() and rje.exists('%s.Genes.TopHits.tdt' % db.baseFile()) and rje.exists('%s.Proteins.TopHits.tdt' % db.baseFile()):
                self.printLog('#HITS','Genes.TopHits and Proteins.TopHits tables found (force=F).'); return True
            tophitbuffer = self.getNum('TopHitBuffer')
            if tophitbuffer < 0: self.warnLog('Cannot have TopHitBuffer < 0.0!'); tophitbuffer = 0.0
            refseqlist = self.obj['Reference']
            ftdict = db.splitTable(self.ftdb(),'feature',asdict=True,keepfield=False,splitchar=None,values=['gene','CDS'])    # Reference features tables
            ftdict['Genes'] = ftdict.pop('gene')
            #self.debug(ftdict['Genes'].entries()[:10])
            ftdict['Proteins'] = ftdict.pop('CDS')
            #self.debug(ftdict['Proteins'].index('note').keys()[:10])
            acc2chr = {}
            for seq in refseqlist.seqs(): acc2chr[string.split(refseqlist.seqAcc(seq),'.')[0]] = refseqlist.seqGene(seq)
            ### ~ [1] Process ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            for gtype in ['Genes','Proteins']:
                ## ~ [1a] Load GABLAM data ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
                if not self.getBool('%sSummary' % gtype[:4]): continue
                gdb = db.addTable(filename='%s.%s.Fragments.gablam.tdt' % (self.fileBase('GABLAM','Base'),gtype),mainkeys=['Qry','Hit'],name='%s.gablam' % gtype,expect=True)
                if not gdb: self.warnLog('%s.%s.Fragments.gablam.tdt missing!' % (self.fileBase('GABLAM','Base'),gtype)); continue
                ## ~ [1b] Generate TopHits and Synteny predictions ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
                synteny = rje_synteny.Synteny(self.log,self.cmd_list)   #i# Uses own tophitbuffer=X [1.0]
                synteny.baseFile(db.baseFile())
                synteny.obj['DB'] = db
                synteny.obj['RefSeq'] = self.obj['Reference']
                synteny.topHitSynteny(ftdict[gtype],gdb,proteins=gtype=='Proteins',tabname='%s.TopHits' % gtype)
        except: self.errorLog('%s.topHits error' % self.prog())
#########################################################################################################################
    ### <5> ### PAGSAT Report Methods                                                                                   #
#########################################################################################################################
    def ftdb(self): ### Returns the Reference Features table, if given
        '''Returns the Reference Features table, if given.'''
        try:### ~ [0] Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            self.devLog('#RUN','ftdb')
            if self.obj['Features']: return self.obj['Features']
            if not self.getBool('Features'): return False
            db = self.db()
            ### ~ [1] Load Reference Feature Table (if refgenome given) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            if self.getStrLC('RefGenome'):
                ftdb = db.addTable('%s.Feature.tdt' % rje.baseFile(self.getStr('RefGenome')),mainkeys=['locus','feature','position'],name='features')
                ftdb.dataFormat({'start':'int','end':'int'})
            else: self.printLog('#REFFT','Cannot load/report/assess features without refgenome=FILE.'); ftdb = None
            self.obj['Features'] = ftdb
            return self.obj['Features']
        except: self.errorLog('%s.ftdb error' % self.prog()); return None
#########################################################################################################################
    def report(self,getdata=False,assembly=False):   ### Generates HTML reports of PAGSAT assessment
        '''
        Generates HTML reports of PAGSAT assessment.
        >> getdata:bool [False] = Whether to run and return sections data even if output not needed. (Will make tables etc.)
        >> assessment:bool [False] = Whether to run in "assembly" mode for PAGSAT tidy.
        '''
        try:### ~ [0] Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            self.devLog('#RUN','report',debug=False)
            db = self.db()
            if assembly:
                self.printLog('#~~#','## ~~~~~~~~~~~~~~~~~~~~~~~~~~~ PAGSAT Assembly HTML ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##')
            else: self.printLog('#~~#','## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ PAGSAT Report HTML ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##')
            # List of (non-numerical) chromosomes to use if not AccNum.(\d+)
            chrlist = []
            for i in range(16): chrlist.append('%s%s' % (self.getStr('RefChr'),rje.romanFromInt(i+1)))
            chrlist += ['%sMT' % self.getStr('RefChr')]
            chrlist += ['%sP' % self.getStr('RefChr')]  # Won't always have a plasmid.
            ## ~ [0a] Setup file paths ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            #i# Cannot use self.getStr('BaseBase') for report.html output as it would overwrite for different LxIDx runs.
            #i# Will therefore use path-stripped basefile as the filename. Then need to point to files within PAGSAT/
            #i# and PAGSAT/*.Plots directory.
            #i# NOTE: Basefile cannot be set with a path for PAGSAT, so this should be quite robust
            basename = self.baseFile(strip_path=True)
            hfile = '%s.report.html' % basename     # self.baseFile()
            if assembly: hfile = '%s.assembly.html' % basename     # self.baseFile()
            elif rje.exists(hfile) and not self.force() and not getdata:
                self.printLog('#HTML','HTML report found: %s' % hfile)
                return True
            #i# pagbase will point to files within the PAGSAT folder
            #i# If hfile is changed to be within the PAGSAT folder, pagbase becomes './%s' % basename
            pagbase = './%s.PAGSAT/%s' % (self.getStr('BaseBase'),basename)
            # plotbase will point to files within the PAGSAT plots folder
            plotbase = '%s.Plots/%s' % (pagbase,basename)
            ## ~ [0b] Check for required files ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            #i# Not all files are listed but these should indicate that things have run correctly.
            wanted = ['Summary.tdt',    # Summary delimited text file
                      'Sequences.tdt',  # Summary of the combined coverage of chromosomes
                      'png',            # Summary tree of assembly vs reference chromosomes
                      'Assembly.mapping.tdt',   # Pairwise contig:chrom Unique totals
                      'Plots/%s.summary.png' % basename] # Summary reference figure.
            if self.getBool('MapFas'): wanted.append('map.fasta') #i# *.fasta for SAMTools etc.
            for wext in wanted:
                wfile = '%s.%s' % (self.baseFile(),wext)
                if not os.path.exists(wfile):
                    self.printLog('#CHECK','%s: Missing! Will generate.' % wfile)
                    self.assessment(); break
                self.printLog('#CHECK','%s: Found.' % wfile)
            for wext in wanted:
                wfile = '%s.%s' % (self.baseFile(),wext)
                if not os.path.exists(wfile):
                    #raise IOError('Cannot find %s!' % wfile)
                    self.warnLog('Cannot find %s! Report output may be missing data or graphics.' % wfile)
            ## ~ [0c] Setup HTML ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            #!# Consider making an HTML table where each entry is a section, with fields:
            #!# |-- Section, Order, Link, LinkDesc, HTML
            sectdata = {}   # Start with a secdata{Link, LinkDesc, HTML} dictionary that could become table.dict['Data']

            #i# Each section should have a description in the desc dictionary and a corresponding <a name=""> xref.
            sections = ['Contents','Summary Table','Summary Plot','Reference Coverage','Tree',
                        'Assembly Coverage','Assembly Plot','Chromosome Plots','Contig Plots',
                        'Contig Mapping']
            if assembly: sections = ['Contents','Contig Mapping','Summary Plot','Chromosome Plots','Contig Plots','Assembly Coverage']
            #i# links is a dictionary to link the TEXT description to ANAME when the latter is not just the first word of TEXT
            links = {'Summary Table':'summarytable','Reference Coverage':'refcov','Assembly Coverage':'asscov',
                     'Contig Mapping':'mapping'}
            #i# desc is a dictionary of ANAME identifiers and the corresponding mouseover description (title="X")
            #i# These are now laid out in order of appearance:
            desc = {'contents':'Report contents and quick links',
                    'tree':'Summary tree of chromosomes vs contigs (% global identity)',
                    'summary':'Summary plot of assembly against reference chromosomes',
                    'summarytable':'Summary table of assembly against reference chromosomes',
                    'refcov':'Summary table of assembled reference coverage',
                    'asscov':'Summary table of assembled assembly coverage',
                    'chromalign':'Summary plot of aligned contigs against reference chromosomes',
                    'assembly':'Summary plot(s) of reference chromosomes against assembly contigs',
                    'chromosome':'Plots per reference chromosome of top assembly contig hits',
                    'contig':'Plots per assembly contig of top reference chromosome hits',
                    'mapping':'Mapping of assembly contigs onto reference chromosomes (used in PAGSAT Tidy)'
                    }
            #i# hlink is HTML that can be repeated in each section.
            #i# The link identifier should be used with <a name=""> at the start of the section.
            hlink = ['<p>','Quick Links:']
            for section in sections:
                if section in links: link = links[section]
                else: link = string.split(section)[0].lower()
                hlink.append('~ <a href="#%s" title="%s">%s</a>' % (link,desc[link],section))
                sectdata[section] = {'Link':link, 'LinkDesc':desc[link],
                                     'LinkHTML':'<a href="#%s" title="%s">%s</a>' % (link,desc[link],section),
                                     'HTML':[]}  # This will need to be joined at the end.
            hlink += ['</p>','']
            hlink = string.join(hlink,'\n')
            #i# Elsewhere, a link to the top can be provided:
            toplink = '[<a href="#head" title="Return to top of page">Top</a>]'

            ## ~ [0d] Sort out sequence links and PNG files ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            #i# Each chromosome gets its own <A NAME="Locus"> link subsection with its covplot PNG file.
            #i# These should be linked from the summary tables.
            # Load Sequences table & create a copy
            if assembly:
                seqdb = self.db('Sequences',add=True,mainkeys=['Locus'])
                #self.debug(seqdb.fields())
            else: seqdb = db.copyTable(self.db('Sequences',add=True,mainkeys=['Locus']),'SeqSummary')
            #># Locus, Name, Chrom, MapChrom, MapUniq, MapDirn, Spec, Source, Desc, HitNum, MaxScore, EVal,
            #># Length, Coverage, Identity, Positives, Missing, Different, Perfect [,Col]
            tdtitle = {'Locus':'Sequence/Locus Accession Number',
                       'Name':'Sequence name'}
            # Replace certain field values with <a href="#xxx"> links to PNGs
            # Use # for sorting the order
            seqdb.addFields(['#','PNG','NameLink','ChromLink','MapLink'])
            for ekey in seqdb.dataKeys():
                entry = seqdb.data(ekey)
                pngfile = '%s.covplot.%s.png' % (plotbase,entry['Name'])
                if not rje.exists(pngfile): self.warnLog('%s not found!' % pngfile)
                #i# Check for Locus that either matches original unitig format, or SAMPhaser haplotigs.
                if rje.matchExp('\S+\.\D?(\d+)',entry['Locus']):
                    if assembly:
                        if entry['MapChrom'] not in chrlist: chrlist.append(entry['MapChrom'])
                        entry['#'] = chrlist.index(entry['MapChrom'])
                    else: entry['#'] = int(rje.matchExp('\S+\.\D?(\d+)',entry['Locus'])[0])
                else:
                    if entry['Chrom'] not in chrlist: chrlist.append(entry['Chrom'])
                    entry['#'] = chrlist.index(entry['Chrom'])
                entry['PNG'] = pngfile
                entry['NameLink'] = '<a href="#%s" title="%s">%s</a>' % (entry['Locus'],entry['Desc'],entry['Name'])
                entry['ChromLink'] = '<a href="#%s" title="%s">%s</a>' % (entry['Locus'],entry['Desc'],entry['Chrom'])
            seqdb.newKey(['#','Locus']) # Should make it output in chromosome order.
            reftable = db.splitTable(seqdb,'Source',asdict=True)['Reference']
            reftable.index('Chrom')
            for entry in seqdb.entries():
                if entry['MapChrom'] in reftable.index('Chrom'):
                    entry['MapLink'] = reftable.indexEntries('Chrom',entry['MapChrom'])[0]['ChromLink']
                else: entry['MapLink'] = entry['MapChrom']
            seqdata = seqdb.dict['Data']
            #i# Use table.subset(index,value) to temporarily replace table.dict['Data'] for rje_html.dbTableToHTML(table)
            #i# Then: seqdb.dict['Data'] = seqdata
            #i# For ease, make a copy for table output.
            tabdb = db.copyTable(seqdb,'SeqTable')
            tabdb.renameField('Name','PureName')
            tabdb.renameField('NameLink','Name')
            tabdb.renameField('MapChrom','PureMap')
            tabdb.renameField('MapLink','MapChrom')
            tabdata = tabdb.dict['Data']
            #i# Could use this instead of subset:
            tabdb.index(('Chrom','Source'))
            tabfields = ['Name', 'MapChrom', 'MapDirn', 'Desc', 'HitNum', 'Length', 'Coverage', 'Identity', 'Missing', 'Different', 'MapUniq']

            ## Mapping data
            assmapdb = db.copyTable(self.db('Assembly.mapping',add=True,mainkeys=['Qry','Chrom']),'AssMapping')
            assmapdb.dataFormat({'Fwd':'int','Rev':'int','Unique':'int','Dirn':'int'})
            for entry in assmapdb.entries():
                if entry['Dirn'] >= 0: entry['Dirn'] = 'Fwd'
                else: entry['Dirn'] = 'Rev'
            refmapdb = db.copyTable(assmapdb,'RefMapping')
            for ekey in assmapdb.dataKeys():
                entry = assmapdb.data(ekey)
                #if entry['Chrom'] not in chrlist: chrlist.append(entry['Chrom'])
                #entry['#'] = chrlist.index(entry['Chrom'])
                entry['Chrom'] = reftable.indexEntries('Chrom',entry['Chrom'])[0]['ChromLink']
            assmapdb.newKey(['Rank','Chrom','Qry']) # Should make it output in chromosome order.
            refmapdb.addFields(['#'])
            for ekey in refmapdb.dataKeys():
                entry = refmapdb.data(ekey)
                if rje.matchExp('\S+\.\D?(\d+)',entry['Qry']):
                    entry['#'] = int(rje.matchExp('\S+\.\D?(\d+)',entry['Qry'])[0])
                else:
                    if entry['Qry'] not in chrlist:
                        chrlist.append(entry['Qry'])
                        self.warnLog('Had to add %s to ChrList. PAGSAT may not like the name. Report odd behaviour.' % entry['Qry'])
                    entry['#'] = chrlist.index(entry['Qry'])
                locus = string.split(entry['Qry'],'__',1)[-1]
                entry['Qry'] = '<a href="#%s" title="%s">%s</a>' % (locus,entry['Qry'],entry['Qry'])
            refmapdb.newKey(['#','Qry','Chrom']) # Should make it output in chromosome order.

            ### ~ [1] ~ Contents ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            #i# Report contents and quick links to sections
            section = 'Contents'
            if section in sections:
                hbody = sectdata[section]['HTML']
                hbody += ['<a name="%s"></a><h2 title="%s">%s %s</h2>' % (sectdata[section]['Link'],sectdata[section]['LinkDesc'],basename,section),hlink,'']
                if assembly:
                    hbody += ['<p>See also <a href="./%s.report.html">%s.report.html</a> for more details of assembly-reference mapping.</p>' % (basename,basename)]
                else:
                    #i# Reference chromosomes
                    hbody += ['<p>','Reference Chromosomes:']
                    for ekey in seqdb.index('Source')['Reference']:
                        entry = seqdb.data(ekey)
                        hbody.append('~ %s' % entry['NameLink'])
                    hbody += ['</p>','']
                    #i# Assembly chromosomes
                    hbody += ['<p>','Assembly Contigs:']
                    for ekey in seqdb.index('Source')['Assembly']:
                        entry = seqdb.data(ekey)
                        hbody.append(' %s |' % entry['NameLink'])
                    hbody += ['</p>','']
                #i# Reference chromosomes
                refchrlink = 'Reference:'
                for ekey in seqdb.index('Source')['Reference']:
                    entry = seqdb.data(ekey)
                    refchrlink += ' %s |' % entry['ChromLink']
                #i# Assembly chromosomes
                #?# For asschrlink, maybe sort by Chrom not Locus?
                asschrlink = 'Assembly:'
                for ekey in seqdb.index('Source')['Assembly']:
                    entry = seqdb.data(ekey)
                    asschrlink += ' %s |' % entry['ChromLink']

            ### ~ [2] ~ Summary Table ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            #i# Summary table of assembly against reference chromosomes
            section = 'Summary Table'
            if section in sections:
                hbody = sectdata[section]['HTML']
                hbody += ['<a name="%s"></a><h2 title="%s">%s %s</h2>' % (sectdata[section]['Link'],sectdata[section]['LinkDesc'],basename,section),hlink,'']
                htxt = '''
                <p>Summary statistics of assembly, mapping all local BLAST hits between reference chromosomes and assembly
                contigs, subject to `minlocid=X` and `minloclen=X` cutoffs. (The `LXXXIDYY` part of the output.)</p>

                <p><i>NOTE: Because all BLAST hits are mapped, this can be considered an upper bound on the degree of similarity.
                Use <a href="http://rest.slimsuite.unsw.edu.au/snapper">Snapper</a> or another tool for "unique" coverage.
                PAGSAT statistics are primarily designed for comparing assemblies, not for giving absolute statistics.</i></p>
                '''
                while rje.matchExp('`(\S+)`',htxt):
                    reptext = rje.matchExp('`(\S+)`',htxt)[0]
                    htxt = htxt.replace('`%s`' % reptext,'<code>%s</code>' % reptext)
                sumtable = open('%s.Summary.tdt' % self.basefile()).read()
                hbody.append(htxt)
                hbody.append(rje_html.tableToHTML(sumtable,'\t',tabwidth='100%',tdwidths=[],tdalign=[],valign='center',thead=True,border=1,tabid=''))


            ### ~ [3] ~ Summary Plot ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            #i# Summary plot of assembly against reference chromosomes
            section = 'Summary Plot'
            if section in sections:
                hbody = sectdata[section]['HTML']
                hbody += ['<a name="%s"></a><h2 title="%s">%s %s</h2>' % (sectdata[section]['Link'],sectdata[section]['LinkDesc'],basename,section),hlink,'']
                pnglink = '%s.summary.png' % plotbase
                pngdesc = 'Assembly contigs plotted against Reference chromosome(s).'
                hbody.append('<a href="%s"><img src="%s" width="100%%" title="%s"></a>' % (pnglink,pnglink,pngdesc))

            ### ~ [4] ~ Reference Coverage ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            #i# Summary table of assembled reference coverage
            section = 'Reference Coverage'
            if section in sections:
                hbody = sectdata[section]['HTML']
                hbody += ['<a name="%s"></a><h2 title="%s">%s %s</h2>' % (sectdata[section]['Link'],sectdata[section]['LinkDesc'],basename,section),hlink,'']
                #hbody.append(rje_html.tableToHTML(reftable,'\t',tabwidth='100%',tdwidths=[],tdalign=[],valign='center',thead=True,border=1,tabid=''))
                tabdb.dict['Data'] = tabdb.subset('Source',"Reference") # temporarily replace table.dict['Data'] for rje_html.dbTableToHTML(table)
                #!# Add titledict for all table field headers.
                hbody.append(rje_html.dbTableToHTML(tabdb,tabfields,tdtitles=tdtitle))  # Could modify CSS for tabid formatting?
                tabdb.dict['Data'] = tabdata

            ### ~ [5] ~ Tree ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            #i# Summary tree of chromosomes vs contigs (% global identity)
            section = 'Tree'
            if section in sections:
                hbody = sectdata[section]['HTML']
                hbody += ['<a name="%s"></a><h2 title="%s">%s %s</h2>' % (sectdata[section]['Link'],sectdata[section]['LinkDesc'],basename,section),hlink,'']
                hbody.append('<a href="%s.png"><img src="%s.png" width="100%%" title="%s"></a>' % (pagbase,pagbase,desc['tree']))

            ### ~ [6] ~ Assembly Coverage ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            #i# Summary table of assembled assembly coverage
            section = 'Assembly Coverage'
            if section in sections:
                hbody = sectdata[section]['HTML']
                hbody += ['<a name="%s"></a><h2 title="%s">%s %s</h2>' % (sectdata[section]['Link'],sectdata[section]['LinkDesc'],basename,section),hlink,'']
                tabdb.dict['Data'] = tabdb.subset('Source',"Assembly") # temporarily replace table.dict['Data'] for rje_html.dbTableToHTML(table)
                hbody.append(rje_html.dbTableToHTML(tabdb,tabfields,tdtitles=tdtitle))  # Could modify CSS for tabid formatting?
                tabdb.dict['Data'] = tabdata

            ### ~ [7] ~ Assembly Plot ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            #i# Summary plot(s) of reference chromosomes against assembly contigs
            section = 'Assembly Plot'
            if section in sections:
                hbody = sectdata[section]['HTML']
                hbody += ['<a name="%s"></a><h2 title="%s">%s %s</h2>' % (sectdata[section]['Link'],sectdata[section]['LinkDesc'],basename,section),hlink,'']
                for pnglink in glob.glob('%s.assembly*png' % plotbase):
                    if not rje.matchExp('%s.assembly\.(\d+)\.png' % plotbase,pnglink): continue # Individual chromosome or contig
                    pngdesc = 'Reference chromosomes plotted against assembly contigs.'
                    hbody.append('<a href="%s"><img src="%s" width="100%%" title="%s"></a>' % (pnglink,pnglink,pngdesc))

            ### ~ [8] ~ Reference Chromosome Plots ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            plotlink = '%s [<a href="#%s" title="%s">Reference</a>]  [<a href="#%s" title="%s">Contigs</a>]' % (toplink,sectdata['Chromosome Plots']['Link'],sectdata['Chromosome Plots']['LinkDesc'],sectdata['Contig Plots']['Link'],sectdata['Contig Plots']['LinkDesc'])

            #i# Plots per reference chromosome of top assembly contig hits
            section = 'Chromosome Plots'
            if section in sections:
                hbody = sectdata[section]['HTML']
                hbody += ['<a name="%s"></a><h2 title="%s">%s %s</h2>' % (sectdata[section]['Link'],sectdata[section]['LinkDesc'],basename,section),hlink,'']
                hbody += ['','<p>%s</p>' % refchrlink,'']
                for ekey in tabdb.index('Source')['Reference']:
                    entry = tabdb.data(ekey)
                    hbody.append('<hr width="80%%"><a name="%s"></a><h3 title="%s">%s ~ %s</h3>' % (entry['Locus'],entry['Desc'],entry['PureName'],plotlink))
                    if assembly: pngfile = '%s.assembly.%s.png' % (plotbase,entry['PureName'])
                    else: pngfile = entry['PNG']
                    hbody.append(rje_html.dbTableToHTML(tabdb,tabfields,[ekey],tdtitles=tdtitle))
                    if entry['Chrom'] in refmapdb.index('Chrom'):
                        dkeys = refmapdb.index('Chrom')[entry['Chrom']]
                        if assembly:
                            hbody.append('<p>The following %d assembly contig(s) have regions mapping solely to %s:</p>' % (len(dkeys),entry['PureName']))
                        else: hbody.append('<p>The following %d assembly contig(s) have regions mapping solely to %s. The top ten will be shown in the plot:</p>' % (len(dkeys),entry['PureName']))
                        hbody.append(rje_html.dbTableToHTML(refmapdb,refmapdb.fields()[:-1],datakeys=dkeys,tabwidth=750,tdtitles=tdtitle))
                    else: hbody.append('<p><i>No unique mapping for %s.</i></p>' % entry['PureName'])
                    hbody.append('<p><code>%s</code></p>' % pngfile)
                    hbody.append('<a href="%s"><img src="%s" width="100%%" title="%s"></a>' % (pngfile,pngfile,'%s coverage plot' % entry['PureName']))

            ### ~ [9] ~ Assembly Contig Plots ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            #i# Plots per assembly contig of top reference chromosome hits
            section = 'Contig Plots'
            if section in sections:
                hbody = sectdata[section]['HTML']
                hbody += ['<a name="%s"></a><h2 title="%s">%s %s</h2>' % (sectdata[section]['Link'],sectdata[section]['LinkDesc'],basename,section),hlink,'']
                hbody += ['','<p>%s</p>' % asschrlink,'']
                #tabdb.dict['Data'] = tabdb.subset('Source',"Assembly") # temporarily replace table.dict['Data'] for rje_html.dbTableToHTML(table)
                for ekey in tabdb.index('Source')['Assembly']:
                    entry = tabdb.data(ekey)
                    hbody.append('<hr width="80%%"><a name="%s"></a><h3 title="%s">%s ~ %s</h3>' % (entry['Locus'],entry['Desc'],entry['PureName'],plotlink))
                    if assembly:
                        pngfile = '%s.assembly.%s.png' % (plotbase,entry['PureName'])
                        hbody.append(rje_html.dbTableToHTML(tabdb,['Name','MapChrom','MapDirn','Length','MapUniq','NewAcc','NewChrom','Desc'],[ekey],tdtitles=tdtitle))
                    else:
                        pngfile = entry['PNG']
                        hbody.append(rje_html.dbTableToHTML(tabdb,tabfields,[ekey],tdtitles=tdtitle))
                    if entry['PureName'] in assmapdb.index('Qry'):
                        dkeys = assmapdb.index('Qry')[entry['PureName']]
                        hbody.append('<p>%s has regions mapping solely to the following %d reference chromosomes:</p>' % (entry['PureName'],len(dkeys)))
                        hbody.append(rje_html.dbTableToHTML(assmapdb,assmapdb.fields()[:-1],datakeys=dkeys,tabwidth=750,tdtitles=tdtitle))
                        if assembly: hbody.append('<p>Overlap with other contigs mapping to the same chromosomes, along with depth of coverage for those regions, will be shown in the plot below:</p>')
                    else: hbody.append('<p><i>No unique mapping for %s.</i></p>' % entry['PureName'])
                    hbody.append('<p><code>%s</code></p>' % pngfile)
                    hbody.append('<a href="%s"><img src="%s" width="100%%" title="%s"></a>' % (pngfile,pngfile,'%s coverage plot' % entry['PureName']))
                #tabdb.dict['Data'] = tabdata

            ### ~ [10] ~ Assembly Contig Mapping ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            #i# Mapping of assembly contigs onto reference chromosomes (used in PAGSAT Tidy)
            section = 'Contig Mapping'
            if section in sections:
                hbody = sectdata[section]['HTML']
                hbody += ['<a name="%s" title="%s"><h2>%s %s</h2></a>' % (sectdata[section]['Link'],sectdata[section]['LinkDesc'],basename,section),hlink,'']
                hbody += ['<p>Mapping of contigs onto chromosomes via longest total unique-mapping sequence:,</p>','<ul>']
                mapchrom = chrlist[0:]
                if 'Orphan' not in mapchrom: mapchrom.append('Orphan')
                while mapchrom:
                    ctext = '<li>'
                    chrom = mapchrom.pop(0)
                    rkeys = tabdb.indexDataKeys(('Chrom','Source'),(chrom,'Reference'))
                    if len(rkeys) > 1: self.warnLog('Chromosome %s duplication in Reference data?!' % (chr))
                    if rkeys:
                        rentry = tabdb.data(rkeys[0])
                        ctext += '%s: - ' % rentry['ChromLink']
                    else: ctext += '%s: - ' % chrom
                    for akey in tabdb.indexDataKeys(('PureMap','Source'),(chrom,'Assembly')):
                        aentry = tabdb.data(akey)
                        ctext += ' %s |' % aentry['ChromLink'] #['Name']
                        if aentry['MapDirn'] == 'Rev': ctext = ctext[:-2] + '(Rev) |'
                    #if mapchrom: ctext += '<br>'
                    #ctext += '</p>'
                    hbody.append(ctext)
            hbody += ['</ul>','']

            #!# Possible updates to add:
            # Include features overlapping:
            # (a) the missing regions
            # (b) repeated regions (where assembly > reference) in *.covplot.chrom.tdt

            ### ~ [X] Output HTML ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            html = rje_html.HTML(self.log,self.cmd_list)    #!# Add default css here. (Put in SLiMSuite? Or Plots/?)
            if rje.exists(hfile) and not self.force() and not assembly:
                self.printLog('#HTML','HTML report found: %s' % hfile)
            else:
                HTML = open(hfile,'w')
                HTML.write(html.htmlHead(title=basename,tabber=False,frontpage=True,keywords=[],redirect='',refresh=0))
                if assembly:
                    HTML.write('<a name="head"><h1>%s PAGSAT Assembly Tidy</h1></a>\n\n' % basename)
                else: HTML.write('<a name="head"><h1>%s Report</h1></a>\n\n' % basename)
                HTML.write(rje_html.progStartHTML(self))
                for section in sections: HTML.write(string.join(sectdata[section]['HTML'],'\n'))
                HTML.write(html.htmlTail(tabber=False))
                HTML.close()
                self.printLog('#HTML','HTML report output: %s' % hfile)
            return sectdata
        except: self.errorLog('%s.report error' % self.prog()); return False
#########################################################################################################################
    ### <8> ### PAGSAT Assembly Tidying/Editing                                                                         #
#########################################################################################################################
    def sortSeqs(self,seqs,chrlist=[]): ### Sorts sequences by chromosome and returns. Uses self.list['ChrList'].
        '''
        Sorts sequences by chromosome and returns. Uses self.list['ChrList'].
        >> seqs:list of (seqname,sequence) tuples.
        '''
        try:### ~ [0] Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            if not chrlist: chrlist = self.list['ChrList']  # This has both reference and NewChr in there.
            splitseq = {}       # Dictionary of sequence tuples per chromosome
            for (seqname,sequence) in seqs:
                chrom = string.split(seqname,'_')[0]
                if chrom[-1:] in ['H','A','B','N']: chrom = chrom[:-1]  # This should always be true but checking for future compatibility
                if chrom not in splitseq: splitseq[chrom] = []
                splitseq[chrom].append((seqname,sequence))
                if chrom not in chrlist: chrlist.append(chrom)
            if 'Orphan' in chrlist: chrlist.remove('Orphan'); chrlist.append('Orphan')
            ### ~ [1] Cycle through each chromosome and add sequences ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            newseq = []
            for chrom in chrlist:
                if chrom not in splitseq: continue
                splitseq[chrom].sort()
                newseq += splitseq[chrom]
            return newseq
        except: self.errorLog('%s.sortSeqs error' % self.prog()); return False
#########################################################################################################################
    def checkSeqs(self,seqlist): ### Checks sequence name formats and gives options to fix if wrong.
        '''
        Checks sequence name formats and gives options to fix if wrong.
        >> seqlist:SeqList object. Will use seqlist.seqs() if seqs=[].
        '''
        try:### ~ [0] Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            badseqx = 1
            ### ~ [1] Cycle through each sequence and check name ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            while badseqx:
                badseqx = 0
                for seq in seqlist.seqs():
                    if not rje.matchExp('^(\S+)_(\S+)__(\S+)\..*(\d+)$',string.split(seq[0])[0]):
                        self.warnLog('Bad format: %s does not match <gene>_<SPCODE>__<Accnum.XX> format!' % string.split(seq[0])[0])
                        badseqx += 1
                if badseqx:
                    if rje.yesNo('Edit sequences to fix %d names? (Otherwise quit)' % badseqx):
                        seqlist.edit()
                        for (etype,eacc,edesc) in seqlist.list['Edit']:
                            if etype[:3] in ['Sub','Rev','Div','Rem','Dup']:
                                self.printLog('#SQ%s' % etype[:3].upper(),'%s: %s' % (eacc,edesc))
                        seqlist.list['Edit'] = []
                    else: raise ValueError('%s sequences do not match <gene>_<SPCODE>__<Accnum.XX> format!' % badseqx)
                else: return True
        except: self.errorLog('%s.checkSeqs error' % self.prog()); raise
#########################################################################################################################
    def tidyTidyTable(self,seqlist,warn=True):    ### Checks and updates tidy table using SeqList data
        '''
        Checks and updates tidy table using SeqList data. If 'Seq' is empty, it will be populated. If 'Seq' has a
        mismatch, the Start/End positions will be corrected. If a Contig is not found, a sequence match search will be
        performed.
        >> seqlist:SeqList Object with (seqname,sequence) tuples.
        '''
        try:### ~ [0] Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            tdb = self.db('tidy')
            if not tdb:
                self.warnLog('Tidy table not found! Will be created.')
                tdb = self.db().addEmptyTable('tidy',['Contig','Start','End','Desc','Seq'],['Contig','Start'])   # Table of final comparison data
                tdb.dataFormat({'Start':'int','End':'int'})
                return tdb
            seqdict = seqlist.makeSeqNameDic('accnum')
            #self.debug('%s = %d' % (rje.sortKeys(seqdict),len(seqdict)))
            ### ~ [1] Check and update entries ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            missing = []
            sequpdatex = 0
            tex = tdb.entryNum()
            ## ~ [1a] Identify missing sequences ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            for entry in tdb.entries():
                # Check for missing contig name
                acc = entry['Contig']
                if acc not in seqdict: missing.append(entry)
            ## ~ [1b] Deal with missing sequences ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            if missing:
                if warn: self.warnLog('%s tidy entries missing Contig-AccNum links. Will try to assign via Sequence.' % rje.iLen(missing))
                else: self.printLog('#TIDY','Assigning %s tidy entries via Sequence.' % rje.iLen(missing))
                for entry in missing:
                    if not entry['Seq']: tdb.dropEntry(entry); continue
                    for seq in seqlist.seqs():
                        if seq[1] in entry['Seq'] or entry['Seq'] in seq[1]: entry['Contig'] = seqlist.seqAcc(seq); break
                tdb.remakeKeys()
            ## ~ [1c] Deal with sequence changes ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            for entry in tdb.entries():
                # Check for missing contig name
                acc = entry['Contig']
                # Check sequence
                sequence = seqdict[acc][1]
                if sequence == entry['Seq']: continue
                if not entry['Seq']: entry['Seq'] = sequence; sequpdatex += 1; continue
                # Truncations
                if sequence in entry['Seq']:
                    shiftx = entry['Seq'].find(sequence)
                    entry['Start'] = max(1,entry['Start'] - shiftx)
                    entry['End'] -= shiftx
                    #self.debug(entry)
                    if entry['End'] < 1: tdb.dropEntry(entry); continue
                    if entry['Start'] > len(sequence): tdb.dropEntry(entry); continue
                    entry['End'] = min(entry['End'],len(sequence))
                    entry['Seq'] = sequence; sequpdatex += 1; continue
                    #self.debug(entry)
                # Extensions
                if entry['Seq'] in sequence:
                    shiftx = sequence.find(entry['Seq'])
                    entry['Start'] += shiftx
                    entry['End'] = min(entry['End']+shiftx,len(sequence))
                    #self.debug(entry)
                    if entry['Start'] > len(sequence): tdb.dropEntry(entry); continue
                    entry['Seq'] = sequence; sequpdatex += 1; continue
                    #self.debug(entry)
            ## ~ [1d] Report ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            if sequpdatex:
                if warn: self.warnLog('%s Tidy table sequences updated' % rje.iStr(sequpdatex))
                else: self.printLog('#TIDY','%s Tidy table sequences updated' % rje.iStr(sequpdatex))
            if tex != tdb.entryNum(): self.warnLog('%s Tidy table entries dropped' % rje.iStr(tex - tdb.entryNum()))
            seqlist.dict['SeqDict'] = {}
        except: self.errorLog('%s.tidyTidyTable() error' % self.prog()); return False
#########################################################################################################################
    def tidy(self):   ### Semi-automated tidying and editing of assembly to generate final draft genome.
        '''Semi-automated tidying and editing of assembly to generate final draft genome.'''
        try:### ~ [0] Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            self.devLog('#RUN','tidy')
            if not self.report(): raise IOError('PAGSAT Report failed: no Tidy.')
            self.printLog('#~~#','## ~~~~~~~~~~~~~~~~~~~~~~~ PAGSAT Assembly Tidying/Editing ~~~~~~~~~~~~~~~~~~~~~~~ ##')
            db = self.db()
            basename = self.baseFile(strip_path=True)   # Text of basename for output to screen (not for file management)
            maptable = 'Sequences'    # This is the name of the database table to use for mapping.
            ## ~ [0a] Check/create PAGSAT files in *.PAGSAT/ directory ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            # Establish files needed for tidy=T
            wanted = ['%s.tdt' % maptable]    # Mapping file
            # Check for files
            if not rje.checkForFiles(wanted,'%s.' % self.baseFile(),log=self.log,cutshort=True,missingtext=' Will generate.'):
                self.assessment()
                # Check for files again. (Should have been made if missing during first check.)
                rje.checkForFiles(wanted,'%s.' % self.baseFile(),log=self.log,cutshort=True,ioerror=True)
            ## ~ [0b] Setup new directory ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            #i# Use self.fileBase() to return basefile for all input files (e.g. in *.PAGSAT/).
            #i# Use self.fileBase(resdir='Assemble') to return basefile for all output files.
            pagdir = self.getStr('ResDir')
            #Replace PAGSAT/ with ASSEMBLE/
            assdir = rje.makePath('%s.ASSEMBLE/' % string.join(string.split(pagdir,'.')[:-1],'.'))
            rje.mkDir(self,assdir)
            plotdir = rje.makePath('%s.Plots/' % self.fileBase())    # Where to find PAGSAT plots.
            self.setStr({'AssembleDir':assdir,'PlotDir':plotdir})
            self.printLog('#ASSDIR',self.getStr('AssembleDir'))      # Directory for PAGSAT output
            ## ~ [0c] Setup HTML ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            #i# Will now use report(assemble=True) to generate assembly.html

            ### ~ [1] Assign and rename contigs ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            ctgchr = self.getStr('NewChr')                          # This will be used for all new chromosome prefixes
            refchr = self.getStr('RefChr')                          # This is used to identify previous chromosomes
            # List of (non-numerical) chromosomes to use if not AccNum.(\d+)
            chrlist = []
            for i in range(16): chrlist.append('%s%s' % (self.getStr('RefChr'),rje.romanFromInt(i+1)))
            chrlist += ['%sMT' % self.getStr('RefChr')]
            chrlist += ['%sP' % self.getStr('RefChr')]
            for i in range(16): chrlist.append('%s%s' % (self.getStr('NewChr'),rje.romanFromInt(i+1)))
            chrlist += ['%sMT' % self.getStr('NewChr')]
            chrlist += ['%sP' % self.getStr('NewChr')]
            self.list['ChrList'] = chrlist
            seqdb = self.db(maptable,add=True,mainkeys=['Locus'])     # This is the mapping table with MapChrom assigned
            seqdb.addFields(['NewAcc','NewChrom'])                    # Need to store new accession numbers etc.
            seqdb.addField('Ctid',evalue='R')
            seqdb.makeField('#Name#','OldName')
            for entry in seqdb.indexEntries('Source','Assembly'):
                entry['Ctid'] = 'N'
                # Update accession number. NOTE: If NewAcc is given then the last '.' split must be unique
                #!# NOTE: NewAcc now handled later in process. This field might be surplass to requirements.
                acc = entry['Locus']
                #if self.getStrLC('NewAcc'): entry['NewAcc'] = '%s.%s' % (self.getStr('NewAcc'),string.split(acc,'.')[-1])
                #else:
                entry['NewAcc'] = acc
                # Update Chromosome
                if entry['MapChrom'].startswith(refchr): entry['NewChrom'] = ctgchr + entry['MapChrom'][len(refchr):]
                else: entry['NewChrom'] = entry['MapChrom']
                #self.debug(entry)

            ### ~ [2] Generate Assembly HTML ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            self.report(assembly=True)

            ### ~ [3] Load, rename and sort sequences ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            #seqdb.newKey('OldName')
            #self.debug(seqdb.fields())
            hfile = '%s.assembly.html' % self.baseFile(strip_path=True)
            seqfile = '%s%s.pagsat.fas' % (assdir,self.fileBase('Assembly'))
            revseqfile = '%s%s.reviewed.fas' % (assdir,self.fileBase('Assembly'))
            aseqfile = '%s%s.assemble.fas' % (assdir,self.fileBase('Assembly'))
            #!# Sort these by edit time and offer in right order.
            db.baseFile('%s%s' % (assdir,basename))
            tdb = None
            if rje.exists(aseqfile) and not self.force() and (self.yesNo('%s found. Use existing file sequence assembly/names?' % aseqfile)):
                seqcmd = self.cmd_list + ['seqin=%s' % aseqfile,'dna=T','autoload=F','seqmode=list']
                seqlist = rje_seqlist.SeqList(self.log,seqcmd)
                seqlist.loadSeq()
                self.printLog('#PAGMAP','PAGSAT-mapped contigs read from %s. Please check %s for incorrect mapping.' % (aseqfile,hfile))
                tdb = self.db('tidy',add=True,mainkeys=['Contig','Start'])   # Table of final comparison data
            elif rje.exists(seqfile) and not self.force() and (self.yesNo('%s found. Use existing file sequence assembly/names?' % seqfile)):
                seqcmd = self.cmd_list + ['seqin=%s' % seqfile,'dna=T','autoload=F','seqmode=list']
                seqlist = rje_seqlist.SeqList(self.log,seqcmd)
                seqlist.loadSeq()
                self.printLog('#PAGMAP','PAGSAT-mapped contigs read from %s. Please check %s for incorrect mapping.' % (seqfile,hfile))
                tdb = self.db('tidy',add=True,mainkeys=['Contig','Start'])   # Table of final comparison data
            elif rje.exists(revseqfile) and not self.force() and (self.yesNo('%s found. Use existing file sequence assembly/names?' % revseqfile)):
                seqcmd = self.cmd_list + ['seqin=%s' % revseqfile,'dna=T','autoload=F','seqmode=list']
                seqlist = rje_seqlist.SeqList(self.log,seqcmd)
                seqlist.loadSeq()
                self.printLog('#PAGMAP','PAGSAT-mapped contigs read from %s. Please check %s for incorrect mapping.' % (revseqfile,hfile))
                tdb = self.db('tidy',add=True,mainkeys=['Contig','Start'])   # Table of final comparison data
            else:
                seqcmd = self.cmd_list + ['seqin=%s' % self.getStr('Assembly'),'dna=T','autoload=F','seqmode=list']
                seqlist = rje_seqlist.SeqList(self.log,seqcmd)
                seqlist.loadSeq()
                newseq = []
                seqdict = seqlist.makeSeqNameDic('short')
                for ekey in seqdb.index('Source')['Assembly']:
                    entry = seqdb.data(ekey)
                    short = entry['Name']
                    try: (sname,sequence) = seqdict[short]
                    except: raise ValueError('Contig %s not found in %s.' % (short,self.getStr('Assembly')))
                #while seqlist.list['Seq']:
                #    (sname,sequence) = seqlist.list['Seq'].pop(0)
                #    short = string.split(sname,maxsplit=1)[0]
                #    entry = seqdb.data(short)
                #    if not entry: raise ValueError('Contig %s not found in %s table.' % (short,maptable))
                    newname = entry['Name'] = '%s%s_%s__%s' % (entry['NewChrom'],entry['Ctid'],entry['Spec'],entry['NewAcc'])
                    if entry['MapDirn'] == 'Rev':
                        newname += ' RevComp'
                        sequence = rje_sequence.reverseComplement(sequence)
                    newname += ' %s' % entry['Desc']
                    newseq.append((newname,sequence))
                    self.printLog('#EDIT','%s -> %s' % (short,newname))
                #newseq.sort()
                if len(newseq) != seqlist.seqNum(): raise ValueError('Sequence number mismatch!')
                seqlist.list['Seq'] = newseq
                seqlist.saveSeq(seqfile=seqfile)
                self.printLog('#PAGMAP','PAGSAT-mapped contigs output to %s. Please check %s for incorrect mapping.' % (seqfile,hfile))
            self.checkSeqs(seqlist)
            seqlist.setStr({'SeqIn':seqfile})
            seqlist.list['Seq'] = self.sortSeqs(seqlist.list['Seq'])
            self.checkSeqs(seqlist)
            if tdb:
                tdb.dataFormat({'Start':'int','End':'int'})
                tdb.addField('Seq')
                self.tidyTidyTable(seqlist)
            else: tdb = self.db().addEmptyTable('tidy',['Contig','Start','End','Desc','Seq'],['Contig','Start'])   # Table of final comparison data

            ### ~ [4] Tidy and assemble contigs ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            #?# What to do about tel/rRNA contigs etc. that do not really assemble - manual ID/renaming?


            ## ~ [4a] Option to review/accept/quit ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##

            #!# Add options for: <M>EGAssemble (Assemble all contigs together)
            #!# Change R to <E>dit/Review and make <R>eassign contigs
            self.vPrint('\n\nNOTE: It is advisable to check contig-chromosome mappings using the visualisations in *.assembly.html. These are prone to errors where there have been translocations between chromosomes.\n\n',v=0)
            if self.i() >= 0 and rje.yesNo('Try running command to open %s in browser?' % hfile):
                browser = rje.choice('Browser command?',default='open',confirm=True)
                os.system('%s %s' % (browser,hfile))

            stepi = 0; steps = ['R','A','O','F']
            if self.i() <= 0: stepi = 1
            while steps:
                choice = self.choice('\n\n<R>eview/edit Contigs; <A>ssemble; <O>rphans; <F>inish Tidy; <Q>uit PAGSAT?',default=steps[stepi],confirm=True).upper()
                if choice == 'A':
                    try:
                        self.assemble(seqlist,chrlist=chrlist[0:])
                        seqlist.list['Seq'] = self.sortSeqs(seqlist.list['Seq'])
                        aseqfile = '%s%s.assemble.fas' % (assdir,self.fileBase('Assembly'))
                        seqlist.saveSeq(seqfile=aseqfile)
                        self.printLog('#PAGASS','PAGSAT Assembly cycle complete')
                        stepi = 2
                    except SystemExit: choice = 'Q'
                    except KeyboardInterrupt: pass
                    except: raise
                elif choice == 'R':
                    seqlist.edit()
                    for (etype,eacc,edesc) in seqlist.list['Edit']:
                        if etype[:3] in ['Sub','Rev','Div','Rem','Dup']:
                            self.printLog('#SQ%s' % etype[:3].upper(),'%s: %s' % (eacc,edesc))
                    seqlist.list['Edit'] = []
                    seqlist.list['Seq'] = self.sortSeqs(seqlist.list['Seq'])
                    self.checkSeqs(seqlist)
                    rseqfile = '%s%s.reviewed.fas' % (assdir,self.fileBase('Assembly'))
                    seqlist.saveSeq(seqfile=rseqfile)
                    stepi = 1
                    #?# Remake HTML #?#
                    self.tidyTidyTable(seqlist)
                elif choice == 'O': # <O>rphans
                    expand_orphans = self.yesNo('Treat any non-"%s" sequences as orphans?' % self.getStr('NewChr'))
                    olist = []; otxt = []
                    for seq in seqlist.list['Seq']:
                        (seqname,sequence) = seq
                        if seqname.lower().startswith('orphan'): olist.append(seq); otxt.append(seqname)
                        elif expand_orphans and not seqname.startswith(self.getStr('NewChr')): olist.append(seq); otxt.append(seqname)
                    if olist:
                        print '%s\n\n' % string.join(['\n%d Orphan sequences:' % len(olist)]+otxt,'\n - ')
                        if self.yesNo('Delete %d orphan sequences? (Review/Edit for individual changes.)' % len(olist)):
                            for seq in olist:
                                seqlist.list['Seq'].remove(seq)
                                self.printLog('#DEL','Deleted contig %s: Orphan contig.' % (string.split(seq[0])[0]))
                    elif self.getBool('Orphans'): print '\n\nNo Orphan contigs.\n\n'
                    else: self.printLog('#INFO','No Orphans permitted. Check earlier #DEL entries in log file.')
                    stepi = 3
                elif choice == 'F': # <F>inish
                    break
                if choice in ['Q','QUIT']:
                    if tdb.entries() and rje.yesNo('Save tidy table to *.tidy.tdt?'):
                        tdb.dropField('Seq')
                        tdb.saveToFile()
                    if rje.yesNo('Save sequences to %s?' % seqfile,default='N'):
                        rje.backup(self,seqfile)
                        seqlist.saveSeq(seqfile=seqfile)
                    return False


            # Table of tidy joins to checking with read coverage versus main PAGSAT output
            #!# Use Seq to check/update after edits; Make sure this table is loaded and populated if seqs reused.
            savefields = tdb.fields()
            savefields.remove('Seq')
            if tdb.entries():
                #tdb.dropField('Seq')
                tdb.indexReport('Contig',force=True)    # Used for renaming sequences later.
                tdb.saveToFile(savefields=savefields)

            ### ~ [5] Save sequence files for additional processing  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            #!# Make sure these are sorted by chromosome
            ## ~ [5a] Save all sequences ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            #i# This main output file is what can be "picked up" during a re-run.
            #i# It is also the sequences matching the "tidy table" output.
            #!# Add printed info to that effect #!#
            rje.backup(self,seqfile)
            seqlist.saveSeq(seqfile=seqfile)
            ## ~ [5b] Setup subsets ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            #i# Also want to provide additional optional files that are compatible with downstream applications
            #i# These outputs can have updated AccNum and sequence numbering. This is handled in sequence assignment, below.
            if not self.getStrLC('NewAcc') and rje.yesNo('Set new accession number for final output files?'):
                newacc = rje.choice('New Accession number prefix (no spaces), e.g. MBG001 (blank to cancel)?',confirm=True,default='')
                newacc = string.join(string.split(newacc),'')
                self.setStr({'NewAcc':newacc})
            if self.getStrLC('NewAcc') and rje.yesNo('Use NewAcc "%s" as basefile for fasta output?' % self.getStr('NewAcc')):
                pagbase = fasbase = self.getStr('NewAcc')
            else:
                fasbase = self.fileBase('Assembly')
                pagbase = string.join(string.split(basename,'.')[:-1],'.')
            #i# Make a gene dictionary where each gene is the haplotig
            #># Need to allow for multiple sequences per haplotig -> IA1,II1 etc.
            genedic = seqlist.geneDic()     # Dictionary of {'Gene':[seqs]}
            hapsets = {'haploid':'AH','contigs':'ABHN'}
            if self.getBool('Diploid'): hapsets = {'diploidA':'AH','diploidB':'B','contigs':'ABHN'}
            hapseq = {}
            hapfile = {}
            for sub in hapsets: hapseq[sub] = []; hapfile[sub] = ''
            ## ~ [5c] Subset sequence output ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            sx = 0
            for seq in seqlist.seqs():
                sx += 1
                gene = seqlist.seqGene(seq)
                hap = gene[-1]
                newchr = gene[:-1]
                if newchr.startswith(self.getStr('NewChr')): chrom = newchr[len(self.getStr('NewChr')):]
                else: chrom = newchr
                newdesc = 'Chromosome %s' % chrom
                (seqname,sequence) = seqlist.getSeq(seq)
                newgene = gene
                if self.getBool('Diploid'): newdesc += ', Haplotype %s' % hap
                elif gene[-1] == 'H': newgene = gene[:-1]
                if len(genedic[gene]) > 1:
                    newgene = newgene + rje.preZero(genedic[gene].index(seq)+1,len(genedic[gene]))
                    newdesc += ', Contig %d of %d' % (genedic[gene].index(seq)+1,len(genedic[gene]))
                if self.getStrLC('NewAcc'): newacc = '%s.%s' % (self.getStr('NewAcc'),rje.preZero(sx,seqlist.seqNum()))
                else: newacc = seqlist.seqAcc(seq)
                for tentry in tdb.indexEntries('Contig',seqlist.seqAcc(seq)): tentry['Contig'] = newacc
                seqname = '%s_%s__%s %s' % (newgene,seqlist.seqSpec(seq),newacc,newdesc)
                self.printLog('#CHR','%s -> %s' % (seqlist.shortName(seq),string.split(seqname)[0]))
                for sub in hapsets:
                    if hap in hapsets[sub]: hapseq[sub].append((seqname,sequence))
            for sub in hapsets:
                hapfile[sub] = '%s%s.%s.fas' % (assdir,fasbase,sub)
                seqlist.saveSeq(seqfile=hapfile[sub],seqs=hapseq[sub])

            if tdb.entries():
                tdb.remakeKeys()
                seqlist.list['Seq'] = hapseq['contigs']
                self.tidyTidyTable(seqlist)
                tdb.saveToFile('%s%s.contigs.tidy.tdt' % (assdir,fasbase),savefields=savefields)

            ### ~ [6] Option for regenerating new plots etc. using PAGSAT ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            if self.yesNo('Run self-PAGSAT of full contig set vs "haploid core" (tidy=F)?'):
                self.printLog('#PAGSAT','Running PAGSAT: see %s.ploidy.log' % pagbase)
                pagcmd = ['assembly=%s' % hapfile['Contigs'],'refgenome=%s' % hapfile['Haploid'],'basefile=%s.ploidy' % pagbase,'tidy=F',
                          'genesummary=F','protsummary=F','mapfas=F']
                (info,out,mainlog,cmd_list) = setupProgram(pagcmd)
                PAGSAT(mainlog,cmd_list).run()
                mainlog.endLog(info)
            for sub in ['haploid','diploidA','diploidB','contigs']:
                if sub in hapfile and hapfile[sub] and self.yesNo('Run PAGSAT on "%s" output vs Reference (tidy=F)?' % sub):
                    self.printLog('#PAGSAT','Running PAGSAT: see %s.%s.log' % (pagbase,sub.lower()))
                    pagcmd = ['assembly=%s' % hapfile[sub],'basefile=%s.%s' % (pagbase,sub.lower()),'tidy=F']
                    if self.getBool('MapFas') and self.yesNo('Set mapfas=F?'): pagcmd.append('mapfas=F')
                    (info,out,mainlog,cmd_list) = setupProgram(pagcmd)
                    PAGSAT(mainlog,cmd_list).run()
                    mainlog.endLog(info)

        except SystemExit: return False
        except: self.errorLog('%s.tidy() error' % self.prog())
#########################################################################################################################
    def assembleChrom(self,seqlist,chrom,chromseq,midrun=False,walk=False,prev=True,auto=False): ### Run the assembly process for just one chromosome
        '''
        Run the assembly process for just one chromosome.
        >> seqlist:SeqList object = Sequences will be modified.
        >> chrom:str = Chromosome being assembled.
        >> chromseq:list = List of sequences from seqlist to try and assemble.
        >> midrun:bool [False] = Whether this is in the middle of an assembly run - skip certain menu options etc.
        >> walk:bool [False] = Whether to "walk" from chromosome end.
        >> prev:bool [True] = Whether to offer "previous" chromosome option.
        >> auto:bool [False] = Whether to auto-assemble the best unambiguous join.
        '''
        try:### ~ [0] Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            self.devLog('#RUN','assembleChrom')
            tdb = self.db('tidy') # ['Contig','Start','End','Desc','Seq'],['Contig','Start'])
            seqdict = seqlist.makeSeqNameDic('short')  # Dictionary of shortname to sequence, updated for any edits
            sfile = '%s.%s.fas' % (self.fileBase('CtgGABLAM'),chrom)
            sbase = '%s.%s' % (self.fileBase('CtgGABLAM'),chrom)
            haponly = circdef = circularise = False
            if len(chromseq) == 1:
                try:
                    (seqname,sequence) = chromseq[0]
                    seqdesc = string.split(seqname,maxsplit=1)[1]
                except: seqdesc = ''
                circdef = {True:'N',False:'Y'}[seqdesc.startswith('Circle')]
                seqgene = string.split(seqname,'_')[0]
                if seqgene[-1] == 'N':
                    self.printLog('#~~#','## ~~~~~~~~~~~~~~~~~~~~~~ Single Contig Haplotig Assignment ~~~~~~~~~~~~~~~~~~~~~~~~~~ ##')
                    try:
                        if self.getBool('Diploid'): c = 'A'
                        else: c = 'H'
                        newgene = seqgene[:-1] + c
                        self.printLog('#HTIG%s' % c,seqname)
                        cseq = chromseq[0]
                        newname = '%s_%s__%s %s' % (newgene,seqlist.seqSpec(cseq),seqlist.seqAcc(cseq),seqlist.seqDesc(cseq))
                        ci = seqlist.list['Seq'].index(cseq)
                        newseq = (newname,cseq[1])
                        seqlist.list['Seq'][ci] = newseq
                        chromseq = [newseq]
                    except:
                        self.errorLog('Contig assignment error!',quitchoice=True)
            ## ~ [0a] Auto-circularise/return ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            if self.i() < 0:
                if circdef: circularise = True
                elif len(chromseq) == 1:
                    self.assignSeqToHaplotig(chromseq[0],'H',seqlist)
                    return 1
            ## ~ [0b] Chromosome Assembly Menu ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            elif not midrun:
                menulist = []
                if len(chromseq) == 1:
                    headtext = '%s (1 contig)' % (chrom)
                    menulist.append(('C','Check %s for circularity' % chrom))
                    if circdef: default = 'C'
                    else: default = 'N'
                else:
                    headtext = '%s assembly (%s contigs)' % (chrom,rje.iLen(chromseq))
                    menulist += [('A','Assess and assemble %s' % chrom),('W','Walk-through assembly of %s' % chrom)]
                    if self.getBool('Diploid') and len(chromseq) == 2: default = 'N'
                    elif walk: default = 'W'
                    else: default = 'A'
                menulist.append(('H','Haplotype assignment only'))
                menulist.append(('E','Edit contigs'))
                menulist.append(('S','Save sequences and tidy table to *.assembly.fas and *.tidy.tdt'))
                menulist.append(('Q','Quit Assembly (back to tidy menu)'))
                if prev: menulist.append(('P','Previous chromosome'))
                menulist.append(('N','Next chromosome'))
                menulist.append(('L','Log manual assembly note. (#NOTE log entry)'))
                choice = rje_menu.menu(self,headtext,menulist,default=default,confirm=False)
                while choice:
                    if choice == 'C': circularise = True; break
                    if choice == 'N': return 1
                    if prev and choice == 'P': return -1
                    if choice == 'W': walk = True; break
                    if choice == 'A': walk = False; break
                    if choice == 'L':
                        lognote = rje.choice('#NOTE for log:')
                        if rje.yesNo('#NOTE: %s\n -> Add to log file?' % lognote):
                            self.printLog('#NOTE',lognote)
                        break
                    if choice == 'S':
                        seqlist.list['Seq'] = self.sortSeqs(seqlist.list['Seq'])
                        aseqfile = '%s%s.assemble.fas' % (self.getStr('AssembleDir'),self.fileBase('Assembly'))
                        seqlist.saveSeq(seqfile=aseqfile)
                        savefields = tdb.fields()
                        savefields.remove('Seq')
                        if tdb.entries(): tdb.saveToFile(savefields=savefields)
                    if choice == 'E':
                        #i# Note that seqlist sequences are stored as tuples
                        otherseq = rje.listDifference(seqlist.list['Seq'][0:],chromseq)
                        #self.debug('%d vs %d -> %d' % (seqlist.seqNum(),len(chromseq),len(otherseq)))
                        seqlist.list['Seq'] = chromseq
                        try:
                            seqlist.edit(save=False)
                            self.checkSeqs(seqlist)
                            editsave = True
                            for (etype,eacc,edesc) in seqlist.list['Edit']:
                                if etype[:3] in ['Sub','Rev','Div','Rem','Dup']:
                                    self.printLog('#SQ%s' % etype[:3].upper(),'%s: %s' % (eacc,edesc))
                            seqlist.list['Edit'] = []
                        except SystemExit: raise
                        except: editsave = False
                        chromseq = seqlist.list['Seq']
                        seqlist.list['Seq'] = chromseq + otherseq
                        #self.debug('=> %d & %d -> %d' % (len(chromseq),len(otherseq),seqlist.seqNum()))
                        self.sortSeqs(seqlist.list['Seq'])
                        self.checkSeqs(seqlist)
                        self.tidyTidyTable(seqlist)     #!# Don't edit sequence AND accnum together? (If tidied.)
                        seqlist.makeSeqNameDic('short')
                        rseqfile = '%s%s.edited.fas' % (self.getStr('AssembleDir'),self.fileBase('Assembly'))
                        if editsave: seqlist.saveSeq(seqfile=rseqfile)
                        else: raise KeyboardInterrupt
                        #self.debug('Final: %s = %d' % (rje.sortKeys(seqdict),len(seqdict)))
                        return self.assembleChrom(seqlist,chrom,chromseq,midrun=False,walk=walk,prev=prev)
                    if choice == 'H': haponly = True; break
                    if choice == 'Q' and rje.yesNo('Quit to menu? Are you sure?'): raise KeyboardInterrupt
                    choice = rje_menu.menu(self,headtext,menulist,default=default,confirm=False)

            ### ~ [1] Perform all-by-all BLAST ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            # Save and perform BLAST
            seqlist.saveSeq(seqfile=sfile,seqs=chromseq,reformat='short',backup=False)
            #gcmd = self.cmd_list + ['seqin=%s' % sfile,'searchdb=%s' % sfile,'minloclen=%d' % self.getInt('MinLocLen'),'qryacc=F','dna=T','blastp=blastn','fullblast=T','basefile=%s' % gbase]
            bcmd = self.cmd_list + ['blasti=%s' % sfile,'blastd=%s' % sfile,'blastp=blastn','blastf=F','basefile=%s' % sbase,'blasto=%s.blast' % sbase]
            blast = rje_blast.blastObj(self.log,bcmd+['backups=F','gablamfrag=0'])
            blast.formatDB(fasfile=sfile,protein=False,force=True,log=True,checkage=None,details=False)
            blast.blast(wait=True,cleandb=True,use_existing=False,log=True)
            blast.readBLAST(clear=True,gablam=False,unlink=False,local=True,screen=True,log=True,keepaln=True)
            ## ~ [1a] Tidy and filter results tables ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            # 'Run',['Run','Type','E-Value','DBase','InFile','BLASTCmd','Complexity Filter','Composition Statistics','SoftMask','GappedBLAST','OneLine','HitAln','DBLen','DBNum'],['Run']
            # 'Search',['Query','Length','Hits','MaxScore','TopE'],['Query']
            # 'Hit',['Query','Rank','Hit','Description','BitScore','E-Value','Length','Aln','GablamFrag','LocalCut','GABLAM'],['Query','Hit']
            # 'Local',['Query','Hit','AlnID','BitScore','Expect','Length','Identity','Positives','QryStart','QryEnd','SbjStart','SbjEnd','QrySeq','SbjSeq','AlnSeq'],['Query','Hit','AlnID']
            if not circularise:
                for table in ['Hit','Local']:    #,'GABLAM']:
                    blast.db(table).dropEntries(['Query==Hit'])   # No self-hits #!# This does not work. (Why?!)
            # blast.db('Local').dropEntries('Length<%d' % self.getInt('MinLocLen')) ?
            # Read Local table
            clocdb = blast.db('Local')
            clocdb.dropField('AlnSeq')
            clocdb.renameField('Query','Qry')
            # Pure check:
            sex = 0
            for entry in clocdb.entries():
                if entry['Qry'] == entry['Hit'] and not circularise:    #!# Something separate for circularisation #!#
                    #self.warnLog('%s Self-Hit detected and removed!' % entry['Qry'])
                    clocdb.dropEntry(entry); sex += 1
            self.printLog('#SELF','%s self-hits removed' % rje.iStr(sex))
            # Reformat data and add new fields
            clocdb.dataFormat({'AlnNum':'int','BitScore':'num','Expect':'num','Length':'int','Identity':'int','Positives':'int','QryStart':'int','QryEnd':'int','SbjStart':'int','SbjEnd':'int'})
            clocdb.renameField('SbjStart','HitStart')
            clocdb.renameField('SbjEnd','HitEnd')
            clocdb.renameField('SbjSeq','HitSeq')
            clocdb.addFields(['QryLen','HitLen'])
            cqrydb = blast.db('Search')
            for entry in clocdb.entries():
                entry['QryLen'] = cqrydb.data(entry['Qry'])['Length']
                entry['HitLen'] = cqrydb.data(entry['Hit'])['Length']
            # Rate overlaps. (May be overkill but useful for clarity/checking.)
            #i# Each hit is rated for the Query and Hit based on which part of the sequence is involved:
            #i# Start and End assessments are based on JoinMargin
            #i# Full: Start at seq beginning and End at seq end
            #i# Start: Start at seq beginning but End before seq end
            #i# End: Start beyond seq beginning and End at seq end
            #i# InvFull: End at seq beginning and Start at seq end
            #i# InvStart: End at seq beginning and Start within seq
            #i# InvEnd: Start at seq end and End within seq
            #i# Inverted: Start and end within sequence, inverted
            #i# Internal: Start and end of hit within sequence
            clocdb.addFields(['QryType','HitType'])
            for entry in clocdb.entries():
                for qh in ['Qry','Hit']:
                    if entry['%sStart' % qh] <= self.getInt('JoinMargin') < entry['%sEnd' % qh]:
                        if entry['%sEnd' % qh] >= (entry['%sLen' % qh]-self.getInt('JoinMargin')): entry['%sType' % qh] = 'Full'
                        else: entry['%sType' % qh] = 'Start'
                    elif entry['%sEnd' % qh] >= (entry['%sLen' % qh]-self.getInt('JoinMargin')) >  entry['%sStart' % qh]: entry['%sType' % qh] = 'End'
                    elif entry['%sEnd' % qh] <= self.getInt('JoinMargin'):
                        if entry['%sStart' % qh] >= (entry['%sLen' % qh]-self.getInt('JoinMargin')): entry['%sType' % qh] = 'InvFull'
                        else: entry['%sType' % qh] = 'InvStart'
                    elif entry['%sStart' % qh] >= (entry['%sLen' % qh]-self.getInt('JoinMargin')): entry['%sType' % qh] = 'InvEnd'
                    elif entry['%sStart' % qh] > entry['%sEnd' % qh]: entry['%sType' % qh] = 'Inverted'
                    else: entry['%sType' % qh] = 'Internal'
            clocdb.indexReport('QryType',logstr='#QTYPE')
            clocdb.indexReport('HitType',logstr='#HTYPE')
            #if self.dev():
            savefields = clocdb.fields()
            savefields.remove('QrySeq'); savefields.remove('HitSeq')
            clocdb.saveToFile(savefields=savefields)
            cassdb = blast.db().copyTable(clocdb,newname='Assemble')
            if haponly:
                chromseq = self.assignToHaplotig(chromseq,cassdb,seqlist)
                return self.assembleChrom(seqlist,chrom,chromseq,midrun=False,walk=walk,prev=prev)
            # Check for bad RevComp signs = non-self 1-x / 1-y or x-L / y-L overlaps
            for qtype in clocdb.index('QryType'):
                if qtype.startswith('Inv'): raise ValueError('QryType should not be inverted!')
            # Reduce to terminal overlaps
            invseq = []
            clocdb.dropEntriesDirect('QryType',['Start','End'],inverse=True)
            for htype in clocdb.index('HitType'):
                if htype in ['InvStart','InvFull','InvEnd']:
                    self.warnLog('%s inverted terminal hits detected: possible local inversion or RevComp errors' % rje.iLen(clocdb.index('HitType')[htype]))
                    for centry in clocdb.indexEntries('HitType',htype):
                        self.printLog('#%s' % htype.upper()[:4],'%s: %s vs %s' % (htype,centry['Qry'],centry['Hit']))
                        invseq += [centry['Qry'],centry['Hit']]
            clocdb.dropEntriesDirect('HitType',['Start','End'],inverse=True)
            eqx = 0
            for entry in clocdb.entries():
                if entry['QryType'] == entry['HitType']: clocdb.dropEntry(entry); eqx += 1
            if eqx: self.printLog('#TYPE','%s Start:Start or End:End hits removed.' % rje.iStr(eqx))
            if clocdb.entryNum() % 2: raise ValueError('Something has gone wrong with BLAST. Odd number of hits. Should be reciprocal!')
            clocdb.dropEntriesDirect('HitType',['Start'],inverse=True)
            while not clocdb.entryNum() and invseq:
                invseq = rje.sortUnique(invseq)
                self.printLog('#CJOIN','No possible contig joins: %d possible inverted sequences.' % len(invseq))
                ctext = '\n'
                for ci in range(len(invseq)): ctext += '<%d> : Reverse complement %s\n' % (ci+1,invseq[ci])
                ctext += '\n<0> : Continue without additional edits; <CTRL+C> to Quit'
                if self.i() >= 0: ji = rje.getInt(ctext,default=0,confirm=True)   #!# Add acceptable limits!
                else: ji = 0
                if not ji: break
                if ji < 0 or ji > len(invseq): continue
                sname = invseq[ji-1]
                iseq = seqdict[sname]
                si = seqlist.list['Seq'].index(iseq)
                (seqname,sequence) = seqlist.getSeq(iseq)
                chromseq.remove((seqname,sequence))
                seqname = string.split(seqname)
                if len(seqname) > 1 and seqname[1] == 'RevComp': seqname.pop(1)
                else: seqname.insert(1,'RevComp')
                seqname = string.join(seqname)
                sequence = rje_sequence.reverseComplement(sequence)
                self.printLog('#EDIT','%s -> %s' % (sname,seqname))
                seqdict[sname] = seqlist.list['Seq'][si] = (seqname,sequence)
                chromseq.insert(0,(seqname,sequence))
                return self.assembleChrom(seqlist,chrom,chromseq,midrun=True,walk=walk,prev=prev)

            # Assign haplotigs if no joins possible, else report and proceed
            if not clocdb.entryNum():
                self.printLog('#CJOIN','No possible contig joins: assigning haplotigs.')
                chromseq = self.assignToHaplotig(chromseq,cassdb,seqlist)
                return self.assembleChrom(seqlist,chrom,chromseq,midrun=False,walk=walk,prev=prev)
            self.printLog('#CJOIN','%d possible %s contig joins' % (clocdb.entryNum(),chrom))

            ### ~ [3] Work through possible contig joins and repeat process until done ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            #i# Possible joins are sorted by either length or identity (joinsort=X). Neither is perfect, so need to use
            #i# the assembly graphics as a guide.
            joinsort = self.getStrLC('JoinSort')   #'Length'
            cjoins = []     # List of (joinID,qryLen,entry) tuples
            for entry in clocdb.entries():
                if joinsort == 'identity':   # Add -ve identity to sort from big to small. (Could use % difference?)
                    cjoins.append((-float(entry['Identity'])/entry['Length'],entry['QryLen'],entry))
                elif joinsort == 'length':
                    cjoins.append((entry['Length'],entry['QryLen'],entry))
                else: raise ValueError('joinsort="%s" not recognised. (Length/Identity)' % self.getStr('JoinSort'))
            cjoins.sort(reverse=False)

            ## ~ [3a] Reorder for walkthrough ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            wsplit = []     # List of cjoin indices marking splits
            if walk:
                try:
                    # Did remove block self-hits but this caused some issues...
                    #for entry in clocdb.entries()[0:]:
                    #    try:
                    #        qblock = rje.matchExp('\D(\d+)$',entry['Qry'])[0]
                    #        hblock = rje.matchExp('\D(\d+)$',entry['Hit'])[0]
                    #        if qblock == hblock: clocdb.dropEntry(entry)
                    #    except: continue

                    # Set up a new list of the revised order - only include non-screened hits.
                    wjoins = []
                    for cjoin in cjoins:
                        if cjoin[-1] in clocdb.entries(): wjoins.append(cjoin)
                    cjoins = []
                    # Identify initial ends of walks
                    qrylist = clocdb.indexKeys('Qry',force=True,log=False)
                    hitlist = clocdb.indexKeys('Hit',force=True,log=False)
                    endlist = rje.listDifference(hitlist,qrylist) # Returns the elements of list1 that are not found in list2
                    donelist = []
                    #self.debug('%s' % endlist)
                    # Loop until all cjoins have been processed
                    while wjoins and endlist:
                        # Identify queries for
                        joinlist = clocdb.dataList(clocdb.indexEntries('Hit',endlist),'Qry')
                        if not joinlist: break
                        ex = 0
                        # Loop and add extra Hits for EndList Queries
                        while ex != len(endlist):
                            ex = len(endlist)
                            joinend = clocdb.dataList(clocdb.indexEntries('Qry',joinlist),'Hit')
                            endlist = rje.listUnion(endlist,joinend)
                            endlist = rje.listDifference(endlist,donelist)
                            joinlist = clocdb.dataList(clocdb.indexEntries('Hit',endlist),'Qry')
                            joinlist = rje.listDifference(joinlist,donelist)
                            #self.debug('%s -> %s >> %s' % (ex,joinlist,endlist))
                        # Generate cjoins
                        ci = 0
                        while ci < len(wjoins):
                            entry = wjoins[ci][-1]
                            if entry['Qry'] in joinlist: cjoins.append(wjoins.pop(ci))
                            else: ci += 1
                        if wjoins: wsplit.append(len(cjoins))
                        donelist += endlist
                        endlist = rje.listDifference(joinlist,donelist)
                        #self.debug('%s -> %s' % (ex,endlist))
                        #self.debug('joins: %s / %s' % (len(wjoins),len(cjoins)))
                    if wjoins: cjoins += wjoins
                except:
                    self.errorLog('Walk error')
            else:
                qrylist = clocdb.indexKeys('Qry',force=True,log=False)
                hitlist = clocdb.indexKeys('Hit',force=True,log=False)


            ## ~ [3b] Present choices ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            ctext = '\n'
            #i# Report a list of sequences without any join entries
            nojoins = []
            for (name,sequence) in chromseq:
                sname = string.split(name)[0]
                if sname not in qrylist+hitlist: nojoins.append(string.split(sname,'__')[-1])
            if nojoins:
                ctext += 'Sequences without join (Start/End overlap) hits:\n -- %s\n\n' % string.join(nojoins,'; ')
            #i# Give join options, highlight those that are "singletons"
            singles = []; default = 0
            for ci in range(len(cjoins)):
                entry = cjoins[ci][-1]
                if ci in wsplit: ctext += '---\n'
                if len(clocdb.index('Qry')[entry['Qry']]) == 1:
                    if not default: default = ci + 1
                    if entry['Qry'] in clocdb.index('Hit'): qbracket = '+'
                    else: qbracket = '!'
                elif entry['Qry'] in clocdb.index('Hit'): qbracket = '<'
                else: qbracket = '|<'
                if len(clocdb.index('Hit')[entry['Hit']]) == 1:
                    if not default: default = ci + 1
                    if entry['Hit'] in clocdb.index('Qry'): hbracket = '+'
                    else: hbracket = '!'
                elif entry['Hit'] in clocdb.index('Qry'): hbracket = '>'
                else: hbracket = '>|'
                cjtext = '%s%d%s : ' % (qbracket,ci+1,hbracket)
                qacc = string.split(entry['Qry'],'__')[-1]
                hacc = string.split(entry['Hit'],'__')[-1]
                cjtext += 'Join %s %s-%s <-&-> %s %s-%s (%s nt = %.2f%% identity)\n' % (qacc,rje.iStr(entry['QryStart']),rje.iStr(entry['QryEnd']),hacc,rje.iStr(entry['HitStart']),rje.iStr(entry['HitEnd']),rje.iStr(entry['Length']),100.0*float(entry['Identity'])/entry['Length'])
                #if qbracket in '+!' and hbracket in '+!':
                if qbracket in '+!' or hbracket in '+!':
                    if not singles and default != 1: default = ci + 1
                    singles.append(cjtext)
                ctext += cjtext
            if not default: default = 1
            #i# Repeat singles
            if singles and len(singles) < len(cjoins):
                ctext += '===\nTop joins:\n'
                ctext += string.join(singles,sep='')
            ctext += '===\n'
            entry = None    # Local hit entry that forms basis of join
            if singles and auto:
                entry = cjoins[default-1][-1]
            elif singles and len(singles) == len(cjoins) and rje.yesNo('%s\n\nAuto-assemble remaining joins?' % ctext):
                auto = True
                entry = cjoins[default-1][-1]
            else:
                auto = False
                entry = None
                if singles:
                    ctext += '<%d> Auto-assemble recommended joins.\n' % (len(cjoins) + 1)
                ctext += '===\n'
                ctext += '<0> : Exit to %s menu; <CTRL+C> to Quit to main menu; Use -ve number to use name of contig 2.\n\nJoin choice?' % chrom

            # Select the join to perform
            namekey = 'Qry' # Key for field that is to be used for new sequence name.
            while not entry:
                if self.i() >= 0: ji = rje.getInt(ctext,default=default,confirm=False)
                else: ji = default
                vi = ji
                #i# If j<1, invert and keep the Hit as the focal name etc.
                entry = None
                if ji < 0:
                    ji = -ji
                    if ji > len(cjoins): self.verbose('Invalid choice!',v=self.v(),i=self.i()); continue
                    #x# entry = self.invertLocalEntry(cjoins[ji-1][-1])
                    namekey = 'Hit'
                elif ji:
                    if singles and ji == len(cjoins) + 1 and rje.yesNo('Auto-assemble recommended joins?'):
                        auto = True
                        entry = cjoins[default-1][-1]; break
                    elif ji > len(cjoins): self.verbose('Invalid choice!',v=self.v(),i=self.i()); continue
                    else: entry = cjoins[ji-1][-1]
                #i# Verify the selection
                if ji: vtext = '<%d> : Join %s <- %s (%.2f%% x %s nt)?' % (vi,entry['Qry'],entry['Hit'],100.0*float(entry['Identity'])/entry['Length'],rje.iStr(entry['Length']))
                else: vtext = '<0> : Abort join for %s?' % chrom
                if self.i() >= 0 and not rje.yesNo(vtext): entry = None; continue
                if not ji:
                    chromseq = self.assignToHaplotig(chromseq,cassdb,seqlist)
                    return self.assembleChrom(seqlist,chrom,chromseq,midrun=False,walk=walk,prev=prev)

            ### ~ [4] Perform join of the selected contig pair ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            #i# This joins the two sequences in entry
            ## ~ [4a] Setup join data ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            qacc = string.split(entry['Qry'],'__')[-1]
            hacc = string.split(entry['Hit'],'__')[-1]
            joinkey = {'Hit':'Qry','Qry':'Hit'}[namekey]
            jacc = string.split(entry[namekey],'__')[-1]
            ## ~ [4b] Make consensus sequence. (Original method.) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            #i# NOTE: This method is not recommended and should not be used!
            if self.getStrLC('JoinMerge') == 'consensus':
                self.warnLog('joinmerge=consensus no longer supported -> joinmerge=mid')
                self.setStr({'JoinMerge':'mid'})
            if self.getStrLC('JoinMerge') == 'consensus':
                jname = 'Consensus:%s:%s-%s/%s:%s-%s (%snt = %.2f%% identity)' % (qacc,rje.iStr(entry['QryStart']),rje.iStr(entry['QryEnd']),hacc,rje.iStr(entry['HitStart']),rje.iStr(entry['HitEnd']),rje.iStr(entry['Length']),100.0*float(entry['Identity'])/entry['Length'])
                jsequence = seqlist.makeConsensus(entry['QrySeq'],[entry['HitSeq']])
                gapx = jsequence.count('-')
                jsequence = jsequence.replace('-','')
                #seqlist._addSeq(jname,jsequence)
                jseq = (jname,jsequence)
                self.printLog('#SEQ','Sequence added: %s = %s nt; %s gaps removed.' % (jname,rje.iLen(jsequence),rje.iStr(gapx)))
                # Trim Query and Hit
                if circularise:     # Trim off both ends!
                    if entry['Qry'] != entry['Hit']: raise ValueError
                    qh = 'Qry'
                    chromseq.remove(seqdict[entry[qh]])
                    (seqname,sequence) = seqdict[entry[qh]]
                    si = seqlist.list['Seq'].index(seqdict[entry[qh]])
                    if entry['%sType' % qh] == 'Start':
                        x = entry['%sEnd' % qh] + 1
                        y = entry['HitStart'] - 1
                    elif entry['%sType' % qh] == 'End':
                        x = entry['HitEnd'] + 1
                        y = entry['%sStart' % qh] - 1
                    else: raise ValueError(entry['%sType' % qh])
                    sequence = sequence[x-1:y]
                    self.printLog('#EDIT','%s -> Region %d to %d.' % (seqname,x,y))
                    seqname = '%s (Region %d to %d)' % (seqname,x,y)
                    seqdict[entry[qh]] = seqlist.list['Seq'][si] = (seqname,sequence)
                    # Perform join
                    qseq = seqdict[entry['Qry']]
                    joinseq = (jseq,qseq)
                    seqdesc = 'Circle[%s & %s]' % (joinseq[0][0],joinseq[1][0])
                    seqname = '%s %s' % (string.split(joinseq[1][0])[0],seqdesc)
                    sequence = joinseq[0][1] + joinseq[1][1]
                    qi = seqlist.list['Seq'].index(qseq)
                    seqdict[entry['Qry']] = seqlist.list['Seq'][qi] = (seqname,sequence)
                    self.printLog('#EDIT',seqdesc)
                    chromseq.insert(0,(seqname,sequence))
                else:
                    for qh in ['Qry','Hit']:
                        try: chromseq.remove(seqdict[entry[qh]])
                        except: self.warnLog('%s %s not found in %s chromseq dictionary?!' % (qh,entry[qh],chrom))
                        #!# This happens if manual editing of sequence between Assembly runs: make sure chromseq is regenerated at right point.
                        (seqname,sequence) = seqdict[entry[qh]]
                        si = seqlist.list['Seq'].index(seqdict[entry[qh]])
                        if entry['%sType' % qh] == 'Start':
                            x = entry['%sEnd' % qh] + 1
                            y = len(sequence)
                        elif entry['%sType' % qh] == 'End':
                            x = 1
                            y = entry['%sStart' % qh] - 1
                        else: raise ValueError(entry['%sType' % qh])
                        sequence = sequence[x-1:y]
                        self.printLog('#EDIT','%s -> Region %d to %d.' % (seqname,x,y))
                        seqname = '%s (Region %d to %d)' % (seqname,x,y)
                        seqdict[entry[qh]] = seqlist.list['Seq'][si] = (seqname,sequence)
                    # Perform join
                    qseq = seqdict[entry['Qry']]
                    hseq = seqdict[entry['Hit']]
                    if entry['QryType'] == 'End':
                        joinseq = (seqdict[entry['Qry']],jseq,seqdict[entry['Hit']])
                        seqdesc = 'Join[%s & %s & %s]' % (joinseq[0][0],joinseq[1][0],joinseq[2][0])
                        seqname = '%s %s' % (string.split(joinseq[0][0])[0],seqdesc)
                    elif entry['QryType'] == 'Start':
                        joinseq = (seqdict[entry['Hit']],jseq,seqdict[entry['Qry']])
                        seqdesc = 'Join[%s & %s & %s]' % (joinseq[0][0],joinseq[1][0],joinseq[2][0])
                        seqname = '%s %s' % (string.split(joinseq[2][0])[0],seqdesc)
                    else: raise ValueError(entry['QryType'])
                    sequence = joinseq[0][1] + joinseq[1][1] + joinseq[2][1]
                    qi = seqlist.list['Seq'].index(qseq)
                    hi = seqlist.list['Seq'].index(hseq)
                    seqdict[entry['Qry']] = seqlist.list['Seq'][qi] = (seqname,sequence)
                    self.printLog('#EDIT',seqdesc)
                    seqlist.list['Seq'].pop(hi)
                    seqdict.pop(entry['Hit'])
                    chromseq.insert(0,(seqname,sequence))
            ## ~ [4c] Simpler cut and stick join methods ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            #i# Different methods will join different parts of start/end
            else:
                # Check and update the joinmerge method
                if self.getStrLC('JoinMerge') not in ['end','start','longest','mid']:   #!# Add depth?
                    self.warnLog('JoinMerge=%s not recognised: will use "end" mode.' % self.getStr('JoinMerge'))
                    self.setStr({'JoinMerge':'mid'})
                jm = self.getStrLC('JoinMerge')
                #i# If joinmerge=longest, either keep all of the longest sequence, else mid-join in case of a tie
                if jm == 'longest':
                    if entry['QryLen'] > entry['HitLen']: jm = 'end'
                    elif entry['QryLen'] < entry['HitLen']: jm = 'start'
                    else: jm = 'mid'
                # Determine cut positions.
                #i# Query is always the first sequence, the end of which is joined to the start of the Hit
                #i# jacc = AccNum used for new name
                #i# qend = New end for query sequence 1-L
                #i# hbeg = New beginning for hit sequence 1-L
                qx = entry['QryStart']    #i# Start of Query region being joined
                qy = entry['QryLen']      #i# End of Query region being joined
                hy = entry['HitEnd']      #i# End of Hit region being joined
                qend = qy; hbeg = hy + 1  #i# Default is end join
                if jm == 'start': qend = qx - 1; hbeg = 1
                elif jm == 'mid':       #i# Need to map the hits back onto the alignment
                    amid = int(len(entry['QrySeq'])/2.0)
                    qseq = entry['QrySeq'][:amid]
                    qend = qx + len(qseq) - qseq.count('-') - 1
                    hseq = entry['HitSeq'][:amid]
                    hbeg = len(hseq) - hseq.count('-') + entry['HitStart']  # May be fudged by joinmargin

                # Trim Query and Hit to generate circular sequence
                if circularise:
                    #!# Need to update this! #!#

                    if entry['Qry'] != entry['Hit']: raise ValueError
                    # Want to keep the end
                    qh = 'Qry'
                    chromseq.remove(seqdict[entry[qh]])
                    (seqname,sequence) = seqdict[entry[qh]]
                    si = seqlist.list['Seq'].index(seqdict[entry[qh]])
                    try: (sname,seqdesc) = string.split(seqname,maxsplit=1)
                    except: sname = seqname; seqdesc = ''

                    if entry['QryType'] == 'Start':     # Want to chop of the overlapping region from the query
                        x = entry['QryEnd'] + 1
                    elif entry['QryType'] == 'End':     # Want to chop of the overlapping region from the hit
                        x = entry['HitEnd'] + 1
                    else: raise ValueError(entry['QryType'])
                    y = len(sequence)                   # Always want to keep the end of the sequence

                    sequence = sequence[x-1:y]
                    self.printLog('#EDIT','%s -> Circle[Region %d to %d]' % (seqname,x,y))
                    seqname = '%s Circle[Region %d to %d|%s]' % (sname,x,y,seqdesc)
                    seqdict[entry[qh]] = seqlist.list['Seq'][si] = (seqname,sequence)
                    # Perform join
                    qseq = seqdict[entry['Qry']]
                    qi = seqlist.list['Seq'].index(qseq)
                    seqdict[entry['Qry']] = seqlist.list['Seq'][qi] = (seqname,sequence)
                    chromseq.insert(0,(seqname,sequence))
                    #!# Should check/add -A or -H suffix.
                # Trim Query and Hit for join
                else:
                    # Remove the current sequences from chromseq and modify sequences
                    for qh in ['Qry','Hit']:
                        #i# Error happens if manual editing of sequence between Assembly runs: make sure chromseq is regenerated at right point.
                        #i# Should not happen any more!
                        try: chromseq.remove(seqdict[entry[qh]])
                        except: self.warnLog('%s %s not found in %s chromseq dictionary?! Contact author!' % (qh,entry[qh],chrom))
                        # Extract and update sequence
                        (seqname,sequence) = seqdict[entry[qh]]
                        si = seqlist.list['Seq'].index(seqdict[entry[qh]])  # index in SeqList for replacement
                        if qh == 'Qry': x = 1; y = qend
                        else: x = hbeg; y = len(sequence)
                        sequence = sequence[x-1:y]
                        self.printLog('#EDIT','%s -> Region %d to %d.' % (seqname,x,y))
                        seqname = '%s (Region %d to %d)' % (seqname,x,y)
                        seqdict[entry[qh]] = seqlist.list['Seq'][si] = (seqname,sequence)
                    # Perform join between modified sequences
                    #i# NOTE: joins are now always between the Qry End and Hit Start
                    #i# hplus is the length shift of Hits in the tidy table
                    #i# = the length of the query fragment, minus the chunk of the hit that was trimmed
                    qseq = seqdict.pop(entry['Qry'])
                    hseq = seqdict.pop(entry['Hit'])
                    seqlist.list['Seq'].remove(hseq)
                    qi = seqlist.list['Seq'].index(qseq)    # This will be replaced
                    # New sequence is the simple join
                    sequence = qseq[1] + hseq[1]
                    hplus = len(sequence) - entry['HitLen']
                    # Just keep the accnum and desc for the sequences in the join description
                    jacc = '%s.%s' % (jacc,string.split(entry[joinkey],'.')[-1])
                    seqdesc = 'Join[%s & %s]' % (string.split(qseq[0],'__',maxsplit=1)[-1],string.split(hseq[0],'__',maxsplit=1)[-1])
                    seqname = '%s__%s %s' % (string.split(qseq[0],'__')[0],jacc,seqdesc)
                    seqdict[jacc] = seqlist.list['Seq'][qi] = (seqname,sequence)
                    #self.debug(seqdict.keys())
                    #self.debug(seqlist.makeSeqNameDic().keys())
                    self.printLog('#JOIN','%s + %s -> %s' % (qacc,hacc,seqdesc))  #i# These lines can be pulled out for join history
                    # Add the new sequence back to chromseq
                    chromseq.insert(0,(seqname,sequence))
                    # Setup new tidy table entry
                    jentry = {'Contig':jacc,'Start':entry['QryStart'],'End':len(sequence)-(entry['HitLen']-entry['HitEnd'])}
                    #self.debug('Make: %s-%s' % (jentry['Start'],jentry['End']))
                    jentry['Desc'] = seqdesc
                    jentry['Seq'] = sequence    #?# What is this used for?
                    # Update tidy table. Check whether query entries exceed qend or hit entries precede hbeg
                    tdb.index('Contig',force=True)
                    for tentry in tdb.indexEntries('Contig',hacc):
                        if tentry['End'] < hbeg: tdb.dropEntry(tentry); continue   # Chopped off region!
                        tentry['End'] += hplus
                        if tentry['Start'] < hbeg:
                            jentry['End'] = max(jentry['End'],tentry['End'])
                            tdb.dropEntry(tentry); continue     # Merge
                        tentry['Start'] += hplus
                        tentry['Contig'] = jacc
                        tentry['Desc'] = seqdesc
                        tentry['Seq'] = sequence
                    for tentry in tdb.indexEntries('Contig',qacc):
                        if tentry['Start'] > qend: tdb.dropEntry(tentry); continue   # Chopped off region!
                        if tentry['End'] > qend:
                            jentry['Start'] = min(jentry['Start'],tentry['Start'])
                            tdb.dropEntry(tentry); continue     # Merge
                        tentry['Contig'] = jacc
                        tentry['Desc'] = seqdesc
                        tentry['Seq'] = sequence
                    tdb.addEntry(jentry)
                    #self.debug('Add: %s-%s' % (jentry['Start'],jentry['End']))

            self.checkSeqs(seqlist)
            return self.assembleChrom(seqlist,chrom,chromseq,midrun=True,walk=walk,prev=prev,auto=auto)

        except KeyboardInterrupt: raise
        except SystemExit: raise
        except: self.errorLog('%s.assembleChrom() error' % self.prog()); return 0
#########################################################################################################################
    def assignToHaplotig(self,chromseq,cassdb,seqlist):   ### Assigns contigs mapped onto a single chromosome to A/B/N haplotigs.
        '''
        Assigns contigs mapped onto a single chromosome to A/B/N haplotigs.
        >> chromseq = List of (name,sequence) for chromosome.
        >> cassdb:Table = Modified local hit table for contigs. [Created by assembleChrom()]
        >> seqlist:SeqList object containing sequences.
        << chromseq:updated list of sequences
        '''
        try:### ~ [0] Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            #i# Start and End assessments are based on JoinMargin...
            #i# Full: Start at seq beginning and End at seq end
            #i# Start: Start at seq beginning but End before seq end
            #i# End: Start beyond seq beginning and End at seq end
            #i# InvFull: End at seq beginning and Start at seq end
            #i# InvStart: End at seq beginning and Start within seq
            #i# InvEnd: Start at seq end and End within seq
            #i# Inverted: Start and end within sequence, inverted
            #i# Internal: Start and end of hit within sequence
            ## ~ [0a] Reduce hits to ones involving ends: internal-internal hits ignored ~~~~~~~~~~ ##
            cassdb.dropEntriesDirect('HitType',['Internal','Inverted'])
            cassdb.index('Hit')
            ## ~ [0b] Sort Queries by length and work big -> small ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            qsort = []; seqdict = {}
            for seq in chromseq:
                qsort.append((len(seq[1]),string.split(seq[0])[0]))
                seqdict[string.split(seq[0])[0]] = seq
            qsort.sort(reverse=True)
            self.debug(qsort)

            ### ~ [1] Assign haplotigs ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            #i# The longest contig becomes haplotig A (diploid) or H (haploid).
            #i# Any sequence overlapping with A contigs only, becomes haplotig B if diploid=T, else N.
            #i# Any sequence overlapping with A and B becomes haplotig N.
            #i# Any sequence overlapping with neither A nor B becomes A. (Or H)
            htig = {'A':[],    # List on non-overlappng A contigs
                    'B':[],    # List of contigs, overlapping A but not each other
                    'N':[]}    # List of "messy" contigs
            ## ~ [1a] Work through contigs in length order ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            if self.getBool('Diploid') and len(qsort) == 2:
                htig['A'] = [qsort.pop(0)[1]]
                htig['B'] = [qsort.pop(0)[1]]
            while qsort:
                hit = qsort.pop(0)[1]
                if hit in htig['A'] + htig['B'] + htig['N']: raise ValueError('Multiple %s!' % hit)
                qlist = cassdb.indexDataList('Hit',hit,'Qry')
                # Identify non-(internal-internal) overlaps
                alist = rje.listIntersect(htig['A'],qlist)
                blist = rje.listIntersect(htig['B'],qlist)
                if alist:
                    if blist: htig['N'].append(hit)
                    else: htig['B'].append(hit)
                else: htig['A'].append(hit)
            ## ~ [1b] Adjust for haploid ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            if not self.getBool('Diploid'):
                htig['H'] = htig.pop('A')
                htig['N'] = htig.pop('B') + htig['N']

            ### ~ [2] Rename sequences ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            self.printLog('#~~#','## ~~~~~~~~~~~~~~~~~~~~~~~~~~~ Haplotig Assignment ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##')
            hapseq = []
            for c in 'HABN':
                if c not in htig: continue
                self.printLog('#HTIG%s' % c,string.join(htig[c],'; '))
                for contig in htig[c]:
                    cseq = seqdict[contig]
                    if seqlist.seqGene(cseq).endswith(c): hapseq.append(cseq); continue
                    if seqlist.seqGene(cseq)[-1] in 'ABHN':
                        newgene = seqlist.seqGene(cseq)[:-1] + c
                    else: newgene = seqlist.seqGene(cseq) + c
                    newname = '%s_%s__%s %s' % (newgene,seqlist.seqSpec(cseq),seqlist.seqAcc(cseq),seqlist.seqDesc(cseq))
                    ci = seqlist.list['Seq'].index(cseq)
                    newseq = (newname,cseq[1])
                    seqlist.list['Seq'][ci] = newseq
                    seqdict.pop(contig)
                    seqdict[seqlist.shortName(newseq)] = newseq
                    hapseq.append(newseq)
            return hapseq
        except: self.errorLog('%s.assignToHaplotig() error' % self.prog())
#########################################################################################################################
    def BADassignToHaplotig(self,blast,cassdb,seqdict,seqlist):   ### Assigns contigs mapped onto a single chromosome to A/B/N haplotigs.
        '''
        Assigns contigs mapped onto a single chromosome to A/B/N haplotigs.
        >> blast:BLASTObj = BLAST Object with local hits for contigs.
        >> cassdb:Table = Modified local hit table for contigs. [Created by assembleChrom()]
        >> seqdict:dictionary of sequence names to objects.
        >> seqlist:SeqList object containing sequences.
        '''
        try:### ~ [0] Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            qdb = blast.db('Search')    # 'Search Table',['Query','Length','Hits','MaxScore','TopE'],['Query']
            #i# Start and End assessments are based on JoinMargin...
            #i# Full: Start at seq beginning and End at seq end
            #i# Start: Start at seq beginning but End before seq end
            #i# End: Start beyond seq beginning and End at seq end
            #i# InvFull: End at seq beginning and Start at seq end
            #i# InvStart: End at seq beginning and Start within seq
            #i# InvEnd: Start at seq end and End within seq
            #i# Inverted: Start and end within sequence, inverted
            #i# Internal: Start and end of hit within sequence
            ## ~ [0a] Reduce hits to ones involving ends: internal-internal hits ignored ~~~~~~~~~~ ##
            cassdb.dropEntriesDirect('HitType',['Internal','Inverted'])
            cassdb.index('Hit')
            ## ~ [0b] Sort Queries by length and work big -> small ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            qsort = []
            for entry in qdb.entries(): qsort.append((entry['Length'],entry['Query']))
            qsort.sort(reverse=True)
            self.debug(qsort)

            ### ~ [1] Assign haplotigs ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            #i# The longest contig becomes haplotig A (diploid) or H (haploid).
            #i# Any sequence overlapping with A contigs only, becomes haplotig B if diploid=T, else N.
            #i# Any sequence overlapping with A and B becomes haplotig N.
            #i# Any sequence overlapping with neither A nor B becomes A. (Or H)
            htig = {'A':[],    # List on non-overlappng A contigs
                    'B':[],    # List of contigs, overlapping A but not each other
                    'N':[]}    # List of "messy" contigs
            ## ~ [1a] Work through contigs in length order ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            if self.getBool('Diploid') and len(qsort) == 2:
                htig['A'] = [qsort.pop(0)[1]]
                htig['B'] = [qsort.pop(0)[1]]
            while qsort:
                hit = qsort.pop(0)[1]
                qlist = cassdb.indexDataList('Hit',hit,'Qry')
                # Identify non-(internal-internal) overlaps
                alist = rje.listIntersect(htig['A'],qlist)
                blist = rje.listIntersect(htig['B'],qlist)
                if alist:
                    if blist: htig['N'].append(hit)
                    else: htig['B'].append(hit)
                else: htig['A'].append(hit)
            ## ~ [1b] Adjust for haploid ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            if not self.getBool('Diploid'):
                htig['H'] = htig.pop('A')
                htig['N'] = htig.pop('B') + htig['N']

            ### ~ [2] Rename sequences ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            self.printLog('#~~#','## ~~~~~~~~~~~~~~~~~~~~~~~~~~~ Haplotig Assignment ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##')
            for c in 'HABN':
                if c not in htig: continue
                self.printLog('#HTIG%s' % c,string.join(htig[c],'; '))
                for contig in htig[c]:
                    cseq = seqdict[contig]
                    if seqlist.seqGene(cseq).endswith(c): continue
                    if seqlist.seqGene(cseq)[-1] in 'ABHN':
                        newgene = seqlist.seqGene(cseq)[:-1] + c
                    else: newgene = seqlist.seqGene(cseq) + c
                    newname = '%s_%s__%s %s' % (newgene,seqlist.seqSpec(cseq),seqlist.seqAcc(cseq),seqlist.seqDesc(cseq))
                    ci = seqlist.list['Seq'].index(cseq)
                    newseq = (newname,cseq[1])
                    seqlist.list['Seq'][ci] = newseq
                    seqdict.pop(contig)
                    seqdict[seqlist.shortName(newseq)] = newseq

            #!# Add summary of status and pause for to enable reader to see?

            return htig
        except: self.errorLog('%s.assignToHaplotig() error' % self.prog())
#########################################################################################################################
    def assignSeqToHaplotig(self,cseq,hap,seqlist,seqdict={}):   ### Assigns a single contig to A/B/N haplotigs.
        '''
        Assigns a single contig to A/B/N haplotigs.
        >> cseq:Sequence = Sequence Object to update.
        >> hap:str = New haplotig
        >> seqlist:SeqList object containing sequence.
        >> seqdict:optional sequence {name:Sequence} dictionary to update.
        '''
        try:### ~ [0] Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            contig = seqlist.shortName(cseq)
            if seqlist.seqGene(cseq).endswith(hap): return contig
            if seqlist.seqGene(cseq)[-1] in 'ABHN':
                newgene = seqlist.seqGene(cseq)[:-1] + hap
            else: newgene = seqlist.seqGene(cseq) + hap
            newname = '%s_%s__%s %s' % (newgene,seqlist.seqSpec(cseq),seqlist.seqAcc(cseq),seqlist.seqDesc(cseq))
            ci = seqlist.list['Seq'].index(cseq)
            newseq = (newname,cseq[1])
            seqlist.list['Seq'][ci] = newseq
            if seqdict:
                seqdict.pop(contig)
                seqdict[seqlist.shortName(newseq)] = newseq
            return newname
        except: self.errorLog('%s.assignSeqToHaplotig() error' % self.prog())
#########################################################################################################################
    def invertLocalEntry(self,entry):   ### Returns a local BLAST hit entry with Query and Hit reversed.
        '''Returns a local BLAST hit entry with Query and Hit reversed. This does not affect the original.'''
        try:### ~ [0] Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            #i# This is designed as part of the assembleChrom() process. The original fields are:
            #i# ['Query','Hit','AlnID','BitScore','Expect','Length','Identity','Positives','QryStart','QryEnd','SbjStart','SbjEnd','QrySeq','SbjSeq','AlnSeq']
            #i# During assembleChrom(), the key fields become:
            #i# ['Qry','Hit','AlnID','BitScore','Expect','Length','Identity','Positives','QryStart','QryEnd','HitStart','HitEnd','QrySeq','HitSeq','QryLen','HitLen','QryType','HitType']
            #># The following %sX fields must swap between Qry and Hit: ['','Start','End','Seq','Len','Type']
            #># The following do not change: ['AlnID','BitScore','Expect','Length','Identity','Positives']
            reventry = {}
            swapfields = ['','Start','End','Seq','Len','Type']
            keepfields = ['AlnID','BitScore','Expect','Length','Identity','Positives']
            ### ~ [1] Swap ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            for swap in swapfields:
                for qh in [('Qry','Hit'),('Hit','Qry')]:
                    fields = ('%s%s' % (qh[0],swap),'%s%s' % (qh[1],swap))
                    if fields[0] in entry: reventry[fields[1]] = entry[fields[0]]
            for keep in keepfields:
                if keep in entry: reventry[keep] = entry[keep]
            return reventry
        except: self.errorLog('%s.invertLocalEntry() error' % self.prog())
#########################################################################################################################
    def assemble(self,seqlist=None,seqfile=None,chrlist=[]):  ### Generates summary of statistics across multiple PAGSAT runs.
        '''Generates summary of statistics across multiple PAGSAT runs.'''
        try:### ~ [0] Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            self.devLog('#RUN','assemble')
            if self.i() < 0:
                self.warnLog('Cannot perform PAGSAT Manual Assembly if interactivity i<0: will use auto settings.')
            db = self.db()
            self.printLog('#~~#','## ~~~~~~~~~~~~~~~~~~~~~~~~~ PAGSAT Manual Assembly ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##')
            if not seqlist:
                if not seqfile: raise ValueError('PAGSAT.assemble() needs seqlist or seqfile!')
                seqcmd = self.cmd_list + ['seqin=%s' % seqfile,'dna=T','autoload=F','seqmode=list']
                seqlist = rje_seqlist.SeqList(self.log,seqcmd)
                seqlist.loadSeq()
            elif not seqfile: seqfile = seqlist.getStr('SeqIn')
            assdir = self.getStr('AssembleDir')
            cgablamdir = rje.makePath('%sChromGABLAM/' % assdir)    # Where to generate GABLAM data.
            rje.mkDir(self,cgablamdir)
            self.setStr({'CtgGABLAMDir':cgablamdir})
            ## ~ [0a] Initial split of sequences per chromosome ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            chromlist = chrlist[0:]
            splitseq = {}       # Dictionary of sequence tuples per chromosome
            seqdict = seqlist.makeSeqNameDic('short')  # Dictionary of shortname to sequence
            for sname in rje.sortKeys(seqdict):
                chrom = string.split(sname,'_')[0]
                if chrom[-1:] in ['H','A','B','N']: chrom = chrom[:-1]  # This should always be true but checking for future compatibility
                if chrom not in splitseq: splitseq[chrom] = []
                splitseq[chrom].append(seqdict[sname])
                if chrom not in chromlist: chromlist.append(chrom)

            ### ~ [1] Cycle through each chromosome and try to iteratively assemble it ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            chrom2assemble = rje.sortKeys(splitseq)
            for chrom in chromlist[0:]:
                if chrom not in chrom2assemble: chromlist.remove(chrom)
            if 'Orphan' in chromlist:  chromlist.remove('Orphan'); chromlist.append('Orphan')
            #!# Make this a method for each chromosome?
            # Include localnfas output without alnseq
            walk = rje.yesNo('Peform "walk-through" assembly from 3\' end?',default="Y")
            #i# Allow a +1/0/-1 walk up and down chromlist
            ci = 0
            while ci < len(chromlist):
                chrom = chromlist[ci]
                if chrom == 'Orphan' and self.yesNo('Process each Orphan separately?',default='Y'):
                    for seq in splitseq[chrom]:
                        sname = seqlist.shortName(seq)
                        self.assembleChrom(seqlist,sname,[seq],walk=walk,prev=False)
                    ci += 1
                    continue
                ci += self.assembleChrom(seqlist,chrom,splitseq[chrom],walk=walk,prev=ci>0)

            ### ~ [2] Option to repeat assembly process ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            if self.i() > 0 and self.yesNo('Repeat manual assembly cycle?',default='N'): return self.assemble(seqlist,chrlist=chrlist)
            return True
        except KeyboardInterrupt:
            self.printLog('#CTRLC','Assembly cancelled (CTRL+C)')
        except SystemExit: raise
        except: self.errorLog('%s.assemble() error' % self.prog())
#########################################################################################################################
    ### <7> ### PAGSAT Comparison Methods                                                                               #
#########################################################################################################################
    def compare(self):  ### Generates summary of statistics across multiple PAGSAT runs.
        '''## PAGSAT Compare mode

        The `compare=FILES` run mode generates summary of statistics across multiple PAGSAT runs. For input, it will take
        a list of `*.Summary.tdt` files, from which PAGSAT will extrapolate the run paths to find the other files it
        needs. (PAGSAT assumes these files have not been moved or rearrange since the original run. If they have, you
        will need to mimic the original directory structure.

        For each PAGSAT run, PASGAT Compare will use:

        *

        In addition, PAGSAT will use a `*.Features.tdt` table associated with the reference genome to identify repeat
        features to exclude from "Unique" output stats (see below).


            fragcov = self.list['FragCov']   # = [50,90,95,99] List of coverage thresholds to count (local table)
            chromcov = self.list['ChromCov'] # = [95,98,99] No. of chromosomes covered by a single contig (GABLAM table)


            compfields = ['Assembly','N','%AssCov','%AssAcc','%AssAlnCov','%AssAlnAcc','Multiplicity','Parsimony','%RefCov','%RefAcc','%GlobRefAcc','%RefAlnCov','%RefAlnAcc','%GlobAlnAcc','Missing','Different','Extra','Duplicate','TreeLen','WtTreeLen']
            if ftdb: compfields += ['UniqCov','UniqCtg','UniqDup','RepeatFT']
            for chromx in chromcov: compfields.append('Chrom%d' % chromx)
            for fragx in fragcov:
                compfields.append('Frag%d' % fragx)
                if ftdb: compfields.append('UniqFrag%d' % fragx)
            compdb = db.addEmptyTable('compare',compfields,['Assembly'])   # Table of final comparison data
            if self.getBool('GeneSummary'): compdb.addFields(['%GeneCov','%GeneAcc'])#,'%GeneIntegrity'])
            if self.getBool('ProtSummary'): compdb.addFields(['%ProtCov','%ProtAcc'])#,'%ProtIntegrity'])

        ### Output statistics

        * Assembly = The assembly being assessed
        * N = Number of contigs/scaffolds
        * %AssCov = Percentage of assembly nucleotides mapping onto reference
        * %AssAcc = Percentage of mapped assembly nucleotides identical to reference
        * Multiplicity = Assembly coverage / Reference coverage
        * Parsimony = Assembly length / Reference coverage
        * %RefCov = Percentage of reference nucleotides mapping onto assembly
        * %RefAcc = Percentage of mapped reference nucleotides identical to assembly
        * %GlobRefAcc = Percentage of total reference nucleotides identical to assembly
        * Missing = Number of reference nucleotides not mapped onto assembly
        * Different = Number of mapped nucleotides mismatched in reference vs assembly
        * Extra = Number of assembly nucleotides not mapped onto reference
        * Duplicate = Flawed statistic. Ignore!
        * TreeLen = Total length of branches in chromosome/contig tree
        * WtTreeLen = Total length of branches in chromosome/contig tree, weighted by chromsome/contig length
        * UniqCov = Proportion of "unique" reference regions covered by assembly (see RepeatFT). [Needs checking]
        * UniqCtg = Proportion of "unique" reference regions covered uniquely by one assembly contig (see RepeatFT). [Needs checking]
        * UniqDup = Flawed statistic. Ignore!
        * RepeatFT = "Repeat" features in reference; "Unique" regions are those outside these features.
        * ChromXX = The number of reference chromosomes with >= XX% global identity in assembly.
        * FragXX = The number assembly chunks needed for >=XX% global coverage of reference. [Needs checking]
        * UniqFragXX = The number assembly chunks needed for >=XX% global coverage of "unique" reference regions (see RepeatFT). [Needs checking]

        '''
        try:### ~ [0] Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            self.devLog('#RUN','compare')
            self.printLog('#~~#','## ~~~~~ PAGSTAT Compare mode (%d files) ~~~~~ ##' % len(self.list['Compare']))
            db = self.db()
            # This method essentially wants to read and combine the summary data from several runs, and then extract the
            # most useful information for assessing assessment quality, including:
            # - %coverage and %accuracy for assembly and reference.
            # - no. contigs
            # - optional gene/protein data if present
            ## ~ [0a] Load Reference Feature Table (if refgenome given) ~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            #!# Add RepeatFT=list option along with docs of how to make Features table.
            repeatft = ['rRNA','mobile','LTR','centromere','telomere']   # self.list['RepeatFT']
            repeatft.sort()
            ftdb = None
            if repeatft: ftdb = self.ftdb()
            if ftdb:
                ftdb.dropEntriesDirect('feature',repeatft,inverse=True)
                self.printLog('#RPTFT','%s repeat features to exclude in "Uniq" outputs.' % rje.iStr(ftdb.entryNum()))
                if not ftdb.entryNum(): ftdb = None
            else:
                if not self.getStrLC('RefGenome'): self.printLog('#RPTFT','Cannot filter repeat features without refgenome=FILE.')
                if not repeatft: self.printLog('#RPTFT','Cannot filter repeat features without repeatft=LIST.')
            loc2chr = {}                # Will be a locus -> chromosome dictionary
            fragcov = self.list['FragCov']   # = [50,90,95,99] List of coverage thresholds to count (local table)
            chromcov = self.list['ChromCov'] # = [95,98,99] No. of chromosomes covered by a single contig (GABLAM table)
            fragcov.sort(); chromcov.sort()

            ### ~ [1] Load Data ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            compfields = ['Assembly','N','%AssCov','%AssAcc','%AssAlnCov','%AssAlnAcc','Multiplicity','Parsimony','%RefCov','%RefAcc','%GlobRefAcc','%RefAlnCov','%RefAlnAcc','%GlobAlnAcc','Missing','Different','Extra','Duplicate','TreeLen','WtTreeLen']
            if ftdb: compfields += ['UniqCov','UniqCtg','UniqDup','RepeatFT']
            for chromx in chromcov: compfields.append('Chrom%d' % chromx)
            for chromx in chromcov: compfields.append('Chrom%dcov' % chromx)
            for fragx in fragcov:
                compfields.append('Frag%d' % fragx)
                if ftdb: compfields.append('UniqFrag%d' % fragx)
            compdb = db.addEmptyTable('compare',compfields,['Assembly'])   # Table of final comparison data
            if self.getBool('GeneSummary'): compdb.addFields(['%GeneCov','%GeneAcc'])#,'%GeneIntegrity'])
            if self.getBool('ProtSummary'): compdb.addFields(['%ProtCov','%ProtAcc'])#,'%ProtIntegrity'])
            for pfile in self.list['Compare']:
                #!# Can/should this whole process be moved into a function that can be run on a single dataset? #!#
                #!# Can then simply compile the datasets if found with the right headers.
                #i# pfile is the *.PAGSAT/*.Summary.tdt file. This may not be in the current directory.
                self.printLog('#FILE',pfile)
                ppath = os.path.split(pfile)[0]
                self.printLog('#PATH',ppath)
                basedir = '%s/' % ppath
                [ppath,pcheck] = os.path.split(ppath)
                ## ~ [1a] Load and Process Summary Table ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
                pbase = rje.baseFile(pfile,strip_path=True)
                if pbase.endswith('.Summary'): pbase = string.join(string.split(pbase,'.')[:-1],'.')     # Strip Summary

                #!# Need to add parent directories if required!
                #basedir = rje.makePath('%s.PAGSAT/' % string.join(string.split(pbase,'.')[:-1],'.'))
                #if basedir != rje.makePath(pcheck): self.warnLog('Expect %s but file in %s!' % (rje.makePath(pcheck),basedir))

                #gabdir = rje.makePath('%s.GABLAM/' % string.join(string.split(pbase,'.')[:-1],'.'))
                #if ppath:
                #    basedir = rje.makePath('%s/%s' % (ppath,basedir))
                #    gabdir = rje.makePath('%s/%s' % (ppath,gabdir))
                gabdir = rje.makePath('%s.GABLAM/' % string.join(string.split(basedir,'.')[:-1],'.'))
                self.setStr({'GABLAMDir':gabdir,'ResDir':basedir,'BaseBase':string.join(string.split(pbase,'.')[:-1],'.'),'CutBase':pbase})
                try: pdb = db.addTable(pfile,['Summary'],name=pbase,expect=True)
                except: self.errorLog('Cannot load PAGSAT Summary table "%s": check format' % pfile); continue
                pdb.dataFormat({'Length':'int','Coverage':'int','Identity':'int','Missing':'int','Different':'int'})
                centry = {'Assembly':pbase}
                for entry in pdb.entries():
                    if entry['Summary'] == 'Reference':
                        centry['%RefCov'] = 100.0 * entry['Coverage'] / entry['Length']     # Coverage
                        centry['%RefAcc'] = 100.0 * entry['Identity'] / entry['Coverage']
                        centry['%GlobRefAcc'] = 100.0 * entry['Identity'] / entry['Length']
                        centry['Missing'] = entry['Missing']
                        centry['Different'] = entry['Different']
                        centry['Duplicate'] = 0
                    if entry['Summary'] == 'ReferenceAlign':
                        centry['%RefAlnCov'] = 100.0 * entry['Coverage'] / entry['Length']     # Coverage
                        centry['%RefAlnAcc'] = 100.0 * entry['Identity'] / entry['Coverage']
                        centry['%GlobAlnAcc'] = 100.0 * entry['Identity'] / entry['Length']
                        centry['Duplicate'] = 0
                    if entry['Summary'] == 'Assembly':
                        centry['%AssCov'] = 100.0 * entry['Coverage'] / entry['Length']     # Validity
                        centry['%AssAcc'] = 100.0 * entry['Identity'] / entry['Coverage']
                        centry['Multiplicity'] = float(entry['Coverage']) / pdb.data('Reference')['Coverage']
                        centry['Parsimony'] = float(entry['Length']) / pdb.data('Reference')['Coverage']
                        centry['Extra'] = entry['Missing']
                        centry['N'] = entry['N']
                    if entry['Summary'] == 'AssemblyAlign':
                        centry['%AssAlnCov'] = 100.0 * entry['Coverage'] / entry['Length']     # Validity
                        centry['%AssAlnAcc'] = 100.0 * entry['Identity'] / entry['Coverage']
                    if entry['Summary'] == 'Genes':
                        centry['%GeneCov'] = 100.0 * entry['Coverage'] / entry['Length']
                        centry['%GeneAcc'] = 100.0 * entry['Identity'] / entry['Coverage']
                    if entry['Summary'] == 'Proteins':
                        centry['%ProtCov'] = 100.0 * entry['Coverage'] / entry['Length']
                        centry['%ProtAcc'] = 100.0 * entry['Identity'] / entry['Coverage']
                    #i# The Reciprocal Gene searches do not seem to very useful as summary data.
                    #if entry['Summary'] == 'Genes.Reciprocal':
                    #    centry['%GeneIntegrity'] = 100.0 * entry['Identity'] / entry['Length']
                    #if entry['Summary'] == 'Proteins.Reciprocal':
                    #    centry['%ProtIntegrity'] = 100.0 * entry['Identity'] / entry['Length']
                for field in centry:
                    if field not in ['Assembly','N','Missing','Different','Extra','Duplicate','TreeLen','WtTreeLen']:
                        centry[field] = rje.dp(centry[field],4)
                centry = compdb.addEntry(centry)
                #self.debug(centry)
                #self.debug('%s' % compdb.data(pbase))
                ## ~ [1b] Load and process CovPlot Table ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
                #MBG8150.SP16481.hcq.sgd.srt.1000.covplot.chrom.tdt
                #!# Should this be Reference or RefSnap

                #!# if self.getBool('Snapper'): - can use *Snap for unique coverage. I think this should be it!
                #!# Otherwise could take square root on assumption that each dupl should hit each other?! #!#

                cfile = string.replace(pfile,'Summary','Reference.covplot')
                if not rje.exists(cfile): self.warnLog('Could not locate %s' % cfile); continue
                try: cdb = db.addTable(cfile,['Qry','Pos'],name='covplot',expect=True)
                except: self.errorLog('Cannot load PAGSAT chromosome coverage table "%s": check format' % cfile); continue
                ## >> Temp renaming of fields
                # Qry     Pos     HitAln  HitSeq  HitChrom        Class   RecAln  RecSeq  RecChrom
                cdb.renameField('Qry','Chrom')
                cdb.renameField('HitAln','HitNum')
                cdb.renameField('HitSeq','ContigNum')
                cdb.renameField('HitChrom','Contigs')
                cdb.renameField('RecAln','ChromHit')
                cdb.renameField('RecSeq','ChromNum')
                cdb.renameField('RecChrom','RefChrom')
                #<<#

                cdb.dataFormat({'Pos':'int','ContigNum':'int','ChromNum':'int'})
                # ['Chrom','Pos','HitNum','ContigNum','Contigs','Class','ChromHit','ChromNum','RefChrom']
                covdata = {}    # Dict of {chrom:{pos:excess}}
                for entry in cdb.entries():
                    if entry['Chrom'] not in covdata: covdata[entry['Chrom']] = {}
                    covdata[entry['Chrom']][entry['Pos']] = entry['ContigNum'] - entry['ChromNum']
                centry['Duplicate'] = 0
                for chrom in covdata:
                    cpos = rje.sortKeys(covdata[chrom])
                    (x,i) = (0,0)
                    while i < len(cpos):
                        cx = covdata[chrom][cpos[i]]    # Contig hits - chrom hits
                        #i# I think this means that "Duplicate" only counts CNV increases on different chromosomes?
                        if cx > 0: centry['Duplicate'] +=  cx * (cpos[i] - x)
                        x = cpos[i]
                        i += 1
                ## ~ [1c] Unique coverage and duplication ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
                bad_loc2chr = False
                if ftdb:        #!# NOTE: Unique stuff is not working!
                    centry['RepeatFT'] = string.join(repeatft,';')
                    # Note: locus=BK006937; Chrom=chrIII_S288C__BK006937.2
                    if not loc2chr:     # Only need to make once
                        for locus in ftdb.index('locus'):
                            loc2chr[locus] = None
                            for chrom in cdb.index('Chrom'):
                                if string.split(chrom,'__')[1].startswith(locus): loc2chr[locus] = chrom
                            if not loc2chr[locus]: self.warnLog('CovPlot missing %s?' % locus); bad_loc2chr = True
                        #self.debug(loc2chr)
                    # First, modify cdb to include R entries where Contig hits = Chrom hits = 0
                    for ft in ftdb.entries():
                        chrom = loc2chr[ft['locus']]
                        if not chrom or not cdb.indexEntries('Chrom',chrom): continue
                        fmin = ()   # (pos,centry) closest to 5' end of feature (to be at Pos=start-1)
                        fmax = ()   # (pos,centry) closest to 3' end of feature (to be at Pos=end+1)
                        for chrentry in cdb.indexEntries('Chrom',chrom)[0:]:
                            if chrentry['Pos'] < (ft['start']-1):
                                if not fmin or chrentry['Pos'] > fmin[0]: fmin = (chrentry['Pos'],chrentry)
                                continue    # No overlap, so keep
                            if chrentry['Pos'] > (ft['end']+1):
                                if not fmax or chrentry['Pos'] < fmax[0]: fmax = (chrentry['Pos'],chrentry)
                                continue    # No overlap, so keep
                            if not fmin or chrentry['Pos'] < fmin[0]: fmin = (chrentry['Pos'],chrentry)
                            if not fmax or chrentry['Pos'] > fmax[0]: fmax = (chrentry['Pos'],chrentry)
                            cdb.dropEntry(chrentry)
                        chrentry = fmin[1]
                        cdb.addEntry(rje.combineDict({'Chrom':chrom,'Pos':ft['start']-1},chrentry,overwrite=False))
                        cdb.addEntry({'Chrom':chrom,'Pos':ft['start'],'ContigNum':0,'Class':'R','ChromNum':0})
                        cdb.addEntry({'Chrom':chrom,'Pos':ft['end'],'ContigNum':0,'Class':'R','ChromNum':0})
                        chrentry = fmax[1]
                        cdb.addEntry(rje.combineDict({'Chrom':chrom,'Pos':ft['end']+1},chrentry,overwrite=False))
                    # Then calculate UniqDup as before
                    covdata = {}    # Dict of {chrom:{pos:excess}}
                    uniqdata = {}   # Dict of {chrom:{pos:class}}
                    uniqlen = totlen = 0; uniqcov = uniqctg = 0
                    for entry in cdb.entries():
                        if entry['Chrom'] not in covdata: covdata[entry['Chrom']] = {}; uniqdata[entry['Chrom']] = {}
                        try: covdata[entry['Chrom']][entry['Pos']] = entry['ContigNum'] - entry['ChromNum']
                        except: self.debug(entry)
                        uniqdata[entry['Chrom']][entry['Pos']] = entry['Class']
                    centry['UniqDup'] = 0
                    for chrom in covdata:
                        cpos = rje.sortKeys(covdata[chrom])
                        totlen += cpos[-1] - 1
                        uniqlen += cpos[-1] - 1
                        (x,i) = (0,0)
                        while i < len(cpos):
                            if uniqdata[chrom][cpos[i]] == 'R': uniqlen -= cpos[i] - x
                            elif uniqdata[chrom][cpos[i]] != 'N': uniqcov += cpos[i] - x    # Was C/U but I think
                            if uniqdata[chrom][cpos[i]] in ['C','U']: uniqctg += cpos[i] - x    # Need to annotate class ratings
                            cx = covdata[chrom][cpos[i]]    # Contig hits - chrom hits
                            if cx > 0: centry['UniqDup'] +=  cx * (cpos[i] - x)
                            x = cpos[i]
                            i += 1
                    centry['UniqCov'] = 100.0 * uniqcov / uniqlen
                    centry['UniqCtg'] = 100.0 * uniqctg / uniqlen
                db.deleteTable(cdb)
                ## ~ [1d] Load an process Tree file ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
                tfile = string.replace(pfile,'Summary.tdt','nwk')
                tree = rje_tree.Tree(self.log,self.cmd_list+['autoload=F'])
                tree.loadTree(tfile,postprocess=False)
                centry['TreeLen'] = rje.dp(tree.treeLen(),1)
                self.printLog('#TREE','Tree length = %s' % centry['TreeLen'])
                # Weighted tree length

                #!# These do not find files if PAGSAT not run in this parent directory!
                gfile = '%s.hitsum.tdt' % self.fileBase('GABLAM','Cut','Reference')
                if not rje.exists(gfile): self.warnLog('Could not locate %s' % gfile); continue
                try: gdb = db.addTable(gfile,['Qry'],name='rhitsum',expect=True)
                except: self.errorLog('Cannot load GABLAM table "%s": check format' % gfile); continue
                gdb.dataFormat({'Length':'int'})
                afile = '%s.hitsum.tdt' % self.fileBase('GABLAM','Cut','Assembly')
                if not rje.exists(afile): self.warnLog('Could not locate %s' % afile); continue
                try: adb = db.addTable(afile,['Qry'],name='ahitsum',expect=True)
                except: self.errorLog('Cannot load GABLAM table "%s": check format' % afile); continue
                adb.dataFormat({'Length':'int'})
                # Qry	Hit	Rank	Score	EVal	QryLen	HitLen
                # Qry = Reference; Hit = Assembly
                seqlen = {}
                for entry in gdb.entries() + adb.entries(): seqlen[entry['Qry']] = entry['Length']
                db.deleteTable(gdb); db.deleteTable(adb)
                centry['WtTreeLen'] = 0.0
                try:
                    treelen = 0.0
                    for branch in tree.branch:
                        blen = tree.pathLen([branch])
                        lens = []
                        for node in tree.branchClades(branch)[1]: lens.append(seqlen[node.shortName()])
                        treelen += blen * rje.meanse(lens)[0]
                    centry['WtTreeLen'] = rje.sf(treelen/1e6,4)
                    self.printLog('#WTLEN','Weighted tree length = %s' % centry['WtTreeLen'])
                except: self.errorLog('Problem generating weighted tree length!')
                ## ~ [1e] FragX and ChrX ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
                #!# NOTE: This needs to be improved with respect to checking options etc. #!#
                #lfile = '%s/%s.local.tdt' % (string.replace(pfile,'Summary.tdt','GABLAM'),pbase)
                # Not: MBG479.SP16499.hcq.qv20.sgd.srt.PAGSAT/MBG479.SP16499.hcq.qv20.sgd.srt.L500ID800.GABLAM/MBG479.SP16499.hcq.qv20.sgd.srt.L500ID800.local.tdt
                # -> MBG479.SP16499.hcq.qv20.sgd.srt.GABLAM/MBG479.SP16499.hcq.qv20.sgd.srt.L500ID800.Reference.local.tdt
                lfile = '%s.local.tdt' % self.fileBase('GABLAM','Cut','Reference')
                if not rje.exists(lfile): self.warnLog('Could not locate %s' % lfile); continue
                try: locdb = db.addTable(lfile,['Qry','Hit','AlnNum'],name='Reference.local',expect=True)
                except: self.errorLog('Cannot load local hit table "%s": check format' % lfile); continue
                locdb.dataFormat({'Length':'int','Identity':'int','QryStart':'int','QryEnd':'int','SbjStart':'int','SbjEnd':'int'})
                for lentry in locdb.entries():
                    if lentry['SbjStart'] > lentry['SbjEnd']:
                        (lentry['SbjStart'],lentry['SbjEnd']) = (lentry['SbjEnd'],lentry['SbjStart'])
                # Use uniqlen and totlen calculated above to count number of local BLAST hits needed to exceed length thresholds
                #fragcov = [50,90,95,99]     # List of coverage thresholds to count (local table)
                for fragx in fragcov: centry['Frag%d' % fragx] = centry['UniqFrag%d' % fragx] = 0
                # Make lists of coverage (start, end), merging as required, sum up and compare to totlen
                # For uniqlen, start with a list of features before adding local hits
                covdict = {'Frag':{},'UniqFrag':{}}    # Dictionary of {chromosome:[(start,end)]
                covtot = {'Frag':{},'UniqFrag':{}}  # Dictionary of {Chromosome:total coverage}
                if ftdb: covlen = {'Frag':totlen,'UniqFrag':uniqlen}  # Dictionary of {Chromosome:total coverage}
                else: covlen = {'Frag':0,'UniqFrag':0}  # Dictionary of {Chromosome:total coverage}
                for qry in locdb.index('Qry'):
                    covdict['Frag'][qry] = []
                    covdict['UniqFrag'][qry] = []
                    covtot['Frag'][qry] = 0
                ucovdict = covdict['UniqFrag']
                #!# Need to fix this ftdb issue!
                if ftdb:
                    for ft in ftdb.entries():
                        qry = loc2chr[ft['locus']]
                        if not qry: continue
                        ucovdict[qry].append((ft['start'],ft['end']))
                for qry in locdb.index('Qry'):
                    ucovdict[qry].sort()
                    x = 1
                    while x < len(ucovdict[qry]):
                        if ucovdict[qry][x][0] <= (ucovdict[qry][x-1][1] + 1):    # Merge
                            ucovdict[qry][x-1] = (ucovdict[qry][x-1][0],max(ucovdict[qry][x-1][1],ucovdict[qry][x][1]))
                            ucovdict[qry].pop(x)
                        else: x += 1
                    covtot['UniqFrag'][qry] = 0
                    for (i,j) in ucovdict[qry]: covtot['UniqFrag'][qry] += (j - i + 1)
                    #self.debug(ucovdict[qry])
                    #self.debug(covtot['UniqFrag'][qry])
                uniqlen = sum(covtot['UniqFrag'].values())
                if ftdb: covlen['UniqFrag'] = totlen - uniqlen
                # Add local hits in size order.
                hitx = 0    # Hit counter
                for lentry in locdb.sortedEntries('Identity',reverse=True):
                    hitx += 1
                    qry = lentry['Qry']
                    for c in ['Frag','UniqFrag']:
                        qfrag = covdict[c][qry]
                        qfrag.append((lentry['QryStart'],lentry['QryEnd']))
                        qfrag.sort()
                        x = 1
                        while x < len(qfrag):
                            if qfrag[x][0] <= (qfrag[x-1][1] + 1):    # Merge
                                qfrag[x-1] = (qfrag[x-1][0],max(qfrag[x-1][1],qfrag[x][1]))
                                qfrag.pop(x)
                            else: x += 1
                        covtot[c][qry] = 0
                        for (i,j) in qfrag: covtot[c][qry] += (j - i + 1)
                        # Assess coverage:
                        for fragx in fragcov:
                            if centry['%s%d' % (c,fragx)] or not ftdb: continue
                            if c == 'UniqFrag':
                                if 100.0 * (sum(covtot[c].values()) - uniqlen) / covlen[c] >= fragx: centry['%s%d' % (c,fragx)] = hitx
                            elif 100.0 * sum(covtot[c].values()) / covlen[c] >= fragx: centry['%s%d' % (c,fragx)] = hitx
                    if centry['Frag%d' % fragcov[-1]] and centry['UniqFrag%d' % fragcov[-1]]: break
                db.deleteTable(locdb)
                if bad_loc2chr: loc2chr = {}

                #chromcov = [50,95,98,99]    # No. of chromosomes covered by a single contig (GABLAM table)
                #gfile = string.replace(lfile,'local','gablam')
                gfile = '%s.gablam.tdt' % self.fileBase('GABLAM','Cut','Reference')
                if not rje.exists(gfile): self.warnLog('Could not locate %s' % gfile); continue
                try: gdb = db.addTable(gfile,['Qry','Hit'],name='gablam',expect=True)
                except: self.errorLog('Cannot load GABLAM table "%s": check format' % gfile); continue
                gdb.dropEntriesDirect('Rank',['1'],inverse=True)

                #!# Should this be converted to coverage? Or also calculated as coverage? #!#
                gxfield = 'Qry_AlnID'   # Could also use Qry_AlnLen
                gdb.dataFormat({gxfield:'float'})
                for chromx in chromcov:
                    centry['Chrom%d' % chromx] = 0
                    for gentry in gdb.entries():
                        if gentry[gxfield] >= chromx: centry['Chrom%d' % chromx] += 1
                    centry['Chrom%dcov' % chromx] = 0
                    for gentry in gdb.entries():
                        if gentry[gxfield] >= chromx: centry['Chrom%dcov' % chromx] += 1

                db.deleteTable(gdb)

                self.debug(centry)
            #!# Temp drop of empty fields
            outfields = []
            for field in compdb.fields():
                if 'Aln' in field: continue
                outfields.append(field)
            compdb.saveToFile(savefields=outfields)



            pagfiles = []
            pagbase = []    # List of basefiles for PAGSAT results

            # Load in summary table, add assembly name and then combine with others
            # Reshape wide and then reshape long again!

            #Summary	HitNum	Length	Coverage	Identity	Positives	Missing	Different	Perfect	N
            #Assembly	1173	13235834	13233590	13232765	13232765	2244	825	28	120
            #Reference	1190	12157104	12124470	12123837	12123837	32634	633	0	17
            #Self	268	12157104	12157104	12157104	12157104	0	0	17	17


            datatypes = ['Genes','Genes.Reciprocal','Proteins','Proteins.Reciprocal','Reference','Self']


        except: self.errorLog('%s.compare error' % self.prog())
#########################################################################################################################
    def compile(self):  ### Generates summary HTML wil reference chromosomes piled up.
        '''Generates summary HTML wil reference chromosomes piled up.'''
        try:### ~ [0] Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            if not self.dev(): raise ValueError('Compile mode only works in dev mode: contact the author to use')
            self.devLog('#RUN','Compile')
            self.printLog('#~~#','## ~~~~~ PAGSTAT Compile mode (%d files) ~~~~~ ##' % len(self.list['Compile']))
            html = rje_html.HTML(self.log,self.cmd_list)

            acclist = []; acchtml = {}; asslist = []; accname = {}; acctitle = {}
            chrlist = []
            ### ~ [1] Parse ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            for rfile in self.list['Compile']:
                ass = rje.baseFile(rfile,True)
                if ass not in asslist: asslist.append(ass)
                asplit = string.split(ass,'.')
                i = len(asplit)
                while i:
                    pagdir = string.join(asplit[:1],'.') + '.PAGSAT'
                    ppath = os.path.split(rfile)[0] + '/' + pagdir
                    if os.path.exists(ppath): break
                    i -= 1
                self.printLog('#PDIR','%s -> %s' % (pagdir,ppath))
                if not os.path.exists(ppath): self.warnLog('%s not found: images won\'t show for %s' % (ppath, rfile))
                for rdata in string.split(open(rfile,'r').read(),'<hr width="80%">'):
                    if not rdata.startswith('<a name=') or rdata.startswith('<a name="MBG'): continue
                    acc = rje.matchExp('<a name="(\S+)">',rdata)[0]
                    if pagdir in rdata:
                        rdata = string.replace(rdata,'./%s' % pagdir,ppath)
                    # Update internal links
                    rdata = string.replace(rdata,'<a href="#','<a href="%s#' % rfile)
                    # Set up title etc.
                    if acc not in acclist:
                        acclist.append(acc)
                        accname[acc] = acc
                        if rje.matchExp('chromosome (\S+),',rdata):
                            accname[acc] = 'chr%s' % rje.matchExp('chromosome (\S+),',rdata)[0]
                        acctitle[acc] = string.split(rje.matchExp('h3 title="(.+)"',rdata)[0],'"')[0]
                        chrlist.append(accname[acc])
                        if accname[acc] not in acchtml:
                            acchtml[accname[acc]] = ''
                    #?# What is this if statement for?
                    if len(string.split(rdata,'<p>Assembly: <a href=')) > 1:
                        rdata = string.split(rdata,'<p>Assembly: <a href=')[0]
                        acchtml[accname[acc]] += '%s\n<hr width="80%%">\n\n' % rdata
                        break
                    else:
                        acchtml[accname[acc]] += '<a name="%s"></a><h2>%s: %s ~ [<a href="#Top" title="Jump to top of compile page">Reports</a>]</h2>\n\n' % (ass,ass,accname[acc])
                        acchtml[accname[acc]] += '%s\n<hr width="80%%">\n\n' % rdata
            self.debug(acclist)
            self.debug(chrlist)


            ### ~ [2] Output ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            tabbed = len(self.list['Compile']) < 10

            if tabbed:
                hfile = '%s.html' % self.baseFile()
                rje.backup(self,hfile)
                HTML = open(hfile,'w')
                HTML.write(html.htmlHead(title='%s Compilation' % self.baseFile(),tabber=True,keywords=[]))
                HTML.write('<h1>PAGSAT Compilation</h1>\n')
                HTML.write('<p>Click on tabs to view all parsed version of reference chromosome.</p>\n\n')
                HTML.write('<p>Assembly order: <code>%s</code></p>\n\n' % string.join(asslist,'</code> <code>'))
                #Tab per chromosome
                tablist = []
                for acc in acclist:
                    tablist.append( (accname[acc], acchtml[accname[acc]], acctitle[acc]) )

                HTML.write(html.tabberHTML('chr',tablist))
                #tabid:str = Identifier for Tabber object
                #tablist:list = List of (tab_id, tab_html_text[, tab_title]) tuples
                HTML.write(html.htmlTail(tabber=True))
                self.printLog('#HTML','Compiled HTML output to %s' % hfile)

            else:
                for acc in acclist:
                    hfile = '%s.%s.html' % (self.baseFile(),accname[acc])
                    rje.backup(self,hfile)
                    HTML = open(hfile,'w')
                    HTML.write(html.htmlHead(title='%s %s Compilation' % (self.baseFile(),accname[acc]),tabber=False,keywords=[]))
                    HTML.write('<a name="Top"></a><h1>PAGSAT %s Compilation</h1>\n' % acctitle[acc])
                    HTML.write('<p>Click on PAGSAT run names to jump to chromosome output for that run. Click ["Reports"] to return to here. NOTE: hyperlinks within each chromosome report will open the original <code>*.html</code> file - you will probably want to do this in a new tab.</p>\n\n')
                    codelist = []
                    for ass in asslist: codelist.append('<a href="#%s">%s</a>' % (ass,ass))
                    HTML.write('<p>Assembly order: <code>%s</code></p>\n\n<hr width="80%%">\n\n' % string.join(codelist,'</code> <code>'))
                    HTML.write(acchtml[accname[acc]])
                    HTML.write(html.htmlTail(tabber=False))
                    self.printLog('#HTML','Compiled %s HTML output to %s' % (accname[acc],hfile))

        except: self.errorLog('%s.compile error' % self.prog())
#########################################################################################################################
### End of SECTION II: PAGSAT Class                                                                                     #
#########################################################################################################################

                                                    ### ~ ### ~ ###

#########################################################################################################################
### SECTION III: MODULE METHODS                                                                                         #
#########################################################################################################################

#########################################################################################################################
### END OF SECTION III                                                                                                  #
#########################################################################################################################

                                                    ### ~ ### ~ ###

#########################################################################################################################
### SECTION IV: MAIN PROGRAM                                                                                            #
#########################################################################################################################
def runMain():
    ### ~ [1] ~ Basic Setup of Program  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
    try: (info,out,mainlog,cmd_list) = setupProgram()
    except SystemExit: return  
    except: print 'Unexpected error during program setup:', sys.exc_info()[0]; return
    
    ### ~ [2] ~ Rest of Functionality... ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
    try: PAGSAT(mainlog,['taxdir=None']+cmd_list).run()

    ### ~ [3] ~ End ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
    except SystemExit: return  # Fork exit etc.
    except KeyboardInterrupt: mainlog.errorLog('User terminated.')
    except: mainlog.errorLog('Fatal error in main %s run.' % info.program)
    mainlog.endLog(info)
#########################################################################################################################
if __name__ == "__main__":      ### Call runMain 
    try: runMain()
    except: print 'Cataclysmic run error:', sys.exc_info()[0]
    sys.exit()
#########################################################################################################################
### END OF SECTION IV                                                                                                   #
#########################################################################################################################
