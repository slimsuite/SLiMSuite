#!/usr/bin/python

# See below for name and description
# Copyright (C) 2014 Richard J. Edwards <redwards@cabbagesofdoom.co.uk>
#  
# This program is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License
# as published by the Free Software Foundation; either version 2 of the License, or (at your option) any later version.
# 
# This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied
# warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with this program; if not, write to 
# the Free Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
#
# Author contact: <seqsuite@gmail.com> / School of Biotechnology and Biomolecular Sciences, UNSW, Sydney, Australia.
#
# To incorporate this module into your own programs, please see GNU Lesser General Public License disclaimer in rje.py

"""
Module:       SMRTSCAPE
Description:  SMRT Subread Coverage & Assembly Parameter Estimator
Version:      2.2.3
Last Edit:    11/07/18
Copyright (C) 2017  Richard J. Edwards - See source code for GNU License Notice

Summary:
    ### ~ Function ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
    `SMRTSCAPE` (SMRT Subread Coverage & Assembly Parameter Estimator) is a tool for analysis of PacBio raw sequencing
    data to assist the design and execution of PacBio genomics projects. It has a number of functions concerned with
    predicting and/or assessing the quantity and quality of useable data produced:

    1. **Genome Coverage (`coverage=T`).** This method tries to predict genome coverage and accuracy for different depths of
    PacBio sequencing. This is useful for estimating genome coverage and/or required numbers of SMRT cells from predicted
    read outputs or emprical (average) SMRT cell data if the `BASEFILE.unique.tdt` output (generated by `summary=T`, below) is
    found. NOTE: Default settings for SMRT cell output are not reliable and you should speak to your sequencing provider
    for their up-to-date figures. By default, output for this mode is incremented by `XCoverage` but this can be switched
    to numbers of SMRT cells with `bysmrt=T`.

    2. **Summarise subreads (`summarise=T`).** This function summarises subread data from a given `seqin=FILE` fasta
    file, or a set of subread fasta files given with `batch=FILELIST` (or listed in `*.fofn`). This produces sequence
    summary data (read lengths, N50 etc.) for each sequence file, SMRT cell and the combined dataset (`*.summary.tdt`).
    In addition, tables are generated that summarise each read individually, which can then be used for further read
    filtering or calculations. Summaries are produced for _all_ data (`*.zmw.tdt`) and just the **Unique** subread data,
    which is the _longest_ read from each ZMW (`*.unique.tdt`). FALCON only uses unique read data, and so it is these
    data that are used for the rest of SMRTSCAPE functions. A summary of **Read Quality (RQ)** data is also output
    (`*.rq.tdt`).

    3. **Calculate length cutoffs (`calculate=T`).** Calculates length cutoffs for different XCoverage and RQ
    combinations from subread summary data. Generates `*.cutoffs.tdt`.

    4. **Optimise (`optimise=T`).** This function attempts to generate predicted optimum assembly settings from the
    `summary=T` and `calculate=T` table data. NOTE: In `V1.x`, this option was `parameters=T`.

    5. **Filter subreads (`readfilter=T`).** This filters *unique* subreads into a new fasta file (`*.LXXXRQXXX.fasta`)
    based on min. read quality (`rqfilter=X`) and min. read length (`lenfilter=X`). NOTE: These filters are not
    available in FALCON, so sequence input must be pre-filtered in this way.

    6. **Preassembly fragmentation analysis (`preassembly=FILE`).** Processes a Preassembly fasta file to assess/correct
    over-fragmentation. Corrected preassembly reads are output to `*.smrtscape.fas` and summary data output to
    `*.fragment.tdt`.

    7. **Feature coverage (`ftxcov=INTLIST`).** Calculates full-length coverage for a list of feature lengths, as well as
    their probability of detection (in raw subread data) if present at different population frequencies
    (`ftxfreq=NUMLIST`).  If seqin=FILE is given, this will be used directly unless summarise=T, calculate=T or
    optimise=T. Otherwise, unique reads from (`*.unique.tdt`) will be used.

    These are explored in more detail in the **Details** section.


    ### ~ Retired Functions ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
    NOTE: The following functions/settings have been retired in `V2.x` as HGAP3-specific options. To use, please use
    `SMRTSCAPE_V1` or contact the author if you wish to have them reinstated for updated versions of SMRTPipeline/SMRTLink:

    parseparam=FILES: Parse parameter settings from 1+ assembly runs []
    paramlist=LIST  : List of parameters to retain for parseparam output (file or comma separated, blank=all) []


    ### ~ Input/Output ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###

    Main input for `SMRTSCAPE` is a set of subreads fasta files (`seqin=FILE` or `batch=FILELIST`). This is not required
    for `coverage=T`. Input for Preassembly Fragmentation analysis is a single preassembly fasta file, given with
    `preassembly=FILE`.

    Main outputs are named using `basefile=X` as the file name root. If `basefile=X` is not set (or =`''`/`None`),
    `seqin=FILE` will set the basefile name, trimming the file extension. If `seqin=FILE` is not given `preassembly=FILE`
    will be used. If neither `seqin` nor `preassembly` are given and `batch=FILELIST` points to a `*.fofn` "file of file
    names", this file will be used to set `basefile`. Otherwise, `basefile=smrtscape`.

    Re-running a particular mode will regenerate the relevant output (with options to back up unless `backups=F`) but
    existing data from previous stages will be read and reused if found. If `force=T` then earlier stages other than
    `summarise=T` output (e.g. `*.unique.tdt`). These will also be regenerated if `fullforce=T`. (The only `summarise=T`
    output that is dependent on input parameters are `XCoverage` fields, which use `genomesize=INT`, and the `Xerr`
    fields that also use `targeterr=X`.)

    All modes will produce a `*.log` file. Other outputs produced depend on the run mode selected:

    1. `coverage=T`:
        * `*.coverage.tdt` = Predict genome coverage and accuracy for different depths of PacBio sequencing.

    2. `summarise=T`:
        * `*.fofn` = File of input subread filenames.
        * `*.summary.tdt` = Sequence summary data (read lengths, N50 etc.) for each sequence file, SMRT cell and the
                            combined dataset.
        * `*.zmw.tdt` = Individual summary data for all subreads.
        * `*.unique.tdt` = Individual summary data for **Unique** subreads (longest per ZMW).
        * `*.rq.tdt`= A summary of **Read Quality (RQ)** data.

    3. `calculate=T`:
        * `*.cutoffs.tdt` = Table of different read length and RQ cutoffs and the predicted depth and quality of
                            resulting assemblies.
        * `*.accuracy.tdt` = Summary table of predicted accuracies at different RQ/Xdepth combinations.

    4. `optimise=T`: No additional output. Optimal parameter suggestions are output in log file.

    5. `readfilter=T`:
        * `*.LXXXRQXXX.fasta` = reads filteres on min. read quality (`rqfilter=X` = `RQXXX`) and min. read length
                                (`lenfilter=X` = `LXXX`).
        * `*.LXXXRQXXX.fasta.index` = index for fasta file, used by `SeqList`.

    6. `ftxcov=INTLIST`):
        * `smrtscape_ftfreq.ftxcov.tdt` = Calculated full-length coverage for list of feature lengths, as well as their
                                          probability of detection (in raw subread data) if present at different
                                          population frequencies (`ftxfreq=NUMLIST`).

    7. `preassembly=FILE`:
        * `*.smrtscape.fas` = fragmentation-corrected preassembly reads.
        * `*.fragment.tdt` =  summary fragmentation data.

    Details are provided in the **Details** Section.


Details:
    ### ~ How SMRTSCAPE works ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###

    `SMRTSCAPE` is built on two ways of calculating "`X`" depth of coverage: (1) a simple calculation of mean X depth;
    (2) Empirical modelling of read depth distributions. These are combined as appropriate with estimations of the
    required depth of coverage to achieve the desired target genome accuracy. These calculations are described below.
    See descriptions of individual `SMRTSCAPE` functions for more information on how they are used in a given setting.

    As a result, `SMRTSCAPE` behaviour is largely controlled by four parameters:

    * `genomesize=INT`  : Genome size (bp) [0]
    * `targetcov=PERC`  : Target percentage coverage for final genome [99.999]
    * `targeterr=NUM`   : Target errors per base for preassembly [1/genome size]
    * `targetxcov=INT`  : Target 100% X Coverage for pre-assembly (e.g. error-corrected seed reads) [3]

    **NOTE:** If you are getting messages about insufficient data, you might want to try reducing the target error rate
    (`targeterr=NUM`) and/or the target "complete" coverage (`targetcov=PERC`).

    **WARNING:** Changing these settings between different runs with the same `basefile=X` setting may give some unusual
    behaviour. It is safest to use a new `basefile=X` if changing any of these settings. (Future `SMRTSCAPE` versions may
    enforce this.) The exception should be the `*.unique.tdt` and `*.zmw.tdt` outputs, which should be robust to changes
    in these settings. (These files are the slowest to generate, and so copying/reusing them could be useful. See
    `summarise=T` documentation for details.

    #### Simple calculation of mean X depth:

    This is a pure prediction based on average data. This is quite simpy the total amount of sequence (bp) divided by the
    genome size, given by `genomesize=INT` and equates to the traditional `XCoverage` value for genome sequence.

    #### Empirical modelling of read depth distributions:

    The heart of SMRTSCAPE is an empirical calculation based modelling read distributions, assuming random sampling of
    reads from across the genome. This calculates the total (summed) read lengths required to generate the desired genome
    coverage (`targetcov=X`) at different `X` depths, *e.g.* what total Xdepth is required to cover 99.999% of the genome
    at 3X (or more). Note that, with the exception of preassembly-based calculations, the _square root_ of the
    `targetcov=X` value is used;  the assembly process involves *two* layers of genome coverage: (1) coverage of seed
    reads by anchor reads to generate the error-corrected preassembly; (2) coverage of the preassembly.

    These "`XCovLimit`" data are calculated by incrementing total summed read lengths in 100 kb increments (adjusted with
    `xsteplen=X`). At each incremment, `genomesize=INT` is used to calculate the total `X` coverage, which is the mean
    depth at any given position. The probability of the target `X` coverage (starting at `1X`) given the total X coverage
    is then calculated using a Poisson distribution. If this probability exceeds the target genome coverage
    (`targetcov=X`), the current summed length is set as the `XCovLimit` for `X` and the target `X` increased by 1. The
    total summed read length is then incremented by `xsteplen` and the process repeated until the summed length reaches
    the total length of all subreads of at least the size set by `minreadlen=X` (default 500 bp).

    #### Target Genome Accuracy:

    The final piece of the puzzle is the depth of coverage required to achieve a particular level of accuracy. By
    default, `SMRTSCAPE` aims at perfection, which is less than 1 error per genome. (NOTE: For large genomes, this will
    require an unrealistic depth of coverage.)

    Accuracy is based on a majority reads covering a particular base with the correct call, assuming random calls at the
    other positions (*i.e.* the correct bases have to exceed 33% of the incorrect positions). For a given depth of
    coverage *for a given base*, the majority cutoff `N` is first calculated. Assuming random base calls for errors, this
    must exceed 1/4 of the read depth (rounded up):

        `N = int(0.25X) + 2`

    Accuracy is then calculated as the probability of achieving `N` correct calls, given the depth `X` and the `RQ` (or
    `1 = ErrPerBase`) using a binomial distribution with an even (random) distribution of errors. When using mean SMRT
    cell outputs, the `errperbase=NUM` parameter is used for this calculation. When using empirical data, the lowest read
    quality (`RQ`) value is used. (Calculations are made for different `RQ` cutoffs.)

    **NOTE:** Read Quality (`RQ`) values are *accuracy* measures, whereas `errperbase=NUM` sets an error rate. These are
    simply related, where `Accuracy = 1.0 - ErrPerBase`.


Example runs:

    To be added.



Commandline:
    ### ~ General Options ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
    basefile=FILE   : Sets the root filename for all output, including the log [smrtscape]
    genomesize=INT  : Genome size (bp) [0]
    targetcov=PERC  : Target percentage coverage for final genome [99.999]
    targeterr=NUM   : Target errors per base for preassembly [1/genome size]
    targetxcov=X    : Target 100% X Coverage for pre-assembly (e.g. error-corrected seed reads) [3]
    minanchorx=X    : Minimum X coverage for anchor (preassembly error-correcting) subreads [6]
    xmargin=X       : "Safety margin" inflation of desired minimum X coverage [1]
    xsteplen=X      : [Adv.] Size (bp) of increasing coverage steps for calculating required depths of coverage [1e5]
    force=T/F       : [Adv.] Whether to force regeneration of existing data, except `unique` and `zmw` tables [False]
    fullforce=T/F   : [Adv.] Whether to force regeneration of existing data including `unique` and `zmw` tables [False]
    ### ~ Genome Coverage Options ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
    coverage=T/F    : Whether to generate coverage report [False]
    avread=X        : Average read length (bp) [20000]
    smrtreads=X     : Average assemble output of a SMRT cell [50000]
    smrtunits=X     : Units for smrtreads=X (reads/Gb/Mb) [reads]
    errperbase=X    : Error-rate per base [0.14]
    maxcov=X        : Maximum X coverage to calculate for coverage=T analysis [100]
    bysmrt=T/F      : Whether to output estimated coverage by SMRT cell rather than X coverage [False]
    xnlist=LIST     : Additional columns giving % sites with coverage >= Xn [`minanchorx`->`targetxcov`+1]
    ### ~ SubRead Summary Options ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
    summarise=T/F   : Generate subread summary statistics including ZMW summary data [False]
    batch=FILELIST  : Batch input of multiple subread fasta files (wildcards allowed) if seqin=None [basefile.fofn]
    seqin=FILE      : Subread sequence file for analysis (over-rides batch command) [None]
    ### ~ Assembly Parameter Options ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
    calculate=T/F   : Calculate X coverage and target X coverage for given seed, anchor + RQ combinations [False]
    optimise=T/F    : Whether to output predicted "best" set of optimised parameters [False]
    minreadlen=X    : Absolute minimum read length for calculations (use minlen=X to affect summary also) [500]
    mapefficiency=X : Efficiency of mapping anchor subreads onto seed reads for correction [0.8]
    rq=X,Y          : Minimum (X) and maximum (Y) values for read quality cutoffs [0.8,0.9]
    rqstep=X        : Size of RQ jumps for calculation (min 0.001) [0.01]
    calcx=NUMLIST   : Add calculate entries for given raw Xdepths [25,30]
    calclen=INTLIST : Add calculate entries for given read length cutoffs [12000,15000,18000]
    ### ~ Subread Filtering Options ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
    readfilter=T/F  : Output filtered subreads into a new fasta file *.LXXXRQXXX.fasta
    rqfilter=X      : Min read quality for filtered subreads [0.85]
    lenfilter=X     : Min read length for filtered subreads [5000]
    ### ~ Feature Coverage Calculation Option ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
    ftxcov=INTLIST  : List of feature lengths for which to predict full-length coverage []
    ftxfreq=NUMLIST : List of feature frequencies for which to calculate probability of detection [0.01,0.05,1.0]
    ### ~ Preassembly Fragmentation analysis Options ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
    preassembly=FILE: Preassembly fasta file for which to assess/correct over-fragmentation [None]
    ### ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
"""
#########################################################################################################################
### SECTION I: GENERAL SETUP & PROGRAM DETAILS                                                                          #
#########################################################################################################################
import math, os, string, sys, time
slimsuitepath = os.path.abspath(os.path.join(os.path.dirname(os.path.realpath(__file__)),'../')) + os.path.sep
sys.path.append(os.path.join(slimsuitepath,'libraries/'))
sys.path.append(os.path.join(slimsuitepath,'tools/'))
### User modules - remember to add *.__doc__ to cmdHelp() below ###
import rje, rje_db, rje_obj, rje_seqlist #rje_tree
#import rje_dismatrix_V3 as rje_dismatrix
#########################################################################################################################
def history():  ### Program History - only a method for PythonWin collapsing! ###
    '''
    # 0.0.0 - Initial Compilation.
    # 1.0.0 - Initial working version for server.
    # 1.1.0 - Added xnlist=LIST : Additional columns giving % sites with coverage >= Xn [10,25,50,100].
    # 1.2.0 - Added assessment -> now PAGSAT.
    # 1.3.0 - Added seed and anchor read coverage generator (calculate=T).
    # 1.3.1 - Deleted assessment function. (Now handled by PAGSAT.)
    # 1.4.0 - Added new coverage=T function that incorporates seed and anchor subreads.
    # 1.5.0 - Added parseparam=FILES with paramlist=LIST to parse restricted sets of parameters.
    # 1.6.0 - New SMRTSCAPE program building on PacBio v1.5.0. Added predict=T/F option.
    # 1.6.1 - Updated parameters=T to incorporate that the seed read counts as X=1.
    # 1.7.0 - Added *.summary.tdt output from subread summary analysis. Added minreadlen.
    # 1.8.0 - preassembly=FILE: Preassembly fasta file to assess/correct over-fragmentation (use seqin=FILE for subreads)
    # 1.9.0 - Updated empirical preassembly mapefficiency calculation.
    # 1.10.0 - Added batch processing of subread files.
    # 1.10.1 - Fixed bug in batch processing.
    # 2.0.0 - Updated Version 2.x. Anchor read depth calculations no longer subtract seed coverage.
    # 2.0.1 - Fixed a bug with the preassembly MinX calculation and enabled seqin=FILE ftcovx analysis.
    # 2.0.2 - SeqIn does not generate *.fofn output.
    # 2.1.0 - Added MapLen and MapX to optimise.tdt output.
    # 2.1.1 - Fixed basefile bug.
    # 2.2.0 - Updated to work with fasta files generated from Sequel BAM files. (No RQ values.)
    # 2.2.1 - Fixed printLog typo bug.
    # 2.2.2 - Added dna=T to all SeqList object generation.
    # 2.2.3 - Fixed bug where SMRT subreads are not returned by seqlist in correct order. Fixed RQ=0 bug.
    '''
#########################################################################################################################
def todo():     ### Major Functionality to Add - only a method for PythonWin collapsing! ###
    '''
    # [ ] : Improved error estimation.
    # [Y] : Option to do a per-SMRT cell analysis.
    # [Y] : Add subread summary and seed read length estimation.
    # [ ] : Reading of genome size from refgenome file if genomesize=0?
    # [Y] : Update parameters to use calculate.
    # [?] : Implement rqmean=T/F      : Whether to use weighted mean RQ instead of min RQ for parameters=T calculations [False]
    # [?] : |-- Test which works better.
    # [Y] : Add predict=T setting to use specific settings and data to predict performance.
    # [Y] : Should `targetcov` be squared prior to analysis? (Needs seed AND anchor?)
    # [?] : Make sure that auto-generated seed lengths are recognised and calculated. Added but not convinced it's right.
    # [Y] : Add other key parameters to predict.tdt. (Check right udb/zdb being used for coverage and add docs.)
    # [?] : Add option to read/generate ZMW, Unique and RQ data with separate basefile. (Why?)
    # [Y] : Add an option to use restricted sets of SMRT cells. (Why?)
    # [Y] : Consider reducing default xsteplen to 1e5?
    # [Y] : Check removal of DIVISION between seed and anchor reads. (Seed reads are a SUBSET.)
    # [Y] : Add output of length- and RQ-filtered subreads for FALCON assembly (following parameter prediction).
    # [Y] : New unique subread output with minlen and RQ cut-off. Option to compile or output per SMRT cell/input file.
    # [X] : |-- Have suboutmode=STR (source/file/cell/smrt/combined) [combined] -> Generate *.LXXXRQXXX.subreads.fasta.
    # [ ] : Make defragmentation an option during preassembly reassessment.
    # [ ] : |-- Take mapefficency=X out of the preassembly assessment.
    # [Y] : Add option to predict within-read depth of coverage for sequences of a given length (e.g. Ty).
    # [ ] : Find out how to predict mapefficiency from first principles of read overlaps.
    # [Y] : Add a simpler read length calculation for FALCON based purely on (unique) depth of coverage.
    # [Y] : |-- This should probably use the coverage=T function?
    # [ ] : Options when using empirical data for coverage() to use best,worse or average data? (Based on length, volume or RQ?)
    # [ ] : Add some Rscript visualisations of data.
    # [ ] : Add repeatscreen, which removes reads that are (a) shorter than repeat elements, and (b) 100% repeat.
    # [ ] : |-- include option(s?) to trim ends of longer reads that consist of <1 repeat unit. (This would also do above!)
    # [X] : Add minseedlen=X parameter to use when there is insufficient data.
    # [ ] : Experiment with smaller steplen - see how it affects results versus speed.
    # [ ] : Test and refine accuracy calculations.
    # [X] : Add inbase=X option for alternative input basefile for looking for and loading files? (Could be awkward as would mess up use of Database defaults?)
    # [ ] : Read/check the genomesize=X setting from *.summary.tdt TotLength and XCoverage fields.
    # [ ] : Add calculate output to preassembly pre- & post-fragmentation correction = Length cutoffs for TargetXCov + XMargin.
    # [Y] : Add fullforce=T to remake udb but other force=T to just remake everything else.
    # [ ] : Add output of FALCON configuration file.
    # [ ] : Consider defaults: targetxcov=4; targeterr=1e-6.
    '''
#########################################################################################################################
def makeInfo(): ### Makes Info object which stores program details, mainly for initial print to screen.
    '''Makes Info object which stores program details, mainly for initial print to screen.'''
    (program, version, last_edit, copy_right) = ('SMRTSCAPE', '2.2.3', 'July 2018', '2017')
    description = 'SMRT Subread Coverage & Assembly Parameter Estimator'
    author = 'Dr Richard J. Edwards.'
    comments = ['This program is still in development and has not been published.',rje_obj.zen()]
    return rje.Info(program,version,last_edit,description,author,time.time(),copy_right,comments)
#########################################################################################################################
def cmdHelp(info=None,out=None,cmd_list=[]):   ### Prints *.__doc__ and asks for more sys.argv commands
    '''Prints *.__doc__ and asks for more sys.argv commands.'''
    try:### ~ [1] ~ Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
        if not info: info = makeInfo()
        if not out: out = rje.Out()
        ### ~ [2] ~ Look for help commands and print options if found ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
        cmd_help = cmd_list.count('help') + cmd_list.count('-help') + cmd_list.count('-h')
        if cmd_help > 0:
            rje.printf('\n\nHelp for {0} {1}: {2}\n'.format(info.program, info.version, time.asctime(time.localtime(info.start_time))))
            out.verbose(-1,4,text=__doc__)
            if rje.yesNo('Show general commandline options?'): out.verbose(-1,4,text=rje.__doc__)
            if rje.yesNo('Quit?'): sys.exit()           # Option to quit after help
            cmd_list += rje.inputCmds(out,cmd_list)     # Add extra commands interactively.
        elif out.stat['Interactive'] > 1: cmd_list += rje.inputCmds(out,cmd_list)    # Ask for more commands
        ### ~ [3] ~ Return commands ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
        return cmd_list
    except SystemExit: sys.exit()
    except KeyboardInterrupt: sys.exit()
    except: rje.printf('Major Problem with cmdHelp()')
#########################################################################################################################
def setupProgram(): ### Basic Setup of Program when called from commandline.
    '''
    Basic Setup of Program when called from commandline:
    - Reads sys.argv and augments if appropriate
    - Makes Info, Out and Log objects
    - Returns [info,out,log,cmd_list]
    '''
    try:### ~ [1] ~ Initial Command Setup & Info ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
        info = makeInfo()                                   # Sets up Info object with program details
        if len(sys.argv) == 2 and sys.argv[1] in ['version','-version','--version']: rje.printf(info.version); sys.exit(0)
        if len(sys.argv) == 2 and sys.argv[1] in ['details','-details','--details']: rje.printf('%s v%s' % (info.program,info.version)); sys.exit(0)
        if len(sys.argv) == 2 and sys.argv[1] in ['description','-description','--description']: rje.printf('%s: %s' % (info.program,info.description)); sys.exit(0)
        cmd_list = rje.getCmdList(sys.argv[1:],info=info)   # Reads arguments and load defaults from program.ini
        out = rje.Out(cmd_list=cmd_list)                    # Sets up Out object for controlling output to screen
        out.verbose(2,2,cmd_list,1)                         # Prints full commandlist if verbosity >= 2
        out.printIntro(info)                                # Prints intro text using details from Info object
        cmd_list = cmdHelp(info,out,cmd_list)               # Shows commands (help) and/or adds commands from user
        log = rje.setLog(info,out,cmd_list)                 # Sets up Log object for controlling log file output
        return (info,out,log,cmd_list)                      # Returns objects for use in program
    except SystemExit: sys.exit()
    except KeyboardInterrupt: sys.exit()
    except: rje.printf('Problem during initial setup.'); raise
#########################################################################################################################
### END OF SECTION I                                                                                                    #
#########################################################################################################################

                                                    ### ~ ### ~ ###

#########################################################################################################################
### SECTION II: SMRTSCAPE Class                                                                                         #
#########################################################################################################################
class SMRTSCAPE(rje_obj.RJE_Object):
    '''
    SMRTSCAPE Class. Author: Rich Edwards (2015).

    Str:str
    - Batch=FILELIST  : This is stored as a string too to assess whether using a *.fofn
    - Preassembly=FILE: Preassembly fasta file to assess/correct over-fragmentation (use seqin=FILE for subreads) [None]
    - SeqIn=FILE      : Subreads sequence input file
    - SMRTUnits=X     : Units for smrtreads=X (reads/Gb/Mb) [reads]

    Bool:boolean
    - BySMRT=T/F      : Whether to output estimated by SMRT cell rather than X coverage [False]
    - Calculate=T/F   : Calculate X coverage and target X coverage for given seed, anchor + RQ combinations [False]
    - Coverage=T/F    : Whether to generate coverage report [False]
    - FastSeedX=T/F   : Whether to use Fast SeedX estimator rather than more accurate "slow" method [True]
    - FullForce=T/F   : [Adv.] Whether to force regeneration of existing data including `unique` and `zmw` tables [False]
    - Optimise=T/F  : Whether to output
    - Predict=T/F     : Whether to add XCoverage prediction and efficiency estimation from parameters and subreads [False]
    - ReadFilter=T/F  : Output filtered subreads into a new fasta file *.LXXXRQXXX.subreads.fasta
    - RQMean=T/F      : Whether to use mean RQ instead of min RQ for calculations [False]
    - Summarise=T/F   : Generate subread summary statistics including ZMW summary data [False]

    Int:integer
    - LenFilter=X     : Min read length for filtered subreads [5000]
    - MaxCov=X        : Maximmum X coverage to calculate [100]
    - MinAnchorX=X    : Minimum X coverage for anchor subreads [10]
    - MinReadLen=X    : Absolute minimum read length for calculations (use minlen=X to affect summary also) [500]

    Num:float
    - AvRead=X        : Average read length (bp) [20000]
    - ErrPerBase=X    : Error-rate per base [0.14]
    - GenomeSize=X    : Genome size (bp) [4e9]
    - MapEfficiency=X : Efficiency of mapping anchor subreads onto seed reads for correction [0.8]
    - MaxRQ=X,Y          : Minimum (X) and maximum (Y) values for read quality cutoffs [0.8,0.9]
    - MinRQ=X,Y          : Minimum (X) and maximum (Y) values for read quality cutoffs [0.8,0.9]
    - RQFilter=X      : Min read quality for filtered subreads [0.85]
    - RQStep=X        : Size of RQ jumps for calculation (min 0.001) [0.01]
    - SMRTReads=X     : Average number of reads of a SMRT cell [50000]
    - TargetCov=X     : Target coverage for final genome [99.999]
    - TargetErr=X     : Target errors per base for preassembly [1e-6]
    - TargetXCov=X    : Target 100% X Coverage for pre-assembly [3]
    - XMargin=X       : "Safety margin" inflation of X coverage [1]
    - XStepLen=X      : Size (bp) of increasing coverage steps for calculating required depths of coverage [1e6]

    File:file handles with matching str filenames
    
    List:list
    - Batch=FILELIST  : Batch input of multiple subread fasta files (wildcards allowed) []
    - CalcX=NUMLIST   : Add calculate entries for given raw Xdepths [25,30]
    - CalcLen=INTLIST : Add calculate entries for given read length cutoffs [12000,15000,18000]
    - FTXCov=INTLIST  : List of feature lengths for which to predict full-length coverage []
    - FTXFreq=NUMLIST : List of feature frequencies for which to calculate probability of detection [0.01,1.0]
    - TargetXDepth= []    # List of target x (index) and required depth (value)
    - XCovLimits : List of total amount of sequence for each X coverage at TargetCov %coverage []
    - XnList=LIST     : Additional columns giving % sites with coverage >= Xn [10,25,50,100]

    Dict:dictionary
    - Accuracy : dictionary of lists of %accuracy for each xcoverage level for each rq {rq:[accbyxcov]}
    - PercXDepth : {XCov:[%coverage at each Xdepth]}

    Obj:RJE_Objects
    '''
#########################################################################################################################
    ### <1> ### Class Initiation etc.: sets attributes                                                                  #
#########################################################################################################################
    def _setAttributes(self):   ### Sets Attributes of Object
        '''Sets Attributes of Object.'''
        ### ~ Basics ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
        self.strlist = ['Batch','Preassembly','SeqIn','SMRTUnits']
        self.boollist = ['BySMRT','Calculate','Coverage','FastSeedX','FullForce','Optimise','Predict','ReadFilter','RQMean','Summarise']
        self.intlist = ['LenFilter','MaxCov','MinAnchorX','MinReadLen','TargetXCov','XMargin']
        self.numlist = ['AvRead','ErrPerBase','GenomeSize','MapEfficiency','MaxRQ','MinRQ','RQFilter','RQStep','SMRTReads','TargetCov','TargetErr','XStepLen']
        self.filelist = []
        self.listlist = ['Batch','CalcX','CalcLen','FTXCov','FTXFreq','TargetXDepth','XCovLimits','XnList']
        self.dictlist = ['Accuracy','PercXDepth']
        self.objlist = []
        ### ~ Defaults ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
        self._setDefaults(str='None',bool=False,int=0,num=0.0,obj=None,setlist=True,setdict=True,setfile=True)
        self.setStr({'SMRTUnits':'reads'})
        self.setBool({'BySMRT':False,'Calculate':False,'Coverage':False,'FastSeedX':True,'FullForce':False,
                      'Optimise':False,'ReadFilter':False,'Summarise':False})
        self.setInt({'LenFilter':5000,'MaxCov':100,'MinAnchorX':6,'MinReadLen':500,'TargetXCov':3,'XMargin':1})
        self.setNum({'AvRead':20000,'ErrPerBase':0.14,'MapEfficiency':0.8,'MaxRQ':0.9,'MinRQ':0.8,'RQFilter':0.85,
                     'RQStep':0.01,'GenomeSize':0,'SMRTReads':50000,'TargetCov':99.999,'TargetErr':-1,'XStepLen':1e5})
        self.list['XnList'] = []
        self.list['CalcX'] = [25,30]
        self.list['CalcLen'] = [12000,15000,18000]
        self.list['FTXFreq'] = [0.01,1.0]
        self.dict['PercXDepth'] = {0:[1.0]}
        ### ~ Other Attributes ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
        self._setForkAttributes()   # Delete if no forking
#########################################################################################################################
    def _cmdList(self):     ### Sets Attributes from commandline
        '''
        Sets attributes according to commandline parameters:
        - see .__doc__ or run with 'help' option
        '''
        for cmd in self.cmd_list:
            try:
                self._generalCmd(cmd)   ### General Options ### 
                self._forkCmd(cmd)  # Delete if no forking
                ### Class Options (No need for arg if arg = att.lower()) ### 
                #self._cmdRead(cmd,type='str',att='Att',arg='Cmd')  # No need for arg if arg = att.lower()
                self._cmdReadList(cmd,'str',['SMRTUnits'])   # Normal strings
                #self._cmdReadList(cmd,'path',['Att'])  # String representing directory path
                self._cmdReadList(cmd,'file',['Batch','Preassembly','SeqIn'])  # String representing file path
                #self._cmdReadList(cmd,'date',['Att'])  # String representing date YYYY-MM-DD
                self._cmdReadList(cmd,'bool',['BySMRT','Calculate','Coverage','FastSeedX','FullForce','Optimise','Predict','ReadFilter','RQMean','Summarise'])  # True/False Booleans
                self._cmdReadList(cmd,'int',['LenFilter','MaxCov','MinAnchorX','MinReadLen','TargetXCov','XMargin'])   # Integers
                self._cmdReadList(cmd,'float',['AvRead','ErrPerBase','GenomeSize','MapEfficiency','RQFilter','RQStep','SMRTReads','TargetErr','XStepLen']) # Floats
                self._cmdReadList(cmd,'perc',['TargetCov'])
                self._cmdRead(cmd,'fmax','MaxRQ','rq')   # Integer value part of min,max command
                self._cmdRead(cmd,'fmin','MinRQ','rq')   # Integer value part of min,max command
                self._cmdReadList(cmd,'list',['ParamList'])  # List of strings (split on commas or file lines)
                self._cmdReadList(cmd,'ilist',['CalcLen','FTXCov','XnList'])  # List of integers (split on commas or file lines)
                self._cmdReadList(cmd,'nlist',['CalcX','FTXFreq'])  # List of integers (split on commas or file lines)
                #self._cmdReadList(cmd,'clist',['Att']) # Comma separated list as a *string* (self.str)
                self._cmdReadList(cmd,'glist',['Batch','ParseParam']) # List of files using wildcards and glob
                #self._cmdReadList(cmd,'cdict',['Att']) # Splits comma separated X:Y pairs into dictionary
                #self._cmdReadList(cmd,'cdictlist',['Att']) # As cdict but also enters keys into list
            except: self.errorLog('Problem with cmd:%s' % cmd)
        if self.getBool('FullForce'): self.setBool({'Force':True})
#########################################################################################################################
    ### <2> ### Main Class Backbone                                                                                     #
#########################################################################################################################
    def run(self):  ### Main run method
        '''
        Main run method.
        '''
        try:### ~ [1] ~ Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            #i# The setup() function sets up filenames and basefile, corrects targeterr/genomesize etc. and the Database
            #i# object for storing data.
            self.setup()
            ### ~ [2] ~ Main run modes ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            #i# These are checked in reverse order of superseding commands:
            #i# - The preassembly fragmentation analysis takes precedence.

            if self.getStrLC('Preassembly'): return self.preassemblyFrag()
            if self.getBool('ReadFilter'): return self.readFilter()
            if self.getBool('Optimise'): self.optimise()    # Includes calculate if required.
            elif self.getBool('Calculate'): self.calculate()    # Includes summarise if required.
            elif self.getBool('Summarise'):
                if not self.summarise(): return False
            if self.getBool('Coverage'): self.coverage()        # Does not require summarise but will use if present.
            if self.list['FTXCov']: self.ftXCoverage()
            return
        except:
            self.errorLog(self.zen())
            raise   # Delete this if method error not terrible
#########################################################################################################################
    def setup(self):    ### Main class setup method.
        '''Main class setup method.'''
        try:### ~ [1] Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            ## ~ [1a] Setup basefile ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            if not self.baseFile(return_none=None) and self.getStrLC('SeqIn'):
                basename = rje.baseFile(self.getStr('SeqIn'),strip_path=True)
                if basename.endswith('.subreads'): basename = os.path.splitext(basename)[0]
                self.baseFile(basename)
            elif not self.baseFile(return_none=None) and self.getStrLC('Preassembly'):
                basename = rje.baseFile(self.getStr('Preassembly'),strip_path=True)
                if basename.endswith('.preassembly'): basename = os.path.splitext(basename)[0]
                self.baseFile(basename)
            elif not self.baseFile(return_none=None) and self.getStr('Batch').endswith('.fofn'):
                basename = rje.baseFile(self.getStr('Batch'),strip_path=True)
                self.baseFile(basename)
            elif not self.baseFile(return_none=None): self.baseFile('smrtscape')
            if self.getStrLC('REST') and not self.basefile(return_none=''): self.basefile('smrtscape')
            self.obj['DB'] = rje_db.Database(self.log,self.cmd_list+['tuplekeys=T'])
            self.db().basefile(self.basefile())
            self.printLog('#BASE','Basename set for input/output: %s.*' % self.basefile())

            #!# Read/check the genomesize=X setting from *.summary.tdt TotLength and XCoverage fields
            while not self.getInt('GenomeSize'):
                if self.i() >= 0: self.setNum({'GenomeSize':int(float(rje.choice('Enter Genome Size (bp)',confirm=True)))})
                else: raise ValueError('Need to set genomesize=X')
            self.printLog('#GSIZE','Genome Size: %s bp' % rje.iStr(self.getInt('GenomeSize')))

            if self.getNum('TargetErr') < 0: self.setNum({'TargetErr':1.0/self.getInt('GenomeSize')})
            self.printLog('#PCERR','Target Error Rate = %s errors per base.' % rje.expectString(self.getNum('TargetErr')))
            ### ~ [2] Setup Batch list ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            fofn = '%s.fofn' % self.baseFile()
            self.debug('%s: %s' % (fofn,self.getStr('Batch') == fofn))
            if self.getStrLC('SeqIn'):
                if self.list['Batch']: self.printLog('#BATCH','Batch file list updated to seqin: [%s]' % self.getStr('SeqIn'))
                else: self.printLog('#BATCH','Batch file list set to seqin: [%s]' % self.getStr('SeqIn'))
                self.list['Batch'] = [self.getStr('SeqIn')]
            if self.list['Batch']:
                if self.getStr('Batch') == fofn:
                    self.printLog('#FOFN','%d file names loaded from %s' % (len(self.list['Batch']),fofn))
                elif not self.getStrLC('SeqIn'):
                    rje.backup(self,fofn)
                    open(fofn,'w').write(rje.join(self.list['Batch'],'\n'))
                    self.printLog('#FOFN','%d file name(s) output to %s' % (len(self.list['Batch']),fofn))
            elif rje.exists(fofn) and (self.i() < 0 or rje.yesNo('Load batch file list from %s?' % fofn)):
                self._cmdRead('batch=%s' % fofn,'list','Batch')
                self.printLog('#FOFN','%d file names loaded from %s' % (len(self.list['Batch']),fofn))
            return True     # Setup successful
        except: self.errorLog('Problem during %s setup.' % self.prog()); return False  # Setup failed
#########################################################################################################################
    def restSetup(self):    ### Sets up self.dict['Output'] and associated output options if appropriate.
        '''
        Run with &rest=help for general options. Run with &rest=full to get full server output as text or &rest=format
        for more user-friendly formatted output. Individual outputs can be identified/parsed using &rest=OUTFMT for:

        coverage = main results table
        '''
        try:### ~ [0] ~ Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            for outfmt in self.restOutputOrder(): self.dict['Output'][outfmt] = 'No output generated.'
            #!# Add specific program output here. Point self.dict['Output'][&rest=X] to self.str key.
            return
        except: self.errorLog('RestSetup error')
#########################################################################################################################
    def restOutputOrder(self): return ['coverage']
#########################################################################################################################
    ### <3> ### PacBio Genome Coverage Methods                                                                          #
#########################################################################################################################
    def coverage(self): ### Calculates estimated % coverage and accuracy of genome sequencing.                      #!#
        '''Calculates estimated % coverage and accuracy of genome sequencing.'''
        try:### ~ [1] Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            self.printLog('#~~#','# ~~~~~~~~~~~~~~~~~~~~ CALCULATING GENOME COVERAGE ~~~~~~~~~~~~~~~~~~~~ #')
            ## ~ [1a] General Settings setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            self.coverageSetup()                    # Sets up smrtread stats and xnlist
            targetxcov = self.targetXDepth()        # Sets up target X depth lists
            self.debug(targetxcov)
            self.accuracy(self.getInt('MaxCov'))    # Sets up
            ## ~ [1b] Setup table ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            if self.getBool('BySMRT'): ckey = 'SMRT'
            else: ckey = 'XCoverage'
            cfields = ['XCoverage','SMRT','%Coverage','%Accuracy','%Complete','MinX']

            # XCoverage = Total mean depth of coverage
            # SMRT = Total number of SMRT cells
            # %Coverage = Estimated %coverage of assembly
            # %Accuracy = Estimated %accuracy of assembled genome
            # %Complete = Product of %coverage and %accuracy
            # MinX = Estimated minimum depth of coverage (meeting targetcov=X)
            # Xn = Estimated coverage at nX depth
            for xn in self.list['XnList']: cfields.append('%%X%d' % xn)
            cdb = self.db().addEmptyTable('coverage',cfields,[ckey])
            ## ~ [1c] Setup stats for coverage calculations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            cov_per_base_per_read = self.getNum('AvRead') / self.getNum('GenomeSize')
            # Calculate reads = number of reads per cycle of calculations
            if self.getBool('BySMRT'): reads = self.getInt('SMRTReads')                 # If going per SMRT cell
            else: reads = int(0.5 + self.getNum('GenomeSize') / self.getNum('AvRead'))  # if going per X coverage
            self.debug(self.int)
            self.debug(self.num)
            self.debug('BySMRT: %s; Reads = %d' % (self.getBool('BySMRT'),reads))

            ### ~ [2] Calculate stats for each round of sequencing ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            xcoverage = 0      # Total X coverage of sequencing
            while xcoverage < self.getNum('MaxCov'):    # Cycle until limits reached
                self.progLog('\r#XCOV','Calculating coverage stats: %.1f%%' % (100.0 * xcoverage / self.getNum('MaxCov')))
                # Add sequence
                xcoverage += self.getNum('AvRead') * reads / self.getNum('GenomeSize')
                # Number of SMRT cells
                smrt = (self.getNum('GenomeSize') * xcoverage) / (self.getNum('AvRead') * self.getNum('SMRTReads'))
                # SeedX for determining coverage: TargetXCov if enough, else XCoverage.
                seedx = min(targetxcov[self.getInt('TargetXCov')],xcoverage)       # This is deemed required for optimal assembly
                # AnchX is the total xcoverage
                anchx = xcoverage
                #i# Percentage coverage is defined as the product of:
                #i# 1. The probability of 1x+ coverage given SeedX
                #i# 2. The probability of at least MinAnchorX coverage given the full XCoverage
                pccov = 100.0 * rje.logPoisson(1,seedx,exact=False,callobj=self) * rje.logPoisson(self.getInt('MinAnchorX'),xcoverage,exact=False,callobj=self)
                pcacc = 0.0
                # Calculate X coverage counts using binomial
                #self.dict['XCovPerBase'] = {}   # Dictionary of {TotalX:[List where index is X coverage and number is proportion of reads]}
                xcov = self.pcXDepth(anchx)
                covsum = sum(xcov[self.getInt('MinAnchorX'):])
                self.debug(covsum)
                self.debug(xcov)
                if covsum:
                    for x in range(self.getInt('MinAnchorX'),len(xcov)):
                        #self.debug(self.accuracy(x+1))   # Seed too, so x+1!
                        pcacc += xcov[x] * self.accuracy(x+1)   # Seed too, so x+1!
                    pcacc = 100.0 * pcacc / covsum
                elif pccov: raise ValueError('Somehow have anchor coverage with 0% genome coverage.')
                # Minimum Xcoverage
                minx = 0
                self.debug(xcoverage)
                if xcoverage > targetxcov[-1]:
                    targetxcov = self.targetXDepth(maxcov=int(xcoverage+1))
                while xcoverage > targetxcov[minx+1]: minx += 1
                # Setup entry for this level of XCoverage
                centry = {'XCoverage':rje.sf(xcoverage,3),'SMRT':rje.sf(smrt,3),'%Coverage':rje.sf(pccov,5),
                          '%Accuracy':rje.sf(pcacc,5),'%Complete':rje.sf(pccov*pcacc/100.0,5),'MinX':minx}
                if not self.getBool('BySMRT'): centry['XCoverage'] = int(centry['XCoverage']+0.1)
                xcov = self.pcXDepth(xcoverage)
                # XnList
                for xn in self.list['XnList']:
                    #self.bugPrint('%d >> %s = %s' % (xn,xcov[xn:],sum(xcov[xn:])))
                    if xn <= len(xcov): centry['%%X%d' % xn] = rje.sf(100.0*sum(xcov[xn:]),5)
                    else: centry['%%X%d' % xn] = 0.000
                cdb.addEntry(centry)
                #self.debug(centry)
            self.printLog('\r#XCOV','Calculated coverage stats upto %dX coverage.' % self.getInt('MaxCov'))

            ### ~ [4] Save results ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            for xkey in cdb.dataKeys():
                cdb.dict['Data'][float(xkey)] = cdb.dict['Data'].pop(xkey)
            cdb.saveToFile()

            return
        except: self.errorLog('%s.coverage error' % self.prog())
#########################################################################################################################
    def coverageSetup(self):    ### Sets up specific attributes for coverage function.                              #V2.0
        '''
        Sets up specific attributes for coverage function. This includes loading the unique SMRT cell read data if found
        and sorting out SMRT units and SMRT reads.
        '''
        try:### ~ [0] ~ Setup Coverage ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            if not self.baseFile(return_none=None): self.baseFile('pacbio')
            ## ~ [0a] Generate data from summarise *.unique.tdt ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            udb = self.db('unique',add=True,mainkeys=['SMRT','ZMW'])
            if udb and self.i() > 0 and not rje.yesNo('SMRTSCAPE unique data found: use for coverage calculation?'):
                udb = None
            if udb:
                self.printLog('#SMRT','Calculating SMRT Output from unique data.')
                udb.dropFields(['Pos'])
                if not udb.formatted(): udb.dataFormat({'Len':'int','RQ':'num','Seq':'int'})
                for entry in udb.entries(): entry['Seq'] = 1
                udb.compress(['SMRT','RQ'],default='sum')
                udb.dropFields(['ZMW','RN'])
                udb.makeField('Len*RQ','RQSum')         # Calculate sum of quality bases for mean RQ calculation
                udb.compress(['SMRT'],default='sum')    # Compress to data per SMRT cell
                for entry in udb.entries(): entry['RQ'] = float(entry['RQSum']) / entry['Len']
                for entry in udb.entries(): entry['RQSum'] = 'All'
                udb.compress(['RQSum'],default='mean',rules={'Len':'mean','RQ':'mean','Seq':'mean'})     # Compress to data per SMRT cell
                udb.dropFields(['SMRT'])
                udata = udb.entries()[0]
                self.printLog('#SMRT','Mean Total Length = %.2fMb' % (udata['Len']/1e6))
                self.printLog('#SMRT','Average Read Length = %.2fkb' % (udata['Len']/udata['Seq']/1e3))
                self.printLog('#SMRT','Mean RQ = %.3f' % udata['RQ'])
                self.printLog('#SMRT','Mean SMRTReads = %s' % rje.iStr(udata['Seq']))
                self.setStr({'SMRTUnits':'reads'})
                self.setNum({'SMRTReads':udata['Seq'],'AvRead':udata['Len']/udata['Seq'],'ErrPerBase':udata['RQ']})
            ## ~ [0b] SMRTReads ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            while self.getStrLC('SMRTUnits') not in ['reads','gb','mb']:
                txt = 'SMRTUnits "%s" not recognised'
                if self.getNum('SMRTReads') < 10: smrtunits = 'Gb'
                elif self.getNum('SMRTReads') > 10000: smrtunits = 'reads'
                else: smrtunits = 'Mb'
                if self.i() < 0 or rje.yesNo('%s: switch to (%s) %s?' % (txt,self.getNum('SMRTReads'),smrtunits)):
                    self.setStr({'SMRTUnits':smrtunits})
                elif self.i() >0: self.setStr({'SMRTUnits':rje.choice('SMRTUnits (reads/Gb/Mb)?')})
                self.printLog('#UNITS','%s => %s' % (txt,self.getStr('SMRTUnits')))
            if self.getStrLC('SMRTUnits') in ['gb','mb']:
                smrttotal = self.getNum('SMRTReads') * {'gb':1e9,'mb':1e6}[self.getStrLC('SMRTUnits')]
                txt =  '%s %s @ %.3f kb/read' % (self.getNum('SMRTReads'),self.getStr('SMRTUnits'),self.getNum('AvRead')/1000.0)
                self.setNum({'SMRTReads':smrttotal/self.getNum('AvRead')})
                txt += ' => %s reads' % rje.iStr(int(self.getNum('SMRTReads')))
                self.printLog('#READS',txt)
            #!# Should we summarise parameters even if udb not used? (Yes?)
            ## ~ [0c] XnList ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            xmin = min(self.getInt('TargetXCov'),self.getInt('MinAnchorX'))
            xmax = max(self.getInt('TargetXCov'),self.getInt('MinAnchorX')+1+self.getInt('XMargin'))
            xnlist = range(xmin,xmax)
            for xn in self.list['XnList']:
                if xn == '': continue
                try:
                    ixn = int(xn)
                    if xn not in [ixn,'%d' % ixn]: self.printLog('#XN','"%s" -> %dX' % (xn,ixn))
                    if ixn == 0: self.printLog('#XN','No point in 0X output: use 1-%Coverage.')
                    elif ixn == 1: self.printLog('#XN','No point in 1X output: use %Coverage.')
                    else: xnlist.append(ixn)
                except: self.errorLog('Could not process %s as part of XnList. (Integers only.)' % xn)
            xnlist.sort()
            if xnlist: self.printLog('#XN','XnList: %sX.' % rje.join(rje.split('%s' % xnlist,','),'X, ')[1:-1])
            self.list['XnList'] = xnlist

            return True     # Setup successful
        except: self.errorLog('Problem during %s coverageSetup.' % self.prog()); return False  # Setup failed
#########################################################################################################################
    def targetXDepth(self,purelen=False,sqroot=True,reset=False,maxcov=0,maxlen=0): ### Sequencing needed for target Xdepth  #V2.0
        '''
        Calculates lists of target X (list index) and required X depth (list value). It uses self.getPerc('TargetCov')
        to determine what proportion of the genome must be covered at the target Xdepth.

        >> purelen:bool [False] = Whether to return pure length requirements for targetX (True) or Xdepth (False)
        >> sqroot:bool [True] = Whether sqrt(targetcov) should be used to adjust for two layers of read mapping.
        >> reset:bool [False] = Whether to reset the xcovlimits (in place!) to [0] before recalulating.
        >> maxcov:int [self.getInt('MaxCov')] = Maximum depth of coverage to calculate to.
        >> maxlen:int [maxcov x GenomeSize or sum unique read lengths] = Max total sequence depth to exceed.
        << xcovlimits:list = Target total XDepth required for each target min Xdepth. (NOTE: List edited in place!)
        '''
        try:### ~ [0] Setup parameters ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            #i# This methods sets up self.list['TargetXDepth'] and self.list['XCovLimits'] lists. The difference between
            #i# these two lists is simply that the former is converted into XCoverage, wherease the latter is pure read
            #i# length totals. TargetXDepth is used for coverage(), whereas all other methods use XCovLimits.
            udb = self.udb(add=False)
            if reset or not self.list['TargetXDepth']:
                self.list['TargetXDepth'] = [0]
                self.list['XCovLimits'] = [0]

            #i# NOTE: TargetXDepth was used for coverage() and seedXForBestCoverage(). The seedXForBestCovergae() method
            #i# is obsolete in V2.x as seed reads are also used for read correction. When the optimal seed read depth
            #i# cannot be met then using all of the data seems to be the way to go!

            #i# The TargetXDepth limits are defined by exceeding both (a) the combined total sequence length available
            #i# (if known), and (b) the maximum target depth of coverage to achieve.

            #i# maxlen:int = This is the maximum sequence length to be reached. Units are bp.
            #i# If self.udb() is found, Unique ZMW subread sequence data will be used. Otherwise, self.getInt('MaxCov').
            #!# This should be called as part of summarise() after data is parsed
            #!# It then will not need to be called (or should recognise existing setup) as part of coverage()
            if not maxcov: maxcov = self.getInt('MaxCov')
            if not maxlen:
                maxlen = maxcov * self.getNum('GenomeSize')
                if self.udb(add=False):     # Already present -> Make sure it is loaded when summarise=T.
                    maxlen = sum(udb.dataList(udb.entries(),'Len',sortunique=False,empties=True))

            #i# maxdepth:int [0] = This is the maximum target Xdepth to be reached. (len(self.list['TargetXDepth'])-1)
            #i# This is set by the maximum value derived from TargetXCov, MinAnchorX and XMargin
            maxdepth = max(self.getInt('TargetXCov'),self.getInt('MinAnchorX')+1)
            maxdepth += self.getInt('XMargin')

            ### ~ [1] Check for sufficient existing data ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            #i# Unless reset=T, list lengths will be checked and then extended if required, or returned if not.
            xcovlimits = self.list['XCovLimits']
            xlen = xcovlimits[-1]
            if maxlen <= xlen and maxdepth <= len(xcovlimits):
                if purelen: return self.list['XCovLimits']
                else: return self.list['TargetXDepth']

            ### ~ [2] Calculate TargetXDepth values data ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            if udb: self.printLog('#MAXLEN','TargetXDepth maxlen set from Unique ZMW subread data')
            else: self.printLog('#MAXLEN','TargetXDepth maxlen set from MaxCov and GenomeSize.')

            ## ~ [2a] Calculate list of target x (index) and required depth (value) ~~~~~~~~~~~~~~~ ##
            #i# targetcov:perc [self.getPerc('TargetCov')] = The proportion (or percentage) of the genome to be covered.
            targetcov = self.getPerc('TargetCov')  # Needs square root for anchor x seed
            if sqroot: targetcov = math.sqrt(self.getPerc('TargetCov'))  # Needs square root for anchor x seed
            steplen = self.getNum('XStepLen')

            #i# The heart of SMRTSCAPE is the TargetXDepth calculation. These are the summed read lengths (or Xdepth)
            #i# required to generate the desired percentage coverage of the genome (targetcov=X) at different minimum
            #i# depths of X coverage. TargetXDepth is built on a simplified assumption based on a random distribution
            #i# of PacBio reads and ignoring chromosome length. It is assumed that the probability of a given depth of
            #i# coverage at any given site follows a Poisson distribution where the expected depth of coverage is simply
            #i# the total sequencing length divided by the genome size. When this probability for the desired depth of
            #i# coverage exceeds the desired level set by targetcov=X, the required sequence length is set as the
            #i# target for the desired X depth.

            #!# Note when square root of the targetcov=X value is used due to the two layers of genome coverage:
            #!# (1) coverage of seed reads by anchor reads to generate the pre-assembly;
            #!# (2) coverage of the pre-assembly.

            #i# Extend XCovLimits and TargetXDepth for each XCoverage until limits reached
            while xcovlimits[-1] <= maxlen or len(xcovlimits) <= maxdepth:
                self.progLog('\r#XDEPTH','Setting up TargetXDepth & XCovLimits: %dX (%s bp)' % (len(xcovlimits),rje.iStr(xlen)))
                #i# Quick cycle through initial xlen steps
                if xlen/self.getNum('GenomeSize') < len(xcovlimits): xlen += steplen; continue
                #i# Assess whether probability of exceeding next Xdepth exceeds targetcov, given expected (average) Xdepth.
                while rje.poisson(len(xcovlimits),xlen/self.getNum('GenomeSize'),exact=False,callobj=self) >= targetcov:
                    xcovlimits.append(xlen)
                    self.list['TargetXDepth'].append(xlen/self.getNum('GenomeSize'))
                xlen += steplen
            self.printLog('\r#XDEPTH','Set up TargetXDepth & XCovLimits for up to %dX (%s bp).' % (len(xcovlimits)-1,rje.iStr(xlen)))
            ## ~ [2b] Return relevant data list ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            if purelen: return self.list['XCovLimits']
            else: return self.list['TargetXDepth']
        except: self.errorLog('%s.targetXDepth error' % self.prog())
#########################################################################################################################
    def accuracy(self,xdepth,rq=0):   ### Calculate accuracy (if required) at xdepth and returns                    #V2.0
        '''
        This method returns the predicted sequencing accuracy for a given sequencing depth (xdepth) based on the
        errperbase=X parameter. It is only used for coverage=T output. Accuracies are stored in self.dict['Accuracy'][rq],
        which has xdepth as the index and the accuracy at that depth as the value. The first two entries are 0, and
        (1 - ErrPerBase). For higher Xdepth, the accuracy is calculated assuming a non-biased error distribution and
        independence of sites. Accuracy is based on a majority reads covering a particular base with the correct call,
        assuming random calls at the other positions (i.e. the correct bases have to exceed 33% of the number of
        incorrect positions). This is clearly a crude approximation but should give a reasonable ballpark estimate.
        If the predicted number of errors at the previous Xdepth is less than one base, accuracy is rounded up to 1.0.

        >> xdepth:int = The Xdepth of coverage for which an accuracy estimate is needed.
        << estimated accuracy at given Xdepth: num (0.0-1.0)
        '''
        try:### ~ [1] Calculate ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            if not rq: rq = 1.0 - self.getNum('ErrPerBase')
            if rq in self.dict['Accuracy']: accbyxcov = self.dict['Accuracy'][rq]
            else: accbyxcov = self.dict['Accuracy'][rq] = [0,rq]     # Setup 0X and 1X.
            #i# Additional calculations are only required when the desired Xdepth is not already calculated.
            while len(accbyxcov) <= xdepth:
                if not int((1.0 - accbyxcov[-1]) * self.getNum('GenomeSize')): # Too few errors to worry!
                    accbyxcov.append(1.0)
                    continue
                xcov = len(accbyxcov)
                #?#majority = int(0.33*xcov/1.33) + 1        # Number of correct reads needed for majority
                majority = int(0.25*xcov) + 2        # Number of correct reads needed for majority > 1/4 bases.
                try: accbyxcov.append(rje.logBinomial(majority,xcov,rq,exact=False,callobj=self))
                except: accbyxcov.append(rje.logPoisson(majority,xcov*rq,exact=False,callobj=self))
            return accbyxcov[xdepth]
        except: self.errorLog('%s.accuracy error' % self.prog())
#########################################################################################################################
    def seedXForBestCoverage(self,xcoverage):   ### Calculate optimal seedX for best %coverage given Xcoverage      #V2.0
        '''Calculate optimal seedX for best %coverage given Xcoverage.'''
        try:### ~ [0] Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            #i# NOTE: V2.x no longer separates seed reads from anchor reads. (FALCON doesn't)!
            #i# As a result, this optimisation is now more complex than needed: the optimal seedX should be independent
            #i# of the possible AnchorX. If there is enough data, seedX should be the Xdepth required for full coverage
            #i# at the TargetXCov. Otherwise, it is the full xcoverage.
            #i# NOTE: XMargin and MapEfficiency are not used at this point. (Should they be? Probably not. Part of output.)
            self.printLog('#DEV','Calling obsolete seedXForBestCoverage()')
            targetxcov = self.targetXDepth()
            return min(targetxcov[self.getInt('TargetXCov')],xcoverage)
        except: self.errorLog('%s.seedXForBestCoverage error' % self.prog())
#########################################################################################################################
    def xCovLimits(self): ### Generates/returns XCovLimits list of summed read lengths generating whole genome X Coverage
        '''Generates/returns XCovLimits list of summed read lengths generating whole genome X Coverage.'''
        # This is basically targetXDepth but without the conversion to Xdepth
        self.printLog('#DEV','Calling obsolete xCovLimits()')
        return self.targetXDepth(purelen=True,sqroot=True)
#########################################################################################################################
    def pcXDepth(self,xcov,xdepth=-1):  ### (Calculates and) returns the proportion of coverage at Xdepth for given Xcov.
        '''
        (Calculates and) returns the proportion of coverage at Xdepth for given Xcov.
        >> xcov:int = the overall X coverage of the genome.
        >> xdepth:int = the specific X depth for which to return proportional coverage. Returns list if < 0.
        '''
        try:### ~ [0] Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            if xcov < 0: raise ValueError('Cannot have XCoverage < 0!')
            xdepth = int(xdepth)
            xdict = self.dict['PercXDepth']
            ### ~ [1] Calculate ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            if xcov not in xdict:
                xdict[xcov] = []
                bases = int(self.getNum('GenomeSize'))
                while bases > 1:
                    xdict[xcov].append(rje.logPoisson(len(xdict[xcov]),xcov,exact=True,callobj=self))
                    bases -= self.getNum('GenomeSize') * xdict[xcov][-1]
            ### ~ [2] Return ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            if xdepth < 0: return xdict[xcov]
            elif xdepth > len(xdict[xcov]): return 0.0
            else: return xdict[xcov][xdepth]
        except: self.errorLog('%s.pcXDepth error' % self.prog()); raise
#########################################################################################################################
    ### <4> ### Summarise Subreads Methods                                                                              #
#########################################################################################################################
    def summarise(self):    ### Generate subread summary.
        '''Generate subread summary.'''
        try:### ~ [0] Setup SeqList and basic stats ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            self.printLog('#~~#','# ~~~~~~~~~~~~~~~~~~~~ GENERATING SUBREAD SUMMARY ~~~~~~~~~~~~~~~~~~~~ #')
            db = self.db()  # Database object
            seqbatch = []   # List of SeqList objects
            self.printLog('#BATCH','%s sequence files to process.' % rje.iLen(self.list['Batch']))
            for seqfile in self.list['Batch']:
                seqcmd = self.cmd_list + ['seqmode=file','autoload=T','summarise=F','seqin=%s' % seqfile,'autofilter=F','dna=T']
                seqbatch.append(rje_seqlist.SeqList(self.log,seqcmd))
            self.printLog('#BATCH','%s sequence files to summarise.' % rje.iLen(seqbatch))
            if not seqbatch: raise IOError('No batch input fasta files found! Set batch=FILELIST.')
            cells = []  # List of SMRT Cell identifiers. Add dictionary converter for names. Or ask?
            zdb = self.db().addEmptyTable('zmw',['SMRT','ZMW','RN','Len','Pos','RQ','Seq'],['SMRT','ZMW','RN'])
            cdb = self.db().addEmptyTable('smrt',['SMRT','Name'],['Name'])
            ### ~ [1] Calculate ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            sdb = self.db().addEmptyTable('summary',['SMRT','SeqNum','TotLength','MinLength','MaxLength','MeanLength','MedLength','N50Length','XCoverage'],['SMRT'])
            for seqlist in seqbatch:
                seqdata = seqlist.summarise()   # This will summarise read lengths etc.
                basename = rje.baseFile(seqlist.getStr('SeqIn'),strip_path=True)
                if basename.endswith('.subreads'): basename = os.path.splitext(basename)[0]
                seqdata['SMRT'] = basename
                seqdata['XCoverage'] = seqdata['TotLength'] / self.getNum('GenomeSize')
                sdb.addEntry(seqdata)
                # SMRT = SMRT cell identifier
                # ZMW = ZMW identifier
                # RN = subread number for that ZMW
                # Len = length of actual sequence read in
                # Pos = Position information from header
                # RQ = RQ Value
                # Partition out ZMWs and make histograms of lengths and numbers
                #>m150625_001530_42272_c100792502550000001823157609091582_s1_p0/9/0_3967 RQ=0.784
                #>m150625_001530_42272_c100792502550000001823157609091582_s1_p0/11/0_20195 RQ=0.868
                #>m150625_001530_42272_c100792502550000001823157609091582_s1_p0/12/0_18976 RQ=0.823
                #>m150625_001530_42272_c100792502550000001823157609091582_s1_p0/14/5776_27852 RQ=0.807
                #...
                #>m150625_043200_42272_c100792502550000001823157609091583_s1_p0/163464/0_1712 RQ=0.854
                prevzmw = None; rn = 0; sx = 0.0; stot = seqlist.seqNum(); norqx = 0
                for seq in seqlist.seqs():
                    self.progLog('\r#SUB','Processing subreads: %.2f%%' % (sx/stot)); sx += 100.0
                    (name,sequence) = seqlist.getSeq(seq)
                    self.debug(name)
                    #!# Add additional format checks
                    zdata = rje.split(rje.replace(name,'/',' '))
                    try: [smrt,zmw,pos] = zdata[:3]
                    except: raise ValueError('Subread sequence name format error! Need raw PacBio subreads.')
                    rq = zdata[-1]
                    #[smrt,zmw,pos,rq] = rje.split(rje.replace(name,'/',' '))
                    if smrt not in cells: cells.append(smrt)
                    smrt = cells.index(smrt)
                    if zmw != prevzmw: prevzmw = zmw; rn = 0
                    rn += 1
                    try: rq = rje.matchExp('RQ=(\S+)',rq)[0]
                    except: rq = 1.0 - self.getNum('ErrPerBase'); norqx += 1
                    zentry = {'SMRT':smrt,'ZMW':zmw,'RN':rn,'Len':len(sequence),'Pos':pos,'RQ':rq,'Seq':seq}
                    while zdb.makeKey(zentry) in zdb.dict['Data']: zentry['RN'] += 1; rn += 1
                    zdb.addEntry(zentry)
                self.printLog('\r#SUB','Processed %s subreads (-> %d SMRT cells)' % (rje.iStr(stot),len(cells)))
                if norqx: self.warnLog('No RQ values read for %s of %s reads: used 1-ErrPerBase (%f)' % (rje.iStr(norqx),rje.iStr(rn),1.0 - self.getNum('ErrPerBase')))
            zdb.dataFormat({'RN':'int','Len':'int','RQ':'float','ZMW':'int'})
            zdb.saveToFile()
            zdb.index('RN')
            for smrt in cells:
                self.printLog('#~~#','# ~~~~~~~~~~~ SEQUENCE SUMMARY FOR %s ~~~~~~~~~~~ #' % smrt)
                self.printLog('#SMRT','SMRT %d = %s' % (cells.index(smrt),smrt))
                seqdata = self.summariseSeqLen(zdb.indexDataList('SMRT',cells.index(smrt),'Len',sortunique=False))
                seqdata['SMRT'] = smrt
                sdb.addEntry(seqdata)
                cdb.addEntry({'SMRT':cells.index(smrt),'Name':smrt})
            cdb.saveToFile()

            basename = self.baseFile()
            self.printLog('#~~#','# ~~~~~~~~~~~~~~~~~~~~~~~ COMBINED PACBIO SUBREAD SUMMARY FOR %s ~~~~~~~~~~~~~~~~~~~~~~~~~~~ #' % basename)
            seqlen = zdb.dataList(zdb.entries(),'Len',sortunique=False)
            seqdata = self.summariseSeqLen(seqlen)
            sdb.addEntry(seqdata)
            ### >>> Rest as summarise() >>>

            # Make a ZMW unique table by collapsing on ZMW and keeping max length or quality where tied
            self.printLog('#~~#','# ~~~~~~~~~~~ PACBIO Unique ZMW subreads (%s) ~~~~~~~~~~~ #' % basename)
            udb = db.copyTable(zdb,'unique')
            #udb.dropField('Pos')
            udb.compress(['SMRT','ZMW'],default='max',best=['Len','RQ','RN'])
            udb.saveToFile()
            #udb.indexReport('RN','Best ZMW reads from pass (RN)')
            udb.index('RN')
            zrn = rje.sortKeys(zdb.index('RN')); rmax = max(zrn)
            for rn in zrn:
                zn = rje.iLen(zdb.index('RN')[rn])
                ptxt = 'Read %d longest in ' % rn
                if rn in udb.index('RN'):
                    un = rje.iLen(udb.index('RN')[rn])
                    if rn < rmax: px = len(zdb.index('RN')[rn+1])
                    else: px = 0
                    ptxt += '%s of %s ZMW; %s ZMW with %d+ passes.' % (un,zn,rje.iStr(px),rn+1)
                else: ptxt += '0 ZMW.'; continue
                self.printLog('#RN',ptxt)
                #if rn in udb.index('RN'): self.printLog('#RN','Read %d longest in %s of %s ZMW with %d+ passes.' % (rn,rje.iLen(udb.index('RN')[rn]),rje.iLen(zdb.index('RN')[rn]),rn))
                #else: self.printLog('#RN','Read %d longest in 0 of %s ZMW with %d+ passes.' % (rn,rje.iLen(zdb.index('RN')[rn]),rn))
            bestseq = udb.dataList(udb.entries(),'Seq',sortunique=False,empties=False)
            self.printLog('#~~#','# ~~~~~~~~~~~ SEQUENCE SUMMARY FOR %s UNIQUE ~~~~~~~~~~~ #' % basename)
            seqlen = udb.dataList(udb.entries(),'Len',sortunique=False)
            seqdata = self.summariseSeqLen(seqlen)
            seqdata['SMRT'] = '%s.unique' % basename
            sdb.addEntry(seqdata)
            for smrt in cells:
                self.printLog('#~~#','# ~~~~~~~~~~~ SEQUENCE SUMMARY FOR %s.unique ~~~~~~~~~~~ #' % smrt)
                seqdata = self.summariseSeqLen(udb.indexDataList('SMRT',cells.index(smrt),'Len',sortunique=False))
                seqdata['SMRT'] = '%s.unique' % smrt
                sdb.addEntry(seqdata)
            sdb.saveToFile()

            # Output number and percentage of subreads and longest reads at each rq. Fields: rq, subreads, bestreads
            self.printLog('#~~#','# ~~~~~~~~~~~ PACBIO ZMW subread RQ (%s) ~~~~~~~~~~~ #' % basename)
            if self.getNum('TargetErr') <= 0:
                self.setNum({'TargetErr':1.0/self.getNum('GenomeSize')})
                self.printLog('#RQERR','Set target RQ error per base to 1/genome size = %s' % rje.expectString(self.getNum('TargetErr')))
            # Report on read quality and optionally filter?
            rqz = {}; rqzlen = {}
            sumrq = 0   # Sum of RQ * subreads
            for rq in zdb.index('RQ'):
                rqz[rq] = len(zdb.index('RQ')[rq])
                rqzlen[rq] = sum(zdb.indexDataList('RQ',rq,'Len',sortunique=False))
                sumrq += (rq * rqzlen[rq])
            rqzlentot = sum(rqzlen.values())
            self.printLog('#TOTAL','Total length = %.2fMb' % (rqzlentot/1e6))
            maxx = float(rqzlentot) / self.getNum('GenomeSize')
            self.printLog('#MAXX','Max. XCoverage = %.1f' % maxx)
            rqzfreq = rje.dictFreq(rqz,total=False,newdict=True)

            rqu = {}; rqulen = {}
            for rq in udb.index('RQ'):
                rqu[rq] = len(udb.index('RQ')[rq])
                rqulen[rq] = sum(udb.indexDataList('RQ',rq,'Len',sortunique=False))
            rqulentot = sum(rqulen.values())
            rqufreq = rje.dictFreq(rqu,total=False,newdict=True)

            qdb = db.addEmptyTable('rq',['RQ','xerr','subreads','unique','f.subreads','f.unique','cum.subreads','cum.unique','x.subreads','x.unique','MeanRQ','Mean.XErr'],['RQ'])
            for rq in rje.sortKeys(rqz):
                meanrq = sumrq / rqzlentot
                self.progLog('\r#RQ','Processing RQ=%s (Mean=%.3f) ' % (rq,meanrq))
                if rq > 1: raise ValueError('RQ = %s' % rq)
                x = meanx = 0
                if rq > 0:
                    x = 1
                    while ((1-rq) ** x) > self.getNum('TargetErr'): x += 1
                    meanx = 1
                    while ((1-meanrq) ** meanx) > self.getNum('TargetErr'): meanx += 1
                else: self.warnLog('%s subreads have RQ=0!' % rqz[rq])
                rentry = {'RQ':rq,'xerr':x,'subreads':rqz[rq],'unique':0,'f.subreads':rqzfreq[rq],'f.unique':0,
                          'cum.subreads':rqzlentot,'x.subreads':rqzlentot/self.getNum('GenomeSize'),
                          'MeanRQ':meanrq,'Mean.XErr':meanx}
                rqzlentot -= rqzlen[rq]
                sumrq -= (rq * rqzlen[rq])
                if rq in rqu:
                    rentry['unique'] = rqu[rq]; rentry['f.unique'] = rqufreq[rq]
                    rentry['cum.unique'] = rqulentot; rentry['x.unique'] = rqulentot/self.getNum('GenomeSize')
                    rqulentot -= rqulen[rq]
                #self.printLog('#RQ','RQ=%s: %s (%.2f%%) subreads; %s (%.2f%%) unique.' % (rq,rqz[rq],100.0*rqzfreq[rq],rentry['unique'],100.0*rentry['f.unique']))
                qdb.addEntry(rentry)
            self.printLog('\r#RQ','Processing of RQ<=%s complete.' % rq)
            qdb.saveToFile()

            #i# Old notes and contour data now in self.contours(). Replaced by calculate()?
            return True
        except: self.errorLog('%s.summarise error' % self.prog()); return False
#########################################################################################################################
    def summariseSeqLen(self,seqlen):   ### Generate summary data from list of sequence lengths
        '''
        Generate summary data from list of sequence lengths.
        @param seqlen: list of sequence lists
        @return: dictionary of summary data
        '''
        try:### ~ [0] Setup SeqList and basic stats ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            seqlen.sort()
            seqnum = len(seqlen)
            sumlen = sum(seqlen)
            seqdata = {'SMRT':'Total','SeqNum':seqnum,'TotLength':sumlen,
                     'MinLength':min(seqlen),'MaxLength':max(seqlen)}
            seqdata['MeanLength'] = seqdata['TotLength']/float(seqdata['SeqNum'])
            self.printLog('#SUM','Total number of sequences: %s' % rje.iLen(seqlen))
            self.printLog('#SUM','Total length of sequences: %s' % rje.iStr(sumlen))
            self.printLog('#SUM','Min. length of sequences: %s' % rje.iStr(seqlen[0]))
            self.printLog('#SUM','Max. length of sequences: %s' % rje.iStr(seqlen[-1]))
            # Mean & Median sequence lengths
            meanlen = float(sumlen)/len(seqlen)
            meansplit = rje.split('%.2f' % meanlen,'.')
            self.printLog('#SUM','Mean length of sequences: %s.%s' % (rje.iStr(meansplit[0]),meansplit[1]))
            if rje.isOdd(len(seqlen)): median = seqlen[len(seqlen)/2]
            else: median = sum(seqlen[len(seqlen)/2:][:2]) / 2.0
            self.printLog('#SUM','Median length of sequences: %s' % (rje.iStr(median)))
            seqdata['MedLength'] = median
            ## N50 calculation
            n50len = seqdata['TotLength'] / 2.0
            n50 = seqlen[0:]
            while n50len > 0 and n50: n50len -= n50.pop(-1)
            if n50:
                self.printLog('#SUM','N50 length of sequences: %s' % rje.iStr(n50[-1]))
                seqdata['N50Length'] = n50[-1]
            else:
                self.printLog('#SUM','N50 length of sequences: %s' % rje.iStr(seqlen[-1]))
                seqdata['N50Length'] = seqlen[-1]
            seqdata['XCoverage'] = seqdata['TotLength'] / self.getNum('GenomeSize')
            return seqdata
        except: self.errorLog('%s.summariseSeqLen error' % self.prog())
#########################################################################################################################
    def zdb(self,add=True):  ### Returns ZMW Table
        '''
        Returns ZMW Table.
        ['SMRT','ZMW','RN','Len','Pos','RQ','Seq'],['SMRT','ZMW','RN']
        '''
        zdb = self.db('zmw',add=False)
        if zdb: return zdb
        elif not add: return None
        zdb = self.db('zmw',add=not self.getBool('FullForce'),forcecheck=False,mainkeys=['SMRT','ZMW','RN'])
        if not zdb: # Try based on SeqIn
            self.db().baseFile(rje.baseFile(self.getStr('SeqIn')))
            zdb = self.db('zmw',add=not self.getBool('FullForce'),forcecheck=False,mainkeys=['SMRT','ZMW','RN'])
            self.db().baseFile(self.baseFile())
            if zdb: self.printLog('#ZMW','Could not find %s.zmw.tdt: used %s.zmw.tdt.' % (self.basefile(),rje.baseFile(self.getStr('SeqIn'))))
        self.debug(zdb)
        if not zdb:
            if not self.summarise(): raise ValueError('Summarise Failure')
            zdb = self.db('zmw')
        if not zdb: raise IOError('Cannot find *.zmw.tdt table!')
        if not zdb.formatted(): zdb.dataFormat({'RN':'int','Len':'int','RQ':'float','Seq':'int','ZMW':'int'})
        zdb.index('RN')
        return zdb
#########################################################################################################################
    def udb(self,minrq=0.0,force=False,add=True):  ### Returns Unique ZMW Table
        '''
        Returns Unique ZMW Table.
        >> minrq:float [0] = Min. RQ cutoff to apply prior unique read generation.
        >> force:bool [False] = Whether to force regeneration from ZMW table.
        >> add:bool [True] = Whether to add if missing.
        ['SMRT','RN','Len','Pos','RQ','Seq'],['SMRT','ZMW']
        '''
        udb = self.db('unique',add=False)
        if force and udb: self.db().deleteTable(udb); udb = None
        elif not add and not udb: return None
        elif not udb: udb = self.db('unique',add=not self.getBool('FullForce'),forcecheck=False,mainkeys=['SMRT','ZMW'])
        if not udb:     # Generate based on SeqIn ZMW table
            udb = self.db().copyTable(self.zdb(),'unique')
            udb.dataFormat({'SMRT':'int','ZMW':'int','Len':'int','RQ':'float','Seq':'int'})
            if minrq and min(udb.indexKeys('RQ')) < minrq: udb.dropEntries(['RQ<%f' % minrq])
            udb.compress(['SMRT','ZMW'],default='max',best=['Len','RQ','RN'])
            udb.index('RN')
        else:
            if not udb.formatted(): udb.dataFormat({'SMRT':'int','Len':'int','RQ':'float','Seq':'int','ZMW':'int'})
            if minrq and min(udb.indexKeys('RQ')) < minrq: udb.dropEntries(['RQ<%f' % minrq])
        return udb
#########################################################################################################################
    def rqdb(self):  ### Returns RQ Table from summarise
        '''
        Returns RQ Table from summarise.
        ['RQ','xerr','subreads','unique','f.subreads','f.unique','cum.subreads','cum.unique','x.subreads','x.unique','MeanRQ','Mean.XErr'],['RQ']
        '''
        rqdb = self.db('rq',add=False)
        if rqdb: return rqdb
        rqdb = self.db('rq',add=True,mainkeys=['RQ'])
        if not rqdb: # Try based on SeqIn
            self.db().baseFile(rje.baseFile(self.getStr('SeqIn')))
            rqdb = self.db('rq',add=True,mainkeys=['RQ'])
            self.db().baseFile(self.baseFile())
            if rqdb: self.printLog('#RQ','Could not find %s.rq.tdt: used %s.rq.tdt.' % (self.basefile(),rje.baseFile(self.getStr('SeqIn'))))
        if not rqdb:
            if not self.summarise(): raise ValueError('Summarise Failed.')
            rqdb = self.db('rq')
        if not rqdb: raise IOError('Cannot find *.rq.tdt table!')
        if not rqdb.formatted(): rqdb.dataFormat({'RQ':'int'}) # add formatting as required
        return rqdb
#########################################################################################################################
    ### <5> ### PacBio Coverage Cutoff Calculation Methods                                                              #
#########################################################################################################################
    def calculate(self):    ### Calculate cutoffs from subread summary data.
        '''
        Calculate cutoffs from subread summary data.
        '''
        try:### ~ [0] Setup Objects for calculations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            efficiency = self.getNum('MapEfficiency')   # Efficiency of mapping anchor reads to seed reads
            db = self.db()                              # Database object
            udb = self.udb()                            # Data table of Unique reads.
            self.printLog('#~~#','# ~~~~~~~~~~~~~~~~~~~~ CALCULATING SUBREAD CUTOFFS ~~~~~~~~~~~~~~~~~~~~~~~ #')
            targetaccuracy = 1.0 - self.getNum('TargetErr')     # Desired accuracy of basecalls following seed correction
            #i# NOTE: In V2.x, raw ZMW data is NOT used for any serious calculations - it is not used by FALCON.
            calcx = self.list['CalcX']
            for sumx in calcx:
                sumlen = sumx * self.getNum('GenomeSize')
                self.printLog('#CALCX','Adding calcx=%dX = %s bp.' % (sumx,sumlen))
            calclen = rje.sortUnique(self.list['CalcLen'])
            for clen in calclen:
                self.printLog('#CALCL','Adding calclen = %s bp.' % (clen))
            #X# Do not need to add MinReadLen - automatically added
            #X# if self.getInt('MinReadLen') not in calclen: calclen.append(self.getInt('MinReadLen'))

            #i# MapEfficiency is used to adjust the amount of seed read data that actually gets error-corrected by any
            #i# given anchor read. It does NOT inflate the target amount of seed read data. (XMargin=X does this.)
            #i# This is less than 100% because the basic calculation is assuming that 100% of the anchor reads will be
            #i# mapping onto seed reads. In reality, the two reads may only be partially overlapping, thus less than 100%
            #i# of the seed reads with expected anchor coverage will actually end up in the the preassembly.

            #i# NOTE: There is then a second level of uncertainty associated with the preassembly that is of relevance
            #i# for FALCON assembly: how the seed reads get fragmented and thus how much will be lost by the second
            #i# FALCON read length cutoff. One possible course of action here is to run SMRTSCAPE a second time on the
            #i# preassembled reads, this time with a map efficiency of 1.0. This can be combined with an empirical
            #i# assessment of the original preassembly and (optional) fragmentation reduction.

            ### ~ [0a] Filter data and prepare coverage calculations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            udb.dropEntries(['Len<%d' % self.getInt('MinReadLen')],logtxt='Min. read length filter')
            #i# Set up list of required Xdepth to get total coverage at desired Xdepth
            xcovlimits = self.targetXDepth(purelen=True,sqroot=True)
            ### ~ [0b] Set up list of Read Quality (RQ) cutoffs for assessment ~~~~~~~~~~~~~~~~~~~~ ##
            rqcutoffs = self.list['RQCutoffs'] = []
            self.printLog('#MINRQ','Min. RQ=%.3f' % self.getNum('MinRQ'))
            if self.getNum('MaxRQ') < self.getNum('MinRQ'): self.setNum({'MaxRQ':self.getNum('MinRQ')})
            self.printLog('#MAXRQ','Max. RQ=%.3f' % self.getNum('MaxRQ'))
            rqstep = max(0.001,self.getNum('RQStep'))
            rq = self.getNum('MinRQ')
            rqcutoffs = [rq]
            while rq <= self.getNum('MaxRQ'):
                rqcut = rje.dp(rq,3)    # Reduce to 3dp
                if rqcut not in udb.indexKeys('RQ'):
                    self.warnLog('Failed to find RQ=%s in ZMW file.' % rqcut)
                if rqcut not in rqcutoffs: rqcutoffs.append(rqcut)
                rq += rqstep

            #!# For each `RQ` cutoff, `TargetErr` is used to establish the min. required anchor read Xdepth (`AnchorMinX`).
            # If this exceeds the specified `minanchorx=X` value, this will be used as the minimum target instead.
            # Next, the seed read length (`SeedLen`) required to get a combined unique seed read length to give a minimum
            # Xdepth (`SeedMinX`) of `targetxcov=X` is calculated. Where `xmargin` > 0, additional seed lengths will also
            # be calculated to give deeper minimum seed Xdepths. *e.g.* `targetxcov=3 xmargin=2` will calculate `SeedLen`
            # for `3X`, `4X` and `5X`. For each `SeedLen`, anchor read length cutoffs are also calculated such that the
            # summed length of unique reads where is sufficent to give `AnchorMinX` values from the minimum established
            # above until `XMargin` is reached.

            #!# If there is insufficient data to meet the minimum seed and anchor read depths, the "optimal" seed
            # XCoverage will be calculated from the unique seed reads, as described for `coverage=T`. In essence,
            # `SeedMinX` will be reduced to meet `AnchorMinX` until it falls below zero and then the two values will be
            # optimised to try and maximise genome coverage at the required target error. Users may prefer instead to
            # relax the `targetxcov=X` and/or `minanchorx=X` values. This optimisation is based on unique Xcoverage and
            # the precise values subsequently output in `*.cutoffs.tdt` may differ. (Relaxed variations could be run with
            # higher `xmargin=X` values to output a range from which the chosen values can be selected for `predict=T`.)

            #!# **NOTE:** `mapefficiency=X` is used during this process to reduce the effective seed coverage at a given
            # summed length and thus inflate the required `SeedX` needed to achieve a given `SeedMinX`.

            #!# Version 2.x simplified this method to ONLY use unique reads and generate both seed and anchor read length
            #!# lists at the same time as the reuse the same data. This is to avoid chimeric reads contributing multiple
            #!# reads and thus looking more real.

            ### ~ [1] Calculate unique X and coverage for given seed, anchor + RQ combination ~~~~~~~~~~~~~~~~~~~~~~~ ###
            pdb = db.addEmptyTable('cutoffs',['RQ','CutLen','CutX','CutMinX','MinAcc','MapLen','MapX'],['RQ','CutLen'])
            #> RQ = Read Quality Cutoff
            #> CutLen = Read length Cutoff
            #> CutX = Total XDepth of coverage for this RQ-CutLen combination
            #> CutMinX = Min XCoverage depth for TargetCov % of genome (unique reads)
            #> CutAcc = Predicted accuracy at minimum X depth
            #> MapLen = Read Length Cutoff adjusting for MapEfficiency
            #> MapX = Total XDepth of coverage for this RQ-CutLen combination, adjusting for MapEfficiency

            # Needs xcovlimits, rqcutoffs, and udb from above
            usorted = udb.sortedEntries('Len',reverse=True)    # List of all entries, sorted by length
            for rq in rqcutoffs:
                # RQ and TargetError XCoverage
                if rq > 1: raise ValueError('RQ = %s' % rq)
                #i# x is the depth of coverage needed to hit the desired TargetErr. This now uses the accuracy
                #i# calculation estimation of dominant basecalls, modified for the minimum RQ value.
                x = 1
                while self.accuracy(x,rq) < targetaccuracy: x += 1
                #i# anchx is the minimum depth of sequence required for error correction. It is enough for each base to
                #i# be covered by a seed read plus the required anchor read depth.
                anchx = x
                self.printLog('#XERR','Need %dX per base for %s per base error rate @RQ=%s' % (anchx,rje.expectString(self.getNum('TargetErr')),rq))
                #i# targetx is the desired min depth of sequence, accounting for chosen MinAnchorX
                targetx = max(x,self.getInt('MinAnchorX')+1)
                self.printLog('#MINX','Set target min %dX per base for %s per base error rate @RQ=%s (minanchorx=%d)' % (targetx,rje.expectString(self.getNum('TargetErr')),rq,self.getInt('MinAnchorX')))
                rqentry = False     # Whether anything has been output at this RQ

                #i# The target Xdepths based on TargetXCov and XMargin are first put into a list of target minX
                minxlist = range(self.getInt('TargetXCov'),self.getInt('TargetXCov')+self.getInt('XMargin')+1)
                minxlist += range(min(anchx,self.getInt('MinAnchorX')+1),targetx+self.getInt('XMargin')+1)
                minxlist = rje.sortUnique(minxlist)
                self.printLog('#MINX','Calculating read lengths for %d MinX depths: %s' % (len(minxlist),rje.replace('%s' % minxlist,"'","")))

                #i# Next, the minX list is convert to a of (summed) TargetX coverage to achieve for MinX coverage
                sumxlist = []
                for minx in minxlist:
                    if minx >= len(xcovlimits):
                        self.printLog('#MIX','Cannot achieve min %X coverage at @RQ=%s' % (minx,rq))
                        break
                    sumlen = xcovlimits[minx]
                    if sumlen not in sumxlist: sumxlist.append(sumlen)
                if self.dev(): self.printLog('#SUMLEN','%d target summed read lengths for %d MinX depths: %s' % (len(sumxlist),len(minxlist),rje.replace('%s' % sumxlist,"'","")))
                for sumx in calcx:
                    sumlen = sumx * self.getNum('GenomeSize')
                    if sumlen not in sumxlist:
                        sumxlist.append(sumlen)
                sumxlist.sort()
                #!# Add rje.numListToStr(numlist,integers=False,dp=-1,sf=-1)
                #!# Is there a method for printing sequence lengths in decent units?

                #i# Next, convert this into read length cutoffs, add calclen and recalculate X and MinX for output
                #i# NOTE: V2.x no longer separates seed reads from anchor reads. (FALCON doesn't)!
                rqusum = 0      # Sum of all unique reads
                mapsum = 0
                uentries = usorted[0:]
                mentries = usorted[0:]
                #i# Will also need to check for user-added length-cutoffs to output
                lencuts = calclen[0:]
                lencuts.reverse()
                while uentries: # First establish unique seed read coverage
                    lenbreak = False
                    self.progLog('\r#SEED','Establishing seed/anchor lengths/coverage @RQ=%s...' % (rq))
                    pentry = {'RQ':rq}
                    # First, calculate assuming 100% efficiency
                    while uentries: # Need more sequence
                        # Check for length cutoff
                        if lencuts and uentries[0]['Len'] < lencuts[0]:
                            lenbreak = True
                            break
                        # Check for reaching next summed sequence target
                        if sumxlist and rqusum > sumxlist[0]: break
                        uentry = uentries.pop(0)
                        if uentry['RQ'] < rq: continue
                        rqusum += uentry['Len']
                    # Next, calculate adjusting for MapEfficiency
                    while mentries and not lenbreak: # Need more sequence
                        if sumxlist and mapsum > sumxlist[0]: break
                        uentry = mentries.pop(0)
                        if uentry['RQ'] < rq: continue
                        mapsum += (uentry['Len'] * efficiency)
                    # Check for being out of sequence, else set Length at next uentry/mentry size
                    if lenbreak:
                        pentry['CutLen'] = lencuts.pop(0)
                        pentry['MapLen'] = 0
                    else:
                        if uentries: pentry['CutLen'] = uentries[0]['Len']
                        else: pentry['CutLen'] = self.getInt('MinReadLen')
                        if sumxlist: sumxlist.pop(0)
                        if mentries: pentry['MapLen'] = mentries[0]['Len']
                        else: pentry['MapLen'] = self.getInt('MinReadLen')
                    # Calculate Xdepth values
                    pentry['CutX'] = rqusum/self.getNum('GenomeSize')
                    if lenbreak:
                        pentry['MapX'] = 0
                    else:
                        pentry['MapX'] = mapsum/self.getNum('GenomeSize')
                    for i in range(len(xcovlimits)):
                        if xcovlimits[i] <= rqusum: pentry['CutMinX'] = i
                        if xcovlimits[i] <= mapsum: pentry['MapMinX'] = i
                    pentry['MinAcc'] = self.accuracy(pentry['CutMinX'],rq)
                    rqentry = pdb.addEntry(pentry)
                if rqentry: continue   # Move along to next RQ

            self.printLog('\r#SEED','Established seed lengths and anchor lengths for different RQ.')
            pdb.saveToFile()

            ### ~ [2] Generate Table of Accuracy Estimations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            adb = db.addEmptyTable('accuracy',['RQ','X','Accuracy','ErrPerBase'],['RQ','X'])
            #> RQ = Read Quality Cutoff
            #> X = X depth
            #> Accuracy = Calculated Accuracy for RQ-X combination
            #> ErrPerBase = 1.0 - Accuracy
            for rq in rje.sortKeys(self.dict['Accuracy']):
                for x in range(len(self.dict['Accuracy'][rq]))[1:]:
                    adb.addEntry({'RQ':rq,'X':x,'Accuracy':self.dict['Accuracy'][rq][x],'ErrPerBase':1.0-self.dict['Accuracy'][rq][x]})
            adb.saveToFile()
        except: self.errorLog('%s.calculate error' % self.prog())
#########################################################################################################################
    ### <6> ### PacBio Parameter Optimisation Methods                                                                   #
#########################################################################################################################
    def optimise(self):   ### Generate predicted optimum assembly settings from summary tables.
        '''Generate predicted optimum assembly settings from summary tables.'''
        try:### ~ [0] Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            targetaccuracy = 1.0 - self.getNum('TargetErr')     # Desired accuracy of basecalls following seed correction
            ## ~ [0a] Load data ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            cdb = self.db(table='cutoffs',add=True,forcecheck=True,mainkeys=['RQ','CutLen'])
            if not cdb:
                self.calculate()
                cdb = self.db(table='cutoffs',add=True,forcecheck=False,mainkeys=['RQ','CutLen'])
                if not cdb: raise IOError('Unable to find/create "cutoffs" table!')
            self.printLog('#~~#','# ~~~~~~~~~~~~~~~~~~~~ OPTIMISING ASSEMBLY PARAMETERS ~~~~~~~~~~~~~~~~~~~~ #')
            if not cdb.formatted():
                cdb.dataFormat({'RQ':'num','CutLen':'int','CutX':'num','CutMinX':'int','MinAcc':'num','MapLen':'int','MapX':'num'})
            if not cdb.entries(): self.warnLog('No *.cutoffs.tdt data! Too stringent for data quantity?'); return False

            self.infoLog('Parameter optimisation: uses CutLen for seed length cutoff; MapLen for anchor length cutoff')
            ## ~ [0b] Establish targets ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            #i# Use targetxcov=X and xmargin=X to establish the required data combinations for seed reads
            targetxcov = self.getInt('TargetXCov')      # Target 100% X Coverage for pre-assembly
            xmargin = self.getInt('XMargin')            # "Safety margin" inflation of X coverage
            seedrq = {}     # Dictionary or {RQ:CutLen meeting CutMinX target)
            for (rq,cutlen) in cdb.datakeys():
                if cdb.data((rq,cutlen))['MapLen'] <= self.getInt('MinReadLen'): continue
                if cdb.data((rq,cutlen))['CutMinX'] == (targetxcov+xmargin): seedrq[rq] = cutlen
            self.printLog('#SEEDRQ','%d RQ cutoffs meet targetxcov=%d xmargin=%d.' % (len(seedrq),targetxcov,xmargin))
            if not seedrq: self.warnLog('No *.cutoffs.tdt data meets targetxcov=%d xmargin=%d! Too stringent for data quantity?' % (targetxcov,xmargin)); return False
            #i# Use targetaccuracy to establish the required data combinations for anchor reads
            #i# Assumes datakeys (rq,cutlen) are sorting properly
            anchrq = {}     # Dictionary or {RQ:Lowest CutLen meeting targetaccuracy)
            for (rq,cutlen) in cdb.datakeys():
                if cdb.data((rq,cutlen))['MapLen'] <= self.getInt('MinReadLen'): continue
                if cdb.data((rq,cutlen))['MinAcc'] >=  targetaccuracy: anchrq[rq] = cutlen
            self.printLog('#ANCHRQ','%d RQ cutoff meet TargetErr accuracy.' % len(anchrq))
            if not anchrq: self.warnLog('No *.cutoffs.tdt data meets TargetErr setting! Too stringent for data quantity?'); return False

            ### ~ [1] Identify MaxLen (min RQ) and MaxRQ settings that meet the criteria ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            optrq = rje.listIntersect(seedrq.keys(),anchrq.keys())
            self.printLog('#OPTRQ','%d potential optimal RQ cutoffs.' % len(optrq))
            if not optrq: self.warnLog('No *.cutoffs.tdt data meets combined targets! Too stringent for data quantity?'); return False
            optrq.sort()
            ## ~ [1a] Maximise Read Length ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            self.printLog('#~~#','# ~~~~~~~~~~ Maximise read lengths ~~~~~~~~~~~~~~ ##')
            rq = optrq[0]
            entry = cdb.data((rq,anchrq[rq]))
            self.printLog('#PARAM','Recommended RQ cutoff = %s' % rq)
            self.printLog('#PARAM','Recommended min. subread length (Min %dX) = %s bp; %.1fX total.' % (entry['CutMinX'],rje.iStr(entry['MapLen']),entry['CutX']))
            entry = cdb.data((rq,seedrq[rq]))
            self.printLog('#PARAM','Recommended seed length (Min %dX + %dX) = %s bp; %.1fX total.' % (targetxcov,xmargin,rje.iStr(entry['CutLen']),entry['CutX']))
            ## ~ [1b] Maximise Read Quality ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            self.printLog('#~~#','# ~~~~~~~~~~ Maximise read quality ~~~~~~~~~~~~~~ ##')
            rq = optrq[-1]
            entry = cdb.data((rq,anchrq[rq]))
            self.printLog('#PARAM','Recommended RQ cutoff = %s' % rq)
            self.printLog('#PARAM','Recommended min. subread length (Min %dX) = %s bp; %.1fX total.' % (entry['CutMinX'],rje.iStr(entry['MapLen']),entry['CutX']))
            entry = cdb.data((rq,seedrq[rq]))
            self.printLog('#PARAM','Recommended seed length (Min %dX + %dX) = %s bp; %.1fX total.' % (targetxcov,xmargin,rje.iStr(entry['CutLen']),entry['CutX']))
            ## ~ [1c] Output to table ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            odb = self.db().addEmptyTable('optimise',['RQ','SeedLen','SeedX','SeedMinX','MapLen','MapX','ReadLen','ReadX','ReadMinX'],['RQ'])
            for rq in optrq:
                entry = {'RQ':rq}
                aentry = cdb.data((rq,anchrq[rq]))
                entry['ReadLen'] = aentry['MapLen']
                entry['ReadX'] = rje.dp(aentry['CutX'],2)
                entry['ReadMinX'] = aentry['CutMinX']
                sentry = cdb.data((rq,seedrq[rq]))
                entry['SeedLen'] = sentry['CutLen']
                entry['SeedX'] = rje.dp(sentry['CutX'],2)
                entry['MapLen'] = sentry['MapLen']
                entry['MapX'] = rje.dp(sentry['MapX'],2)
                entry['SeedMinX'] = sentry['CutMinX']
                odb.addEntry(entry)
            odb.saveToFile()
            return True
        except: self.errorLog('%s.optimise error' % self.prog()); return False
#########################################################################################################################
    ### <7> ### Read Filtering Methods                                                                                  #
#########################################################################################################################
    def readFilter(self):  ### Filter subreads and outputs to fasta file.
        '''Filter subreads and outputs to fasta file.'''
        try:### ~ [0] Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            self.printLog('#~~#','# ~~~~~~~~~~~~~~~~~~~~ FILTERING UNIQUE SUBREADS ~~~~~~~~~~~~~~~~~~~~ #')
            udb = self.udb()
            cdb = self.db('smrt',add=True,mainkeys=['Name'])
            cdb.dataFormat({'SMRT':'int'})

            minlen = self.getInt('LenFilter')
            minrq = self.getNum('RQFilter')
            ## ~ [0a] Output Sequence Files ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            rqstr = '%s' % minrq
            filtfile = '%s.L%sRQ%s.fasta' % (self.baseFile(),minlen,rqstr[2:])
            ## ~ [0b] Input Sequence Files ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            seqbatch = []   # List of SeqList objects
            self.printLog('#BATCH','%s sequence files to process.' % rje.iLen(self.list['Batch']))
            for seqfile in self.list['Batch']:
                seqcmd = self.cmd_list + ['seqmode=file','autoload=T','summarise=F','seqin=%s' % seqfile,'autofilter=F','dna=T']
                seqbatch.append(rje_seqlist.SeqList(self.log,seqcmd))
            self.printLog('#BATCH','%s sequence files to summarise.' % rje.iLen(seqbatch))
            if not seqbatch: raise IOError('No batch input fasta files found! Set batch=FILELIST.')

            ### ~ [1] Filter and Save ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            ## ~ [1a] Filter Unique Sequences ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            zmwlist = []    # List of (smrt,zmw) meeting filtering criteria
            ux = 0.0; utot = udb.entryNum()
            for entry in udb.entries():
                self.progLog('\r#FILT','Filtering unique subreads: %.2f%%' % (ux/utot)); ux += 100.0
                if entry['Len'] < minlen: continue
                if entry['RQ'] < minrq: continue
                zmwlist.append((entry['SMRT'],entry['ZMW'],entry['Pos']))
            self.printLog('\r#FILT','Filtering unique subreads complete: %s of %s retained.' % (rje.iLen(zmwlist),rje.iStr(utot)))

            ## ~ [1b] Extract Filtered Sequences ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            rje.backup(self,filtfile)
            SEQOUT = open(filtfile,'w')
            sx = 0.0; stot = 0; sn = len(seqbatch); fx = 0
            for seqlist in seqbatch:
                #>m150625_001530_42272_c100792502550000001823157609091582_s1_p0/9/0_3967 RQ=0.784
                si = 100.0/seqlist.seqNum(); stot += seqlist.seqNum()
                for seq in seqlist.seqs():
                    self.progLog('\r#OUT','Extracting subreads: %.2f%%' % (sx/sn)); sx += si
                    (name,sequence) = seqlist.getSeq(seq)
                    [smrt,zmw,pos,rq] = rje.split(rje.replace(name,'/',' '))
                    if (cdb.data(smrt)['SMRT'],int(zmw),pos) not in zmwlist: continue
                    SEQOUT.write('>%s\n%s\n' % (name,sequence)); fx += 1
            self.printLog('\r#OUT','Saved %s filtered subreads to %s.' % (rje.iStr(fx),filtfile))

            ### ~ [2] Summarise Filtered File ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            seqcmd = self.cmd_list + ['seqmode=file','autoload=T','summarise=T','seqin=%s' % filtfile,'autofilter=F']
            rje_seqlist.SeqList(self.log,seqcmd)

            return True
        except: self.errorLog('%s.readFilter error' % self.prog()); return False
#########################################################################################################################
    def ftXCoverage(self):     ### Generate estimated complete coverage of feature of a given length
        '''
        Generate estimated complete coverage of features of a given length, e.g. the number of times a full-length
        feature is expected to be sequenced.
        '''
        try:### ~ [0] Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            self.printLog('#~~#','# ~~~~~~~~~~~~~~~~~~~~~~~ PACBIO FEATURE DEPTH ANALYSIS ~~~~~~~~~~~~~~~~~~~~~~~~~~~ #')
            ftxcov = self.list['FTXCov']   # Read list of feature lengths from self.list['FTXCov']
            ftxcov.sort()
            ftxfreq = self.list['FTXFreq'] # List of feature frequencies for which to calculate probability of detection
            ftxfreq.sort()
            db = self.db()
            udb = None
            if not self.getStrLC('SeqIn') or self.getBool('Summarise') or self.getBool('Optimise') or self.getBool('Calculate'): udb = self.udb()
            elif self.getStrLC('SeqIn'): self.printLog('#SEQIN','Using seqin=%s for feature X coverage analysis.' % self.getStr('SeqIn'))
            ## ~ [0a] Setup output ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            ftxfields = ['FTLen','N','MeanX','MinX']
            for freq in ftxfreq: ftxfields.append('p%s' % freq)
            fdb = db.addEmptyTable('ftxcov',ftxfields,['FTLen'])

            ### ~ [1] Perform coverage calculations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            ftxdic = {}
            for flen in ftxcov: ftxdic[flen] = [0,0]    # Number and combined length of relevant reads
            ## ~ [1a] Unique subread calculations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            if udb:
                ux = 0.0; utot = udb.entryNum()
                for uentry in udb.entries():
                    self.progLog('\r#FTXCOV','Assessing unique reads for feature X coverage: %.2f%%' % (ux/utot)); ux += 100
                    ulen = uentry['Len']
                    for flen in ftxcov:
                        if ulen <= flen: break
                        ftxdic[flen][0] += 1
                        ftxdic[flen][1] += (ulen-flen)
                self.printLog('\r#FTXCOV','Assessing unique reads for feature X coverage complete.')
            ## ~ [1b] Processed read calculations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            else:
                seqlist = rje_seqlist.SeqList(self.log,self.cmd_list+['seqmode=file','autoload=T','summarise=F','seqin=%s' % self.getStr('SeqIn'),'dna=T'])   # This will summarise read lengths etc.
                ux = 0.0; utot = seqlist.seqNum()
                for seq in seqlist.seqs():
                    self.progLog('\r#FTXCOV','Assessing seqin reads for feature X coverage: %.2f%%' % (ux/utot)); ux += 100
                    ulen = seqlist.seqLen(seq)
                    for flen in ftxcov:
                        if ulen <= flen: break
                        ftxdic[flen][0] += 1
                        ftxdic[flen][1] += (ulen-flen)
                self.printLog('\r#FTXCOV','Assessing unique seqin for feature X coverage complete.')
            ## ~ [1c] Convert to coverage ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            for flen in ftxcov:
                fentry = {'FTLen':flen,'N':ftxdic[flen][0],'MeanX':rje.dp(ftxdic[flen][1]/self.getNum('GenomeSize'),2)}
                fentry['MinX'] = 0
                while rje.poisson(fentry['MinX'],fentry['MeanX'],exact=False,callobj=self) >= self.getPerc('TargetCov'):
                    fentry['MinX'] += 1
                #i# The probability of observing 1+ occurrences of a given feature with a population frequency of F
                #i# is the poisson probability of observing 1+ given the expectation of F x the Mean depth
                for freq in ftxfreq:
                    fentry['p%s' % freq] = rje.sf(rje.poisson(1,freq*fentry['MeanX'],exact=False,callobj=self),4)
                fdb.addEntry(fentry)
            fdb.saveToFile()
            return True
        except: self.errorLog('%s.ftXCoverage error' % self.prog()); return False
#########################################################################################################################
#!# NOTE: The reduced sequence output can use the Seq field on udb to fish out seqlist entries (loaded with index!)
#!# But there is no direct link to the input file!!
#!# Edit below...
#########################################################################################################################
    ### <9> ### PacBio Preassembly Methods                                                                              #
#########################################################################################################################
    def preassemblyFrag(self):  ### Assesses and tries to correct the preassembly fragmentation issue.
        '''Assesses and tries to correct the preassembly fragmentation issue.'''
        try:### ~ [0] Setup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            self.printLog('#~~#','# ~~~~~~~~~~~~~~~~~~~~~~~ PACBIO PREASSEMBLY FRAGMENTATION ANALYSIS ~~~~~~~~~~~~~~~~~~~~~~~~~~~ #')
            db = self.db()
            if not rje.exists(self.getStr('Preassembly')): raise IOError('Preassembly file "%s" not found!' % self.getStr('Preassembly'))
            seqlist = rje_seqlist.SeqList(self.log,self.cmd_list+['seqmode=file','autoload=T','summarise=F','seqin=%s' % self.getStr('Preassembly'),'dna=T'])   # This will summarise read lengths etc.
            basename = rje.baseFile(self.getStr('Preassembly'),strip_path=True)
            #i# NOTE: If basefile.fragment.tdt exists, it will be loaded. This enables multiple preassembly analyses to
            #i# be compiled in the same table.
            fdb = self.db('fragment',add=not self.force(),mainkeys=['Assembly','Stage'])
            if fdb and basename in fdb.index('Assembly'):
                self.warnLog('Existing %s *.fragment.tdt entries will be overwritten. (Make sure preassembly files have unique names.)' % basename)
                if self.i() > -1 and not rje.yesNo('Proceed?'):
                    self.printLog('#CANCEL','Preassembly analysis cancelled.'); return False
                fdb.dropIndexEntries('Assembly',basename)
            if not fdb: fdb = db.addEmptyTable('fragment',['Assembly','Stage','SeqNum','TotLength','MinLength','MaxLength','MeanLength','MedLength','N50Length','XCoverage','AdjN'],['Assembly','Stage'])
            fraglen = []    # List of fragmented preassembly read lengths
            fixlen = []     # List of fixed preassembly read lengths
            ### ~ [1] Calculate ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            seqdata = seqlist.summarise()
            seqdata['Assembly'] = basename; seqdata['Stage'] = 'preassembly'
            seqdata['XCoverage'] = seqdata['TotLength'] / self.getNum('GenomeSize')
            seqdata['AdjN'] = 0
            ##~ ~ [2] Adjacent fragment analysis ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            #i# NOTE: the *.smrtscape.fasta output is named after the preassembly fasta file, not self.basefile()
            fixfas = '%s.smrtscape.fasta' % basename
            rje.backup(self,fixfas)
            FIXFAS = open(fixfas,'w'); fx = 0
            prevseq = [None,-1,-1,'']
            while seqlist.nextSeq():
                (name,sequence) = seqlist.getSeq()
                fraglen.append(len(sequence))
                (seed,i,j) = rje.matchExp('^(\S+)/(\d+)_(\d+)$',name)
                i = int(i); j = int(j)
                if seed == prevseq[0] and i == prevseq[2] + 1:  # 0bp fragmentation
                    prevseq[2] = j
                    prevseq[3] += sequence
                    seqdata['AdjN'] += 1
                else:
                    if prevseq[0]:
                        FIXFAS.write('>%s/%d_%d\n%s\n' % (prevseq[0],prevseq[1],prevseq[2],prevseq[3])); fx += 1
                        fixlen.append(len(prevseq[3]))
                    prevseq = [seed,i,j,sequence]
            if prevseq[0]:
                FIXFAS.write('>%s/%d_%d\n%s\n' % (prevseq[0],prevseq[1],prevseq[2],prevseq[3])); fx += 1
                fixlen.append(len(prevseq[3]))
            FIXFAS.close()
            self.printLog('#FAS','%s preassembly reads -> %s output to %s' % (rje.iStr(seqlist.seqNum()),rje.iStr(fx),fixfas))
            fdb.addEntry(seqdata)
            ### ~ [3] Calculate FixFas data ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            fixseq = rje_seqlist.SeqList(self.log,self.cmd_list+['seqmode=file','autoload=T','summarise=F','seqin=%s' % fixfas,'dna=T'])   # This will summarise read lengths etc.
            seqdata = fixseq.summarise()
            seqdata['Assembly'] = basename; seqdata['Stage'] = 'smrtscape'
            seqdata['XCoverage'] = seqdata['TotLength'] / self.getNum('GenomeSize')
            seqdata['AdjN'] = 0
            fdb.addEntry(seqdata)
            ## ~ [3a] Finish and save ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            fdb.saveToFile()

            ### ~ [4] Recalculate depth of coverage ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
            #!# This method needs testing
            ## ~ [4a] Sort lists of sequences ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            fraglen.sort(); fraglen.reverse()
            fragsum = sum(fraglen)
            fixlen.sort(); fixlen.reverse()
            fixsum = sum(fixlen)
            if fixsum != fragsum: self.warnLog('Total de-fragmented sequence length (%s bp) does not match total fragmented sequence lenght (%s bp)' % (rje.iStr(fixsum),rje.iStr(fragsum)))
            ## ~ [4b] Calculate targetXdepth ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ##
            xdb = db.addEmptyTable('fragx',['XCov','MinX','FragLen','FixLen'],['XCov'])
            sumxlist = []
            targetxcov = self.targetXDepth(purelen=True,sqroot=False,reset=True,maxlen=fragsum)
            for x in range(self.getInt('TargetXCov'),self.getInt('TargetXCov')+self.getInt('XMargin')+1):
                if self.v() > 0: self.printLog('#XCOV','Min %dX coverage needs %s bp.' % (x,rje.iStr(targetxcov[x])))
                sumxlist.append(int(targetxcov[x]))
            self.debug(sumxlist)

            #!# Save: XCov, MinX, FragLen, FixLen [XCov]

            #i# Convert calclen into summed read lengths
            calclen = []
            for clen in self.list['CalcLen'][0:]:
                if clen < fraglen[-1]: self.printLog('#CALCL','Skipping calclen = %s bp; Shorter than smallest corrected read = %s bp' % (rje.iStr(clen),rje.iStr(fraglen[-1])))
                else: self.printLog('#CALCL','Adding calclen = %s bp.' % (clen)); calclen.append(clen)
            calclen.reverse()
            self.debug(calclen)
            fragc = 0; fixc = 0
            while calclen:
                targlen = calclen.pop(0)
                while fragc < len(fraglen) and fraglen[fragc] > targlen: fragc += 1
                sumxlist.append(sum(fraglen[:fragc]))
                if self.v() > 0: self.printLog('#CALCL','%s bp Length cutoff => %s bp fragmented' % (rje.iStr(targlen),rje.iStr(sumxlist[-1])))
                while fixc < len(fixlen) and fixlen[fixc] > targlen: fixc += 1
                sumxlist.append(sum(fixlen[:fixc]))
                if self.v() > 0: self.printLog('#CALCL','%s bp Length cutoff => %s bp fixed' % (rje.iStr(targlen),rje.iStr(sumxlist[-1])))
            sumxlist.append(fragsum)
            for sumx in self.list['CalcX']:
                sumlen = sumx * self.getNum('GenomeSize')
                if sumlen > fragsum:
                    self.warnLog('Cannot add calcx=%dX = %s bp; insufficient sequence data.' % (sumx,rje.iStr(sumlen)))
                else:
                    sumxlist.append(sumlen)
                    self.printLog('#CALCX','Adding calcx=%dX = %s bp.' % (sumx,rje.iStr(sumlen)))
            self.debug(sumxlist)
            #X# Do not need to add MinReadLen - automatically added
            #X# if self.getInt('MinReadLen') not in calclen: calclen.append(self.getInt('MinReadLen'))

            sumxlist = rje.sortUnique(sumxlist)
            self.debug(sumxlist)

            #i# Convert sumxlist into Frag Lengths and Xdepth data
            fragtot = 0; fixtot = 0
            fragl = 0; fixl = 0
            while sumxlist:
                xsum = sumxlist.pop(0)
                if not xsum: continue
                while fraglen and fragtot < xsum: fragl = fraglen.pop(0); fragtot += fragl
                while fixlen and fixtot < xsum: fixl = fixlen.pop(0); fixtot += fixl
                if fixtot < xsum:
                    self.warnLog('Insufficient sequence data for target %s bp (%.1fX).' % (rje.iStr(xsum),xsum/self.getNum('GenomeSize')))
                    continue
                xentry = {'XCov':rje.dp(float(xsum)/self.getNum('GenomeSize'),2),'MinX':0,'FragLen':fragl,'FixLen':fixl}
                while targetxcov[xentry['MinX']+1] <= xsum: xentry['MinX'] += 1
                self.debug(xentry)
                xdb.addEntry(xentry)

            xdb.saveToFile()

            return fdb
        except: self.errorLog('%s.preassemblyFrag error' % self.prog()); return False
#########################################################################################################################
### End of SECTION II: SMRTSCAPE Class                                                                                  #
#########################################################################################################################

                                                    ### ~ ### ~ ###

#########################################################################################################################
### SECTION III: MODULE METHODS                                                                                         #
#########################################################################################################################

#########################################################################################################################
### END OF SECTION III                                                                                                  #
#########################################################################################################################

                                                    ### ~ ### ~ ###

#########################################################################################################################
### SECTION IV: MAIN PROGRAM                                                                                            #
#########################################################################################################################
def runMain():
    ### ~ [1] ~ Basic Setup of Program  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
    try: (info,out,mainlog,cmd_list) = setupProgram()
    except SystemExit: return  
    except: rje.printf('Unexpected error during program setup:', sys.exc_info()[0]); return
    
    ### ~ [2] ~ Rest of Functionality... ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
    try: SMRTSCAPE(mainlog,cmd_list).run()

    ### ~ [3] ~ End ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ###
    except SystemExit: return  # Fork exit etc.
    except KeyboardInterrupt: mainlog.errorLog('User terminated.')
    except: mainlog.errorLog('Fatal error in main %s run.' % info.program)
    mainlog.endLog(info)
#########################################################################################################################
if __name__ == "__main__":      ### Call runMain 
    try: runMain()
    except: rje.printf('Cataclysmic run error: {0}'.format(sys.exc_info()[0]))
    sys.exit()
#########################################################################################################################
### END OF SECTION IV                                                                                                   #
#########################################################################################################################
